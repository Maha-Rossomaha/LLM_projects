# Анализ дисперсии (ANOVA)

> **Идея:** проверить, отличаются ли друг от друга **несколько средних** (3+ групп), разложив общую вариацию на «между группами» и «внутри групп».
>
> - Обобщение t‑теста на большее число групп.
> - Работает в рамках линейной модели: «метрика = общая средняя + эффект группы + шум».
> - В A/B‑тестах используется для **A/B/n экспериментов** и сравнения нескольких вариантов сразу.

---

## 1. Задача и модель

Пусть у нас есть k групп (вариантов):

- группа 1: $X_{11}, \dots, X_{1n_1}$
- группа 2: $X_{21}, \dots, X_{2n_2}$
- ...
- группа k: $X_{k1}, \dots, X_{kn_k}$

Обозначим:

- $n_i$ — размер i‑й группы,
- $N = \sum_{i=1}^k n_i$ — общее число наблюдений.

### 1.1. Линейная модель (однофакторная ANOVA)

Модель записывают так:

$$
X_{ij} = \mu + \alpha_i + \varepsilon_{ij},
$$

где:

- $\mu$ — общая средняя,
- $\alpha_i$ — эффект i‑й группы (на сколько её средняя сдвинута относительно общей),
- $\varepsilon_{ij}$ — случайная ошибка.

Ограничение: обычно предполагают $\sum_{i=1}^k \alpha_i = 0$ для идентифицируемости.

**Нулевая гипотеза:**

$$
H_0: \alpha_1 = \alpha_2 = \dots = \alpha_k = 0
$$

то есть **все групповые средние равны**:

$$
H_0: \mu_1 = \mu_2 = \dots = \mu_k.
$$

**Альтернативная:** хотя бы одна средняя отличается.

---

## 2. Разложение дисперсий

Классический приём ANOVA: разложить общую вариацию на компоненты.

Пусть:

- $\bar X$ — общая средняя по всем данным;
- $\bar X_i$ — средняя в группе i.

### 2.1. Общая сумма квадратов (Total Sum of Squares, SST)

$$
SS_T = \sum_{i=1}^k \sum_{j=1}^{n_i} (X_{ij} - \bar X)^2.
$$

Это «сколько вообще есть вариации» в данных.

### 2.2. Межгрупповая сумма квадратов (Between, SSB)

$$
SS_B = \sum_{i=1}^k n_i (\bar X_i - \bar X)^2.
$$

Это вариация, объясняемая **различием между средними групп**.

### 2.3. Внутригрупповая сумма квадратов (Within, SSW)

$$
SS_W = \sum_{i=1}^k \sum_{j=1}^{n_i} (X_{ij} - \bar X_i)^2.
$$

Это то, что **не объясняется группой**: разброс внутри каждой группы.

### 2.4. Связь

Ключевое тождество:

$$
SS_T = SS_B + SS_W.
$$

То есть общая вариация = вариация между группами + вариация внутри групп.

---

## 3. F‑статистика в ANOVA

Чтобы проверить $H_0$, сравниваем:

- среднюю вариацию **между группами**,
- со средней вариацией **внутри групп**.

### 3.1. Средние квадраты

Степени свободы:

- для "*между групп*": $df_B = k - 1$,
- для "*внутри групп*": $df_W = N - k$.

Средние квадраты:

$$
MS_B = \frac{SS_B}{df_B}, \qquad MS_W = \frac{SS_W}{df_W}.
$$

### 3.2. F‑статистика

$$
F = \frac{MS_B}{MS_W}.
$$

Интуиция:

- если все средние одинаковые, то вариация между группами не больше, чем обычный шум внутри;
- если хотя бы одна средняя существенно отличается, то $MS_B$ вырастает, и F становится >> 1.

При $H_0$ F имеет F‑распределение с $(df_B, df_W)$ степенями свободы. По нему считаем p‑value.

---

## 4. Предпосылки однофакторной ANOVA

1. **Независимость** наблюдений внутри и между группами.
2. **Нормальность ошибок**: $\varepsilon_{ij} \sim N(0, \sigma^2)$ в каждой группе.
3. **Гомоскедастичность**: одинаковая дисперсия в группах ($\sigma^2$ не зависит от i).

На практике ANOVA довольно устойчива:

- к умеренным отклонениям от нормальности (особенно при больших n),
- но хуже переносит сильную неодинаковость дисперсий и очень разные размеры групп.

При серьёзных нарушениях:

- либо использовать поправки (Welch ANOVA),
- либо непараметрический аналог (критерий Краскела–Уоллиса).

---

## 5. ANOVA и t‑тест

Для k = 2 однофакторная ANOVA **эквивалентна** обычному t‑тесту:

- проверяют то же самое: $H_0: \mu_1 = \mu_2$,
- статистики связаны соотношением $F = t^2$,
- p‑value совпадают.

То есть можно думать: ANOVA — это «t‑тест, обобщённый на k > 2 групп».

---

## 6. ANOVA как частный случай линейной регрессии

ANOVA легко переписывается как линейная регрессия с дамми‑переменными.

Пример: три группы (A, B, C).


$$
Y = \beta_0 + \beta_1 D_B + \beta_2 D_C + \varepsilon,
$$

где:

- $D_B = 1$, если наблюдение из группы B, иначе 0;
- $D_C = 1$, если из C, иначе 0;
- группа A — базовая (оба дамми = 0).

Тогда проверки типа «все $\mu_i$ равны» ↔ тест совместных ограничений на коэффициенты регрессии.

Это даёт практический вывод: многие ANOVA‑модели можно строить через `statsmodels` как обычную регрессию с категориальными переменными.

---

## 7. ANOVA в A/B/n‑тестировании

Сценарий: есть несколько вариантов интерфейса/цены/механики:

- контроль A,
- B, C, D — экспериментальные варианты.

Метрика: например, revenue per user.

### 7.1. Зачем ANOVA

Если делать k−1 попарных t‑тестов:

- растёт риск ошибок I рода (multiplicity),
- надо отдельно чинить это поправками (Bonferroni, Holm и т.п.).

ANOVA даёт общий тест:

- $H_0$: все $\mu_i$ одинаковы;
- $H_1$: хотя бы одна средняя отличается.

Если ANOVA **не отвергает** $H_0$:

- дальше нет смысла раздувать попарные сравнения (с поправками): всё равно ничего уверенного не найдёшь.

Если ANOVA **отвергает** $H_0$:

- уже потом делаются пост‑hoc сравнения, чтобы понять, **какие** именно группы отличаются.

### 7.2. Пост‑hoc тесты

Популярные варианты:

- Tukey HSD (честный значимый интервал) — для всех попарных сравнений;
- Bonferroni / Holm — поправки к t‑тестам;
- Scheffé, Dunnett (если специфические сравнения: все против контроля).

Логика: сначала общий F‑тест «есть ли вообще эффект группы», потом детальный разбор пар.

---

## 8. Эффект‑сайз в ANOVA

Одного p‑value мало. Нужна оценка, **насколько значим вклад фактора**.

Часто используют:

### 8.1. Eta squared ($\eta^2$)

$$
\eta^2 = \frac{SS_B}{SS_T}.
$$

Интерпретация: доля общей вариации, объяснённая фактором (группой).

Условные ориентиры (очень грубо):

- 0.01 — маленький эффект,
- 0.06 — средний,
- 0.14+ — большой.

### 8.2. Partial eta squared ($\eta^2$_partial)

Если факторов несколько (многофакторная ANOVA), используют:

$$
\eta^2_{partial} = \frac{SS_{factor}}{SS_{factor} + SS_{error}}.
$$

Она показывает вклад конкретного фактора, условно «вычтя» остальные.

Для однофакторной ANOVA $\eta^2 = \eta^2_{partial}$.

---

## 9. Маленький численный пример

Предположим, у нас есть 3 варианта лендинга, и мы меряем чек (условные числа):

- A: [10, 12, 9, 11, 13]
- B: [15, 14, 16, 15, 17]
- C: [8, 9, 7, 10, 9]

Размеры групп:  
$n_A=n_B=n_C=5$, всего $N=15$, число групп $k=3$

По средним:

- $\bar X_A \approx 11$
- $\bar X_B \approx 15.4$
- $\bar X_C \approx 8.6$

Общая средняя:

- $\bar X \approx 11.67$ 

**Вопрос**: достаточно ли сильны различия, чтобы списать их на эффект варианта, а не случайный шум?

### Считаем $SS_B, SS_W, SS_T$:

1. **Общая сумма квадратов $SS_T$:**  $SS_T = \sum_{i,j} (X_{ij} - \bar X)^2 \approx 139.33$.
2. **Межгрупповая сумма квадратов $SS_B$:** $SS_B = \sum_{i=1}^k n_i (\bar X_i - \bar X)^2 \approx 118.93$.
3. **Внутригрупповая сумма квадратов $SS_W$:** $SS_W = \sum_{i=1}^k \sum_{j=1}^{n_i} (X_{ij} - \bar X_i)^2 \approx 20.40$.

Проверка разложения:

$$
SS_T \approx SS_B + SS_W \quad \Rightarrow \quad
139.33 \approx 118.93 + 20.40.
$$

### Степени свободы и F-статистика:

Степени свободы:
- **между группами:** $df_B = k - 1 = 2$
- **внутри групп:** $df_W = N - k = 12$

Средние квадраты:

$$
MS_B = \frac{SS_B}{df_B} \approx \frac{118.93}{2} \approx 59.47
$$
$$
MS_W = \frac{SS_W}{df_W} \approx \frac{20.40}{12} \approx 1.70.
$$

F-статистика:

$$
F = \frac{MS_B}{MS_W} \approx \frac{59.47}{1.70} \approx 34.98.
$$

что является довольно большим значением.

### p-value и вывод:

Для F-распределения с $(2, 12)$ степенями свободы:
* $F \approx 35$ даёт p-value примерно $p \approx 10^{-5}$

То есть:

$$
p \ll 0.001 \Rightarrow H_0: \mu_A = \mu_B = \mu_C \text{ уверенно отвергается}.
$$

> Различия средних чеков между A, B, C настолько велики относительно разброса внутри групп, что это почти точно не случайный шум.

### Эффект-сайз $\eta^2$:

$$
\eta^2 = \frac{SS_B}{SS_T} \approx \frac{118.93}{139.33} \approx 0.85.
$$

Это чудовищно сильный эффект. В реальном продукте такие цифры вызывают либо восторг, либо подозрение, что данные где-то подглядели.

> Однофакторная ANOVA показала значимый эффект варианта лендинга на средний чек:  
> F(2, 12) ≈ 34.98, p < 0.00001, $\eta^2$ ≈ 0.85.  
> Около 85% вариации метрики объясняется различиями между версиями, а не случайным шумом. Средний чек в варианте B заметно выше, чем в A и C, вариант C существенно хуже остальных.


---

## 10. Пример: однофакторная ANOVA

### 10.1. Через SciPy

```python
import numpy as np
from scipy import stats

A = np.array([10, 12, 9, 11, 13])
B = np.array([15, 14, 16, 15, 17])
C = np.array([8, 9, 7, 10, 9])

# Однофакторная ANOVA (классическая)
F_stat, p_value = stats.f_oneway(A, B, C)
print("F =", F_stat, "p-value =", p_value)
```

`f_oneway` реализует стандартную однофакторную ANOVA с предположением равенства дисперсий.

### 10.2. Через statsmodels (как регрессия)

```python
import numpy as np
import pandas as pd
import statsmodels.api as sm
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm

A = np.array([10, 12, 9, 11, 13])
B = np.array([15, 14, 16, 15, 17])
C = np.array([8, 9, 7, 10, 9])

values = np.concatenate([A, B, C])
groups = (['A'] * len(A) +
          ['B'] * len(B) +
          ['C'] * len(C))

_df = pd.DataFrame({'value': values, 'group': groups})

# Линейная модель: value ~ C(group)
model = ols('value ~ C(group)', data=_df).fit()

anova_res = anova_lm(model, typ=2)
print(anova_res)
```

`C(group)` говорит: "сделай категориальную переменную".
В выводе ANOVA будут:

- `sum_sq` — SS_B (для фактора) и SS_W (Residual),
- `df` — степени свободы,
- `F` и `PR(>F)` — F‑статистика и p‑value.

### 10.3. Оценка $\eta^2$

```python
ss_between = anova_res.loc['C(group)', 'sum_sq']
ss_within = anova_res.loc['Residual', 'sum_sq']
ss_total = ss_between + ss_within

eta_sq = ss_between / ss_total
print("eta^2 =", eta_sq)
```

Это и будет доля вариации, объяснённая фактором `group`.

---

## 11. Что писать в отчёте для ANOVA

- формулировка гипотез:
  > $H_0$: средние метрики во всех группах равны; $H_1$: хотя бы одна средняя отличается;
- тип теста: однофакторная ANOVA (при необходимости указать: обычная / Welch);
- численные результаты: k, N, F, $df_B$, $df_W$, p‑value;
- эффект‑сайз: $\eta^2$ (или partial $\eta^2$ при многофакторных моделях);
- при значимом результате — ссылка на последующие пост‑hoc сравнения.