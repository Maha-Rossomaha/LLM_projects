# Основы каузального вывода


## 1. Почему каузальный вывод критичен для uplift

Uplift-модели должны ранжировать **по приросту** результата от воздействия, а не по «склонности к отклику». Чтобы прирост был идентифицируем, нужно перейти от ассоциативной статистики к **каузальной**: моделировать не $\Pr(Y\mid X)$, а разницу между потенциальными исходами $Y(1)$ и $Y(0)$.

---

## 2. Модель потенциальных исходов (Rubin Causal Model)

### 2.1. Обозначения

- $X$ — вектор признаков (ковариат);
- $W\in\{0,1\}$ — индикатор воздействия: 1 — назначено/получено, 0 — нет;
- $Y$ — наблюдаемый исход (бинарный или вещественный);
- **Потенциальные исходы**: $Y(1)$ — исход при воздействии, $Y(0)$ — без воздействия;
- **Наблюдаемый исход (consistency)**: $Y = Y(W)$.

### 2.2. Эффекты

- **ATE**: $\operatorname{ATE} = \mathbb{E}[Y(1)-Y(0)]$;
- **CATE/HTE**: $\tau(x) = \mathbb{E}[Y(1)-Y(0)\mid X=x]$;
- **ITE**: $\tau_i = Y_i(1)-Y_i(0)$ (ненаблюдаем для единицы);
- Для бинарного $Y$: **uplift** $u(x)=\Pr(Y=1\mid X=x,W=1)-\Pr(Y=1\mid X=x,W=0)$ совпадает с $\tau(x)$ при стандартных допущениях.

### 2.3. Фундаментальная проблема

Для каждой единицы видим только $Y(1)$ **или** $Y(0)$. Второй исход — **контрфактуал**. Идентификация требует допущений или дизайна эксперимента.

---

## 3. Контрфактуальное рассуждение

**Вопрос**: «что было бы с этим же объектом при другом значении воздействия?» — это и есть контрфактуал.

**Пример (email‑кампания):** для клиента с признаками $x$ мы видим $Y=1$ после письма ($W=1$). Но купил бы он без письма ($W=0$)? Ответ зависит от совместного распределения $(Y(1),Y(0),X,W)$ и допущений.

**Практический смысл:** политика назначения воздействия должна опираться на оценку $\tau(x)$, а не на $\Pr(Y=1\mid X=x)$.

---

## 4. Ключевые допущения

### 4.1. SUTVA (Stable Unit Treatment Value Assumption)

Два компонента:

1. **Отсутствие интерференции**: исход одной единицы не зависит от того, кто ещё и какое получил воздействие;
2. **Единственность версии воздействия**: «W=1» означает одну и ту же процедуру для всех (нет скрытых разновидностей письма/скидки).

**Нарушения:** «спилловеры» в сетях, каннибализация каналов, разные версии оффера под одним флагом.  
**Практика:** 
1. **Уточнение определение воздействия** - что считается воздействием - факт показа/отправки сообщения или клика/просмотра.
2. **Использование «exposure mapping»** - формализовать сложные схемы контакта (чаще всего - небинарный факт воздействия).
3. **Контроль кросс‑инфекции каналов** - следить, чтобы пользователь не получил взаимодействие через другой канал.

### 4.2. Игнорируемость / Неконфоундированность (Ignorability / Unconfoundedness)

$(Y(1),Y(0)) \;\perp\; W \mid X.$
После учёта ковариат $X$ назначение воздействия «как бы случайно». В RCT это обеспечивается рандомизацией; в наблюдательных данных — предположение.

Замечание: «сильная игнорируемость» объединяет игнорируемость и позитивность (ниже).

### 4.3. Позитивность / Перекрытие (Positivity / Overlap)

Для всех релевантных $x$: $0 < \Pr(W=1\mid X=x) < 1$. Иначе для некоторых $x$ нет данных по одной из ветвей, и $\tau(x)$ не идентифицируем.

**Практика:**  
1. **Контроль распределения propensity score** - смотреть, пересекаются ли плотности $\Pr(W=1\mid X)$ для treatment и control.
2. **Тримминг областей без перекрытия** - исключать наблюдения, где $\Pr(W=1\mid X)$ близки к 0 или 1.
3. **Регуляризация/ограничение весов** - при использовании взвешенных методов ограничивают или сглаживают слишком большие веса, чтобы не давать чрезмерное влияние "редким" областям данных.

### 4.4. Консистентность (Consistency)

Если единице назначено $W=w$, то наблюдаемый исход равен соответствующему потенциальному: $Y=Y(w)$. 

**Нарушения:** несоблюдение протокола, несовпадение фактического и назначенного воздействия, «версии воздействия».

> **Итог:** без этих условий мы не можем корректно переходить от наблюдаемых частот к причинным эффектам.

---

## 5. Конфоундинг и смещения выборки

### 5.1. Конфоундер (смешивающая переменная)

**Конфаундер** — это переменная $Z$, которая влияет **и на назначение воздействия** $W$, **и на исход** $Y$. Если её не учесть, модель будет принимать естественные различия между группами за "эффект воздействия".

**Пример:** активные клиенты чаще получают промо ($W=1$) и чаще совершают покупки ($Y=1$). Если не добавить "активность" в признаки, алгоритм решит, что покупка произошла из-за промо, а не из-за того, что клиент и без него активный.

---

### 5.2. Selection bias (смещение выборки)

**Selection bias** возникает, когда анализ проводится **на подмножестве данных**, отобранном по признакам, связанным с $W$ или $Y$. Это может случайно "открыть" ложные связи между воздействием и исходом.

**Основные случаи:**

- **Коллидер:** переменная $C$, на которую влияют и $W$, и $Y$. Если условиться на неё (например, фильтровать по ней), появляется *искусственная* корреляция между $W$ и $Y$, даже если на самом деле её нет.

- **Пост-тритмент ковариаты:** признаки, которые формируются **после воздействия**  (например, "открыл письмо", "перешёл по ссылке"). Если на них условиться, часть эффекта воздействия "вымывается", и оценка становится смещённой.

---

### 5.3. Парадокс Симпсона

**Парадокс Симпсона** — ситуация, когда общий (агрегированный) эффект воздействия кажется положительным или отрицательным, но при разделении по важному признаку $Z$ (например, возрасту, региону, активности) эффект исчезает или даже меняет знак.

**Пример:** реклама работает в каждой возрастной группе,  
но в среднем кажется "вредной", если молодые пользователи чаще были в контроле.  

> Такой парадокс — типичный сигнал, что в данных есть **неучтённый конфаундер**.


---

## 6. Пропенсити‑скор (Propensity score) и способы его использования

### 6.1. Определение
**Propensity score** - 
$$
e(X) = \Pr(W=1\mid X),
$$  
т. е. вероятность того, что объект с признаками $X$ попадёт в treatment-группу.  
Фактически, это "склонность" или "вероятность назначения воздействия" для конкретного наблюдения.

**Теорема Розенбаума–Рубина:**  
Если выполняется условие **игнорируемости (unconfoundedness)**:
$$
(Y(1), Y(0)) \perp W \mid X,
$$
то оно также выполняется при условии **propensity score**:
$$
(Y(1), Y(0)) \perp W \mid e(X).
$$

> **Смысл**: чтобы устранить смещение из-за разных распределений признаков между treatment и control, **не нужно уравнивать все признаки $X$** — достаточно уравнять (сбалансировать) их **по одной скалярной функции**.

**Почему это важно**  
В реальных данных treatment и control группы часто различаются по $X$. Например, более активные пользователи чаще получают рекламу. Чтобы корректно сравнить группы, нужно, чтобы их распределения по признакам были одинаковыми.  

Но $X$ может быть многомерным — уравнять всё напрямую сложно. Теорема говорит: можно "сжать" всю информацию о вероятности попасть в treatment в одно число $e(X)$, и если treatment и control **имеют одинаковое распределение propensity score**, то они сбалансированы и по исходным признакам $X$.

### 6.2. Оценка e(X)

Propensity score $e(X) = \Pr(W=1 \mid X)$ — это просто **модель вероятности попасть в treatment-группу**. Её можно обучить с помощью любого классификатора, где:
- признаки = ковариаты $X$,
- таргет = $W$ (1 — получил воздействие, 0 — нет).

Задача модели — **не предсказывать точно, кто получит воздействие**, а **обеспечить одинаковое распределение признаков** между treatment и control при стратификации по $e(X)$.

Поэтому высокая точность (ROC-AUC → 0.9+) может быть даже вредна: модель слишком "уверена", группы почти не пересекаются → нарушается условие перекрытия (для некоторых типов людей нет аналогов в другой группе).  

Лучше, если $e(X)$ распределён **плавно**, и treatment/control пересекаются.

После обучения модель часто **калибруют**, чтобы прогнозы отражали реальные вероятности.

Калибровка важна, потому что даже небольшие искажения в вероятностях дают сильные ошибки при вычислении весов (например, в IPW).

### 6.3. Способы использования e(X)

1. **Стратификация/субклассификация** по квинтилям/децилам e(X). Сравниваем исходы внутри бинов; усредняем с весами размеров бин‑групп.
2. **Матчинг** по e(X) или по ковариатам: nearest‑neighbor, caliper, 1\:k matching, с/без возврата; оценка ATE/ATT с учётом парных весов.
3. **Взвешивание (IPTW)**: веса для ATE
   $$
   w_i = \begin{cases}
   1/e(X_i), & W_i=1,\\
   1/(1-e(X_i)), & W_i=0.
   \end{cases}
   $$
   **Стабилизированные веса**: умножают на маргинальные вероятности $\Pr(W=1)$, $\Pr(W=0)$ для снижения дисперсии.
4. **Регрессия с учётом e(X)**: добавление пропенсити как фичи (менее предпочтительно в одиночку), или как часть **двойной робастности** (ниже).

### 6.4. Диагностика баланса

- **Standardized Mean Difference (SMD)** до/после корректировки; ориентир |SMD|<0.1;
- **Love‑plots**, гистограммы e(X) по группам, **overlap‑чек**;
- **Trimming/Truncation**: отсечение наблюдений с экстремальным e(X) или обрезка весов;
- **Effective Sample Size (ESS)** под весами: $\text{ESS} = (\sum w_i)^2 / \sum w_i^2$.

> Для uplift: после выравнивания групп можно обучать модели разности (или мета‑learner’ы), не боясь сильного selection bias в наблюдательных данных.

---

## 7. Числовой мини‑разбор (стратификация по e(X))

Пусть база из 10 000 клиентов, бинарный исход (покупка). Оценили $\hat e(X)$ и разбили на 5 квинтилей (равные по объёму бины). В каждом бине считаем конверсию в группах $W=1$ и $W=0$, затем берём взвешенное среднее разностей.

| Бин e(X)   | N    | CR (W=1) | CR (W=0) | Разность | Вес бина |
| ---------- | ---- | -------- | -------- | -------- | -------- |
| Q1 (низк.) | 2000 | 0.04     | 0.03     | +0.01    | 0.2      |
| Q2         | 2000 | 0.06     | 0.05     | +0.01    | 0.2      |
| Q3         | 2000 | 0.08     | 0.06     | +0.02    | 0.2      |
| Q4         | 2000 | 0.10     | 0.08     | +0.02    | 0.2      |
| Q5 (выс.)  | 2000 | 0.14     | 0.11     | +0.03    | 0.2      |

Итоговая ATE≈0.018 (=сумма разностей×вес). Без стратификации получили бы, например, «эффект» 0.04 из‑за того, что высокие e(X) были перепредставлены в группе W=1.

---

## 8. Связь с uplift‑моделями

- Цель корректировок — приблизить данные к ситуации RCT **или** учесть смещение прямо в алгоритме (weights/DR‑мета‑learners).
- После обеспечения баланса можно оценивать $\tau(x)$ (CATE) и строить политики назначения воздействия, валидируя по Qini/AUUC.
