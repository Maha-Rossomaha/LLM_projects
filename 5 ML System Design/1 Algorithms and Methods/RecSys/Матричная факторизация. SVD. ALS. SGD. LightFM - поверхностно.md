---
Owner: IIvan Vashchenko
---
> [!important] 
> Основные легкие методы рекомендаций (не нейронки).
> 
> ![[image 15.png|image 15.png]]

# Матричная факторизация с SVD

Проблема memory-based подходов - сложно повышать coverage.

Задача: найти функцию $f_R: \text{Users} \times \text{Items} \rightarrow \text{Relevance Score}$

Есть матрица $A \in {R}^{M \times N}$ - решаем оптимизационную задачу

![[image 1 7.png|image 1 7.png]]

**Low-rank approximation** - идея состоит в получении представления с более малым рангом, чем исходная матрица $A$.

**Интуиция матричной факторизации:**

$A_{full} = R + E, R = PQ^T$, $E$ - неустраняемый шум.

Прогнозная релевантность item $j$ для user $v$: $\large r_{vj} \approx p_{v}^T q_j = \sum_{k=1}^d{p_{vk}q_{jk}}$, $d$ - размерность представления.

  

## Реализация MF в implicit библиотеке

![[image 2 6.png|image 2 6.png]]

Данные блоки отражают представление пользователей и айтемов не только через скрытые латентные факторы, но и через явные, заранее известные признаки.

- **Latent** – это скрытые факторы, которые модель автоматически обучает.
- **Paired to explicit features** – это векторное представление, связанное с конкретными, заранее заданными признаками, но упорядоченное соотносительно с латентным пространством.
- **Explicit features** – это матрицы или векторы известных признаков (например, пол, возраст пользователя или категория товара), которые прямо включаются в факторизацию. Идея в том, что помимо скрытых параметров, модель использует и явно заданные признаки, улучшая качество рекомендаций.

**Зачем это нужно в матричной факторизации?**

- Чистая матричная факторизация использует только матрицу взаимодействий, но не учитывает дополнительную информацию о пользователях или товарах.
- Добавление явных признаков даёт модели контекст, улучшает способность предсказывать взаимодействия для тех случаев, где данных мало, и повышает интерпретируемость.
- Подобный подход часто используют в моделях расширенного ALS (например, iALS), чтобы улучшить устойчивость и точность.

---

## Singular Value Decomposition

![[image 3 6.png|image 3 6.png]]

Проблема: SVD определено для полных матриц, а у нас незаполнена в 99.99% случаев.

Можно рассмотреть **PureSVD** заполняем нулями неизвестные рейтинги.

![[image 4 6.png|image 4 6.png]]

![[image 5 6.png|image 5 6.png]]

Получается $R = A_0V_dV_d^T$ - раскладываем рекомендацию через пространство товаров и взаимодействия пользователей.

Стоит помнить:

- ранг $d$ подбирается эмпирически
- можно заполнять не нулями, а например средним рейтингом

  

Какой алгоритм более интерпретируемый?

**Matrix Factorization**: $r = Qp$, $p$ - конкретный пользователь, $Q$ - товары. Неудобно для интепретации и объяснения, потому что “латентные” вектора.

**SVD**: $r = VV^Ta$, $a$ - вектор взаимодействий (бинарный вектор или рейтинги)

$Q \times p = V \times V^Ta$,

$\large V^Ta = \sum_{i \in I_a}{v_i}$, где $I_a$ - взаимодействия пользователя а. То есть наш пользователь представляется “средним эмбеддингов” от тех товаров, с которыми он провзаимодействовал.

Получается мы можем получить величину вклада, который внес товар $i$ в рекомендацию товара $j$:

$\huge \frac {v_j^Tv_i} {{\sum_{k \in I_a}}{v_j^Tv_k}}$

  

Чем еще полезен **SVD**?

Он позволяет добавлять новую информацию и рекомендовать без переобучения - _folding-in_.

![[image 6 6.png|image 6 6.png]]

---

## Randomized SVD

[Criteo Spark-RSVD](https://github.com/criteo/Spark-RSVD) - статья на medium: [https://techblog.criteo.com/sparkrsvd-open-sourced-by-criteo-for-large-scale-recommendation-engines-6695b649f519?gi=e9c681dffeb9](https://techblog.criteo.com/sparkrsvd-open-sourced-by-criteo-for-large-scale-recommendation-engines-6695b649f519?gi=e9c681dffeb9)

[Facebook's randomized SVD implementation](https://research.fb.com/fast-randomized-svd)  
  
[https://www.deepmind.com/blog/game-theory-as-an-engine-forlarge-scale-data-analysis](https://www.deepmind.com/blog/game-theory-as-an-engine-forlarge-scale-data-analysis)

---

## On-stream и incremental learning

![[image 7 5.png|image 7 5.png]]

---

  

# Снижение предвзятости популяции

**Закон Ципфа (zipf-like dist)** - встречаемость $n$-го значения при ранжировании равна $\frac {1}{n}$.

- **Языкознание**: В текстах частота слов подчиняется закону Ципфа — самое частое слово встречается примерно в два раза чаще второго, в три раза чаще третьего и т.д.
- **Экономика**: Распределение доходов или размеров городов.
- **Интернет**: Популярность запросов или посещаемость страниц.

Данные представляют собой зачастую степенные или _zipf-like_ распределения. В этом случае популярные товары могут быть больше похожи на другие товары, чем _реально похожие_ товары. Например у них получается высокое скалярное произведение $a_j^Ta_i$. Причины:

1. **Популярные товары имеют больше взаимодействий:**
    - У популярных товаров векторы эмбеддингов могут быть "усредненными" из-за большого количества взаимодействий с различными пользователями. Это делает их менее специфичными и более похожими на средний вектор пространства.
2. **Косинусная близость и скалярное произведение:**
    - Эмбеддинги популярных товаров часто близки к "центру" латентного пространства, что увеличивает вероятность их высокого скалярного произведения с другими товарами, даже если они не похожи семантически.
3. **Эффект регуляризации:**
    - Алгоритмы, такие как матричная факторизация или нейронные сети, оптимизируют латентные векторы с учетом популярности, что приводит к их схождению в пространстве.
4. **Шумовые данные:**
    - Популярные товары участвуют в большем количестве шумных взаимодействий (например, случайных покупок), из-за чего их векторы становятся более универсальными и получают высокое скалярное произведение с другими товарами.

Первичная идея: нормировать обратно-пропорционально встречаемости.

$\tilde{A} = D_u^{f-1}A$, где $[D]_{ii} = ||a_i||$, $f < 1$

Еще вариант: user-based normalization, либо комбинировать.

## Взвешенная матричная факторизация

**Функция потерь:**

$\mathcal{L}(A, \Theta) = \frac{1}{2} \sum_{i, j \in \mathcal{O}} (a_{ij} - \mathbf{p}_i^T \mathbf{q}_j)^2$

- $\mathcal{O} = \{(i, j): a_{ij} \text{ известно}\}$: множество известных взаимодействий.
- $\mathbf{p}_i$, $\mathbf{q}_j$: латентные представления пользователей и элементов.
- Цель: минимизировать разницу между реальными и предсказанными значениями.

**Матрица весов (в простейшем случае):**

$w_{ij} = \begin{cases} 1, & \text{если } a_{ij} \text{ известно} \\ 0, & \text{иначе.} \end{cases}$

**Матрица представлений:**

$R = P Q^T$

Где:

- $P$: матрица латентных факторов для пользователей $M \times d$
- $Q$: матрица латентных факторов для элементов ($N \times d$).

**PureSVD:**

$\mathcal{L} = \|A_0 - R\|_F^2$

Где $A_0$ — исходная матрица взаимодействий.

  

Общая функция потерь при оптимизации:

$\mathcal{J}(\Theta) = \mathcal{L}(A, \Theta) + \Omega(\Theta)$

Где:

- $\mathcal{L}(A, \Theta)$: функция потерь, измеряющая ошибку предсказаний.
- $\Omega(\Theta)$: дополнительные ограничения, например, L2-регуляризация.

Параметры модели:

$\Theta = \{P, Q\}$

### **Типичные алгоритмы оптимизации (ALS и SGD)**

1. **Alternating Least Squares (ALS):**
    
    ![[image 8 4.png|image 8 4.png]]
    
    - Поочередно фиксирует $P$ и оптимизирует Q, затем наоборот.
    - Формулы: $P^* = \arg \min_P \mathcal{J}(\Theta), \quad Q^* = \arg \min_Q \mathcal{J}(\Theta)$
    - Хорошо подходит для разреженных матриц, эффективно распределяется.
    
    Сложность одной итерации — $O(|\mathcal{O}| \cdot d^2 + (M + N) \cdot d^3)$, где $|\mathcal{O}|$ — количество ненулевых элементов, $d$ — размерность факторов, M — число пользователей, $N$ — число элементов.
    
2. **Stochastic Gradient Descent (SGD):**
    
    - Градиентное обновление параметров:  
        $\mathbf{p}_i \gets \mathbf{p}_i - \eta \nabla_{\mathbf{p}_i} \mathcal{J}, \quad \mathbf{q}_j \gets \mathbf{q}_j - \eta \nabla_{\mathbf{q}_j} \mathcal{J}$
    - Гибкий и легко адаптируемый к разным функциям потерь, но требует настройки гиперпараметров.
    
    Сложность одной итерации — $O(T \cdot |\mathcal{O}| \cdot d)$, где $T$ — количество итераций, $|\mathcal{O}|$ — число ненулевых элементов. Эффективнее для малых и средних данных, но требует больше итераций для сходимости.
    
    **Funk-SVD** — это модификация метода сингулярного разложения матриц (SVD), популяризированная во время Netflix Prize. В отличие от классического SVD, Funk-SVD оптимизирует только известные элементы в пользователь-товарной матрице и обучается с использованием **градиентного спуска**. Есть расширенный подход:
    
    Помимо латентных факторов $\mathbf{p}_i$ и $\mathbf{q}_j$ учитываются дополнительные параметры: глобальный средний рейтинг ($\mu$), пользовательская склонность ($g_i$) и элементная склонность ($f_j$). Они улучшают качество рекомендаций, так как учитывают общий средний рейтинг, а также индивидуальные особенности пользователей и элементов.
    
    **Основная модель предсказания:**
    
    $r_{ij} = \mu + g_i + f_j + \mathbf{p}_i^T \mathbf{q}_j$
    
    Где:
    
    - $\mu$: глобальный средний рейтинг всех элементов.
    - $g_i$: склонность пользователя $i$ к выставлению высоких или низких оценок.
    - $f_j$: склонность элемента $j$ к получению высоких оценок.
    - $\mathbf{p}_i$: латентный вектор пользователя $i$.
    - $\mathbf{q}_j$: латентный вектор элемента $j$.
    
    Этот подход помогает учесть:
    
    1. **Пользовательские предпочтения**: Некоторые пользователи склонны ставить более низкие или высокие оценки в среднем.
    2. **Популярность элементов**: Некоторые фильмы или товары имеют естественную популярность (например, блокбастеры).
    

**Основное отличие ALS от SGD:**

- ALS подходит для распределённых вычислений и работы с большими разреженными матрицами.
- SGD позволяет гибко учитывать весовые функции и работает лучше на меньших наборах данных. **SGD** эффективен для больших разреженных матриц и проще в реализации, но требует больше итераций для сходимости.

---

  

# Взвешивание интеракций и их отсутствия

|   |   |   |   |
|---|---|---|---|
|**Метод**|**Применение**|**Основная идея**|**Данные**|
|**iALS**|Рекомендации на основе неявной обратной связи|Взвешенная ALS для обработки бинарных матриц|Неявная обратная связь|
|**WRFM**|Рекомендации с учетом сложных взаимодействий|Учет весов и взаимодействий между признаками|Контекстные данные|

- **iALS** подходит для работы с большими наборами неявных данных, таких как клики или просмотры.
- **WRFM** полезен для задач, где важно учитывать сложные взаимодействия между признаками или контекст, например, в рекламных системах.

## iALS

Это модификация метода ALS, которая предназначена для работы с **неявными данными** (implicit feedback). Неявные данные представляют собой взаимодействия, которые не содержат явной оценки (например, просмотр, клик, лайк), но дают информацию о предпочтениях пользователей.

Есть реализация в библиотеке [implicit](https://github.com/benfred/implicit).

**Основная идея iALS**

- В неявных данных отсутствуют оценки, но вместо этого можно использовать **весовую матрицу**, которая выражает уверенность в взаимодействии пользователя с элементом.
- Вместо работы с матрицей R, содержащей явные оценки, алгоритм работает с **бинарной матрицей** $X$, где:
    
    $x_{ui} = \begin{cases} 1, & \text{если есть взаимодействие (например, просмотр)} \\ 0, & \text{если взаимодействие отсутствует.} \end{cases}$
    

**Функция потерь iALS**

$\mathcal{L} = \sum_{u, i} c_{ui} (x_{ui} - \mathbf{p}_u^T \mathbf{q}_i)^2 + \lambda (\|\mathbf{P}\|^2 + \|\mathbf{Q}\|^2)$

Где:

- $c_{ui} = 1 + \alpha r_{ui}$: весовая функция, зависящая от количества взаимодействий $r_{ui}$ (например, число просмотров). Весовая функция может зависеть от многих параметров.
- $\mathbf{p}_u$: латентный вектор пользователя.
- $\mathbf{q}_i$: латентный вектор элемента.
- $\lambda$: коэффициент регуляризации.
    
    Наивная реализация требует работы с полной весовой матрицей $C$, что при большом числе пользователей ($M$) и элементов ($N$) приводит к высокой вычислительной стоимости: $O(M \times N \times d)$ для одного обновления.
    
    **ТРЮК:**
    
    **iALS** снижает вычислительную сложность, используя то, что матрица весов CCC является разреженной для большинства приложений. Это позволяет разложить CCC на две части:
    
    $C = I + \alpha R$
    
    где:
    
    - $I$ — единичная матрица, отвечающая за базовые веса.
    - $\alpha R$ — разреженная матрица, зависящая от количества взаимодействий.
    
    **Ускорение вычислений**
    
    Во время оптимизации вместо явного хранения и умножения полной матрицы $C$, **iALS** работает только с ненулевыми элементами разреженной матрицы $R$. Для обновления латентных факторов $P$ и $Q$ используются следующие выражения:
    
    1. **Обновление пользовательских факторов (**$\mathbf{p}_u$**)**
        
        $\mathbf{p}_u = (Q^T C_u Q + \lambda I)^{-1} Q^T C_u \mathbf{x}_u$
        
        $C_u$ — диагональная матрица весов для пользователя uuu.
        
    2. **Обновление элементных факторов (**$\mathbf{q}_i$**):**
        
        $\mathbf{q}_i = (P^T C_i P + \lambda I)^{-1} P^T C_i \mathbf{x}_i$
        
        Где $C_i$ — диагональная матрица весов для элемента $i$.
        
    
    **Уменьшение сложности**
    
    При помощи использования разреженности матрицы $R$, вычисления включают только ненулевые элементы:
    
    1. Матрица $C_u$ (или $C_i$) представляется как диагональная, где ненулевые элементы вычисляются напрямую.
    2. Векторное умножение и матричные операции сводятся к работе только с ненулевыми взаимодействиями, что уменьшает сложность одной итерации до:  
        $O(|\mathcal{O}| \cdot d^2 + (M + N) \cdot d^3)$  
        Где:  
        - $|\mathcal{O}|$ — количество ненулевых элементов.
        - $d$ — размерность латентных факторов.
    
    **Итог**
    
    - **Основной трюк iALS**: замена работы с полной весовой матрицей $C$ на разреженные операции с ненулевыми элементами матрицы $R$.
    - Это позволяет значительно снизить вычислительные затраты, делая iALS подходящим для обработки больших наборов данных.
    

**Преимущества iALS**

- Хорошо работает для задач с большими разреженными матрицами.
- Оптимизирован для обработки огромных наборов данных с неявной обратной связью (например, рекомендации товаров или музыки).
- Учитывает разную уверенность в взаимодействиях ($c_{ui}$).

**Ограничения iALS**

- Требует больше памяти для хранения весовой матрицы.
- При высокой разреженности данные "нулей" могут сильно доминировать над "единицами", что требует настройки гиперпараметров.

---

## WRFM

Это метод, который объединяет идеи факторизации матриц и Factorization Machines (FM), добавляя **взвешивание** для обработки разреженных данных. Этот метод используется для задач, где важно учитывать сложные взаимодействия между признаками (например, в рекомендательных системах, предсказании CTR).

**Основная идея WRFM**

- WRFM — это обобщение классической факторизации матриц, которое позволяет учитывать дополнительные признаки (например, время взаимодействия, категорию товара, контекст).
- Метод учитывает разный вес для различных взаимодействий, что делает его гибким для обработки разреженных данных.

**Функция потерь WRFM**

$\mathcal{L} = \sum_{(i, j) \in \mathcal{O}} c_{ij} \cdot (r_{ij} - \hat{r}_{ij})^2 + \lambda \|\Theta\|^2$

Где:

- $r_{ij}$: реальное значение взаимодействия.
- $\hat{r}_{ij}$: предсказанное значение.
- $c_{ij}$: вес, отражающий важность взаимодействия.
- $\Theta$: параметры модели (включая латентные векторы).

**Отличительные особенности**

1. **Учет взаимодействий между признаками**:
    - WRFM может учитывать более сложные зависимости между пользователями, товарами и контекстными признаками.
2. **Взвешивание**:
    - Каждое взаимодействие имеет свой вес $c_{ij}$, который регулируется в зависимости от надежности или важности данных.

**Преимущества WRFM**

- Гибкость: Подходит для задач, где нужно учитывать сложные взаимодействия.
- Точность: Улучшает качество рекомендаций за счет учета весов и дополнительных признаков.
- Широкое применение: Используется в системах рекомендаций, рекламе (CTR), прогнозировании рейтингов.

**Ограничения WRFM**

- Более высокая вычислительная сложность по сравнению с iALS.
- Требует тщательной настройки гиперпараметров и весовых функций.

---

  

# Negative sampling

Все эти методы необходимы для баланса вклада негативных и позитивных айтемов

- **SGD** - negative sampling (негативный популярный товар может быть гораздо более сильным сигналом)
- **iALS** - confidence weights
- **PureSVD** - data normalization

---

  

# Bayesian Personalized Ranking

В контексте ранжирования рекомендаций стоит помнить про альтернативу [[Функция потерь и базовые подходы в LTR]]: [[Функция потерь и базовые подходы в LTR]] (штрафуем, когда порядок нарушен) и [[Функция потерь и базовые подходы в LTR]] (сложно оптимизировать).

Мы можем ввести метрику **AUC:**

$\Large AUC(u) = \frac{1}{|I_u||I_{-u}|} \sum_{i \in I_u} \sum_{i \in I_{-u}} {I(i >_u i_j)}$

где $>_u$ - сравнение относительно пользователя $u$

$\Large AUC = \frac{1}{\mathcal{U}} \sum_{u \in \mathcal{U}} {AUC(u)}$

Но такая метрика недифференцируема, поэтому надо ввести некоторую сглаженную аппроксимацию.

Помним, что $r_{ui} = p_u^Tq_j$

Введем $x_{uij} = r_{ui} - r_{uj} = p_u^T(q_i - q_j)$ при $\mathcal{D} = \{u,i,j: i >_u j, i \neq j\}$

Введем функцию ошибки:

$\Large \mathcal{L}(A,R) = \sum_{u,i,j \in \mathcal{D}} {l(r_{ui} - r_{uj})} = \sum_{u,i,j \in \mathcal{D}} {- \text{log} \sigma(x_{uij})}$

![[image 9 3.png|image 9 3.png]]

По факту это работает как логрег (расписывается через максимизацию правдободобия) и мы придем к точно такой же формуле.

![[image 10 3.png|image 10 3.png]]

---

  

# LightFM

**LightFM** — это библиотека для построения рекомендательных систем, которая поддерживает гибридные подходы, комбинируя **коллаборативную фильтрацию** и **контентные признаки**. Библиотека позволяет работать как с явными (explicit), так и с неявными (implicit) данными. Она оптимизирует модель с использованием различных функций потерь, включая **BPRLoss** и **WarpLoss**.

**Основные особенности LightFM:**

1. **Гибридная рекомендательная система**:
    - Поддержка как матричной факторизации, так и контентных признаков.
    - Возможность учитывать дополнительные данные, такие как текстовые или категорийные атрибуты пользователей и элементов.
2. **Оптимизация под задачи ранжирования**:
    - Включает функции потерь, ориентированные на улучшение метрик ранжирования (например, BPRLoss и WarpLoss).
3. **Гибкость**:
    - Легко адаптируется под неявную обратную связь.
    - Поддерживает пользовательские функции потерь.
4. **Эффективность**:
    - Оптимизирован для разреженных матриц взаимодействий.

---

## **BPRLoss (Bayesian Personalized Ranking Loss)**

**BPRLoss** — это функция потерь, ориентированная на оптимизацию ранжирования, которая минимизирует вероятность того, что негативный элемент будет предсказан выше позитивного.

**Формула BPRLoss:**

$\Large \mathcal{L} = - \sum_{(u, i, j)} \ln(\sigma(\hat{r}_{ui} - \hat{r}_{uj})) + \lambda \|\Theta\|^2$

Где:

- $u$: пользователь.
- $i$: позитивный элемент (с которым есть взаимодействие).
- $j$: негативный элемент (с которым взаимодействия нет).
- $\hat{r}_{ui}, \hat{r}_{uj}$: предсказанные оценки для элементов $i$ и $j$.
- $\sigma(x)$: сигмоида.
- $\lambda$: коэффициент регуляризации.

**Основные этапы реализации:**

1. Для каждого пользователя $u$:
    - Выбрать пару элементов $(i,j)$, где $i$ — позитивный элемент, а $j$ — негативный.
    - Вычислить разницу предсказанных значений: $\Delta = \hat{r}_{ui} - \hat{r}_{uj}$.
    - Вычислить градиенты и обновить параметры модели $(P,Q)$.
2. Повторять до сходимости.

---

## **WarpLoss (Weighted Approximate-Rank Pairwise Loss)**

**WarpLoss** — это функция потерь, которая оптимизирует ранжирование, уделяя больше внимания значительным ошибкам (высоким рангам). WarpLoss вводит весовые штрафы в зависимости от позиции неправильного элемента.

### Формула WarpLoss:

$\Large \mathcal{L} = \sum_{(u, i)} \sum_{j \in \mathcal{N}(u)} w(\text{rank}(j)) \cdot \max(0, 1 - \hat{r}_{ui} + \hat{r}_{uj})$

Где:

- $\text{rank}(j)$: позиция неправильного элемента $j$ в предсказанном списке.
- $w(\text{rank}(j))$: вес ошибки, увеличивающийся с ростом ранга $j$.
- Остальные обозначения аналогичны BPRLoss.

### Основные этапы реализации:

1. Для каждого пользователя $u$:
    - Выбрать положительный элемент $i$ и сэмплировать негативный элемент $j$.
    - Определить $\text{rank}(j)$ в предсказанном списке.
    - Если $\hat{r}_{ui} \leq \hat{r}_{uj}$, применить штраф $w(\text{rank}(j))$.
2. Обновить параметры модели $(P,Q)$ на основе градиента.

---

## Сравнение BPRLoss и WarpLoss

|   |   |   |
|---|---|---|
|**Характеристика**|**BPRLoss**|**WarpLoss**|
|**Оптимизация**|Фокус на парных различиях|Фокус на ранге элементов|
|**Вес ошибки**|Равный для всех ошибок|Зависит от позиции неправильного элемента|
|**Применение**|Улучшение качества ранжирования|Улучшение метрик ранжирования (например, NDCG)|
|**Сложность реализации**|Простая|Более сложная из-за вычисления ранга|

## Почему LightFM — библиотека?

1. **Многофункциональность:**
    - LightFM предоставляет гибкие инструменты для работы как с **коллаборативной фильтрацией**, так и с **гибридными рекомендациями** (учёт контентных признаков).
    - Поддерживает разные функции потерь: **BPRLoss**, **WarpLoss**, **Hinge Loss**, **Logistic Loss**.
    - Позволяет учитывать дополнительные данные, такие как признаки пользователей или элементов.
2. **Легкость интеграции:**
    - LightFM поддерживает разреженные матрицы, что делает её удобной для обработки больших данных.
    - Прост в использовании, интеграции и настройке.
3. **Настраиваемость:**
    - Пользователи могут выбирать функцию потерь, количество латентных факторов, регуляризацию и другие параметры.

---

  

# Другие методы

- **Graph-based techniques** фокусируются на моделировании взаимодействий через графовые структуры, что позволяет учитывать сложные связи между пользователями и элементами.
- **Другие методы оптимизации MF** предлагают разные подходы для улучшения качества рекомендаций, включая интерпретируемость (Non-negative MF), оптимизацию ранжирования (CLI-MF), и работу с контекстом (Translation-based).

## **На основе графов**

1. **P3α**:
    - Алгоритм, основанный на случайных блужданиях по графу.
    - Используется для рекомендаций, представляя пользователей и элементы (товары) в виде вершин графа, соединённых рёбрами (взаимодействиями).
    - Управляется параметром $\alpha$, который регулирует вероятность возврата к пользователю после перехода по ребру.
    - Подходит для персонализации рекомендаций.
2. **RecWalk**:
    - Модификация случайных блужданий, оптимизированная для рекомендательных систем.
    - Использует дополнительные механизмы для обработки разреженных данных и улучшения качества рекомендаций за счёт приоритизации наиболее релевантных узлов в графе.
    - Эффективен при работе с неявной обратной связью.
3. **Personalized Diffusions**:
    - Метод, который моделирует распространение предпочтений пользователя через граф.
    - Учитывает связи между элементами и пользователями, чтобы передавать влияние через соседей.
    - Более сложный и вычислительно затратный, но даёт улучшение рекомендаций за счёт глубокого анализа структуры графа.

---

## **Другие методы оптимизации матричной факторизации**

1. **Non-negative MF**:
    - Ограничивает латентные факторы быть только неотрицательными.
    - Полезен для интерпретируемости, так как все значения имеют физический смысл (например, количество).
2. **Boolean MF**:
    - Работает с бинарными данными (например, взаимодействие произошло или нет).
    - Оптимизирован для задач, где матрица взаимодействий состоит из 0 и 1.
3. **Ranking Approximation** (CLI-MF, CoFiRank, Maximum Margin MF):
    - Эти методы направлены на оптимизацию метрик ранжирования (например, NDCG, MAP).
    - Они фокусируются на том, чтобы элементы, с которыми у пользователя есть взаимодействие, находились выше в списке рекомендаций.
4. **Kernelized MF**:
    - Применяет методы из теории ядер (kernel methods), чтобы учитывать нелинейные зависимости между пользователями и элементами.
    - Используется для улучшения рекомендаций, когда простая матричная факторизация недостаточна.
5. **Distance-based, Metric Learning**:
    - Фокусируется на уменьшении расстояния между пользователем и релевантным элементом в латентном пространстве.
    - Подходит для задач, где расстояние между объектами играет важную роль.
6. **Translation-based**:
    - Моделирует отношения между пользователями и элементами как "переводы" в латентном пространстве (похоже на подходы в NLP для обработки отношений между словами).
    - Используется для задач, где нужно учитывать отношения, такие как "пользователь предпочитает элементы категории X".
7. **Probabilistic MF**:
    - Включает вероятностные подходы, такие как использование распределений (например, экспоненциальных).
    - Это добавляет уровень неопределённости в предсказания, улучшая их устойчивость к шуму.

---