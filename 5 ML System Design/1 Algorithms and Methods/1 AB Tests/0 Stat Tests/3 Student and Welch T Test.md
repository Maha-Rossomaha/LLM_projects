# T‑тесты для независимых выборок (Student & Welch)

> **Коротко:** сравниваются средние $\mu_1$ и $\mu_2$ двух **независимых** групп.
>
> - **Student’s t‑test** — когда дисперсии равны (гомоскедастичность).
> - **Welch’s t‑test** — когда дисперсии (и/или размеры выборок) отличаются. На практике **Welch — дефолт**: он надёжнее при нарушении равенства дисперсий, теряя минимум мощности при их равенстве.

---

## 1. Постановка и интуиция

Пусть есть две независимые выборки $X_{1i}$ и $X_{2j}$ размеров $n_1, n_2$ с истинными средними $\mu_1, \mu_2$ и дисперсиями $\sigma_1^2, \sigma_2^2$.

- Оценки: $\bar x_1, \bar x_2$, выборочные дисперсии: $s_1^2, s_2^2$.
- Нас интересует $\Delta = \mu_2 - \mu_1$.

**Гипотезы**\
$H_0:\ \mu_1 = \mu_2$ ($\Delta=0$);  альтернативы: двусторонняя $\mu_1 \ne \mu_2$ или односторонняя $\mu_2>\mu_1$ / $\mu_2<\mu_1$.

Интуиция: стандартизируем разность средних оценкой её стандартной ошибки. При нормальности (и других предпосылках) эта статистика имеет t‑распределение с некоторым числом степеней свободы (df).

---

## 2. Варианты t‑теста и формулы

### 2.1. Student’s t‑test (равные дисперсии)

$$
 s_p^2 = \frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2-2},\qquad
 t = \frac{\bar x_2 - \bar x_1}{s_p\,\sqrt{\tfrac{1}{n_1}+\tfrac{1}{n_2}}},\qquad
 \text{df} = n_1 + n_2 - 2.
$$

### 2.2. Welch’s t‑test (неравные дисперсии)

$$
 t = \frac{\bar x_2 - \bar x_1}{\sqrt{\tfrac{s_1^2}{n_1}+\tfrac{s_2^2}{n_2}}},\qquad
 \text{df} \approx \frac{\big(\tfrac{s_1^2}{n_1}+\tfrac{s_2^2}{n_2}\big)^2}{\tfrac{(s_1^2/n_1)^2}{n_1-1}+\tfrac{(s_2^2/n_2)^2}{n_2-1}}\quad \text{(Уэлч–Саттертуэйт)}.
$$

### 2.3. Как выбирать

- Если **заранее** уверены в гомоскедастичности и $n_1\approx n_2$ → **Student** слегка мощнее.
- Если сомневаетесь (обычно так и есть) или явный дисбаланс дисперсий/размеров → **Welch по умолчанию**.

---

## 3. Предпосылки и область применимости

**Подходит для:**

- Количественные метрики (доход, время, чек, длительность сессии и т.п.), где среднее — валидная характеристика.
- Независимые наблюдения; рандомизация по единицам анализа (обычно пользователь/просмотр/сеанс).

**Предпосылки:**

1. Независимость наблюдений **между** и **внутри** групп.
2. Приближительная нормальность распределений (t‑тест устойчив к умеренным отклонениям, особенно при $n\gtrsim 30$ в каждой группе; важна симметрия/отсутствие «тяжёлых хвостов»).
3. Для Student — **равенство дисперсий**; для Welch — не требуется.

**Когда быть осторожным:**

- Выбросы/сильно скошенные распределения (подумать о трансформациях, робастных/непараметрических тестах).
- Кластеризация/повторы на одного пользователя (нужно агрегирование по пользователю или кластер‑устойчивые ошибки).
- Задачи, где среднее — неустойчивая метрика (лучше медиана/квантиль → непараметрические/квантильные подходы).

---

## 4. Проверка предпосылок на практике

- **Визуально:** гистограммы/графики плотности, box‑plot, Q‑Q plot.
- **Равенство дисперсий:** Levene (или Brown–Forsythe). Если $p<\alpha$ → лучше Welch.
- **Нормальность:** Shapiro–Wilk, Anderson–Darling. Интерпретируйте аккуратно: при больших $n$ «любой» отход даёт значимость; важнее практическая симметрия и устойчивость к выбросам.
- **Альтернатива при явной ненормальности/сдвиге форм:** Mann–Whitney U (но он тестирует сдвиг распределений при одинаковых формах, а **не** строго равенство средних).

---

## 5. Что именно тестируем и как интерпретировать

- **Нулевая гипотеза про средние**: $\mu_1=\mu_2$.
- Сообщайте **размер эффекта** и **доверительный интервал** для $\Delta=\mu_2-\mu_1$.
- Указывайте тип теста (Student/Welch), односторонний/двусторонний, способ проверки предпосылок.

**Эффект‑сайзы**

- **Cohen’s d (Student/гомо):** $d = \tfrac{\bar x_2-\bar x_1}{s_p}$.
- **Hedges’ g (малые выборки):** $g = J(\text{df})\, d$, где $J(\text{df})=1-\tfrac{3}{4\,\text{df}-1}$.
- **Glass’s $\Delta$ (разные дисперсии):** $(\bar x_2-\bar x_1)/s_1$ — нормируем на SD «контроля».

---

## 6. Доверительные интервалы для разности средних

$t_{1-\alpha, df}$ - квантиль t-распределения - значение, такое что «справа под хвостом остаётся $\alpha/2$ площади».  
Функция для подсчета в питоне:
```знерщт
stats.t.ppf(0.975, df)
```

- **Student:**\
  $CI_{1-\alpha}:\ (\bar x_2-\bar x_1) \pm t_{1-\alpha/2,\,n_1+n_2-2}\, s_p\, \sqrt{\tfrac{1}{n_1}+\tfrac{1}{n_2}}.$

- **Welch:**\
  $CI_{1-\alpha}:\ (\bar x_2-\bar x_1) \pm t_{1-\alpha/2,\,\text{df}_{Welch}}\, \sqrt{\tfrac{s_1^2}{n_1}+\tfrac{s_2^2}{n_2}}.$

---

## 7. Планирование мощности и MDE

Для независимого t‑теста стандартный эффект — **Cohen’s d**: $d = \Delta/\sigma$. Тогда:

- Задаём $\alpha$, мощность (обычно 0.8) и целевой **MDE** в единицах $d$ → считаем $n$ на группу.
- Если есть предположение о SD в контроле/историческая $\hat\sigma$, можно перевести MDE из «реальных единиц» в $d$: $d = \text{MDE}/\hat\sigma$.

Практический совет: при сомнениях по равенству дисперсий и дисбалансу $n$ планируйте мощность как для Welch, но в инструментах обычно используют формулу для Student — это даёт близкие оценки при умеренных нарушениях.

---

## 8. Пример

```python
import numpy as np
from scipy import stats
from statsmodels.stats.power import TTestIndPower

rng = np.random.default_rng(42)

# Синтетические данные: разные дисперсии и размеры
x1 = rng.normal(loc=100, scale=15, size=800)   # контроль
x2 = rng.normal(loc=103, scale=22, size=1200)  # тест

# 1) Базовые t‑тесты
res_student = stats.ttest_ind(x2, x1, equal_var=True)
res_welch   = stats.ttest_ind(x2, x1, equal_var=False)
print("Student:", res_student)
print("Welch:  ", res_welch)

# 2) Проверка равенства дисперсий (робастная)
lev = stats.levene(x1, x2, center='median')
print("Levene p-value:", lev.pvalue)

# 3) Доверительные интервалы для разности средних
m1, m2 = np.mean(x1), np.mean(x2)
s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)
n1, n2 = len(x1), len(x2)

# Student CI
sp2 = ((n1-1)*s1 + (n2-1)*s2) / (n1 + n2 - 2)
sp  = np.sqrt(sp2)
se_student = sp * np.sqrt(1/n1 + 1/n2)
df_student = n1 + n2 - 2
tcrit_st = stats.t.ppf(0.975, df_student)
ci_student = ((m2-m1) - tcrit_st*se_student, (m2-m1) + tcrit_st*se_student)
print("CI Student (95%):", ci_student)

# Welch CI
se_welch = np.sqrt(s1/n1 + s2/n2)
df_welch = (se_welch**4) / (((s1/n1)**2)/(n1-1) + ((s2/n2)**2)/(n2-1))
tcrit_wl = stats.t.ppf(0.975, df_welch)
ci_welch = ((m2-m1) - tcrit_wl*se_welch, (m2-m1) + tcrit_wl*se_welch)
print("CI Welch   (95%):", ci_welch)

# 4) Эффект‑сайзы
sp = np.sqrt(sp2)
cohens_d = (m2 - m1) / sp
J = 1 - 3/(4*df_student - 1)  # Hedges correction
hedges_g = J * cohens_d
# Glass's Delta (нормируем на SD контроля)
glass_delta = (m2 - m1) / np.sqrt(s1)
print(f"d={cohens_d:.3f}, g={hedges_g:.3f}, GlassΔ={glass_delta:.3f}")

# 5) Power / MDE (в единицах d)
power = TTestIndPower()
# Требуемое n на группу для ожидаемого d=0.2
n_req = power.solve_power(effect_size=0.2, alpha=0.05, power=0.8, ratio=n2/n1)
print("n per group (target d=0.2):", np.ceil(n_req))

# Как получить MDE при заданных n и альфа/мощности
mde_d = power.solve_power(nobs1=n1, alpha=0.05, power=0.8, ratio=n2/n1)
print("MDE (в d единицах):", mde_d)
# Перевод MDE в «натуральные» единицы при известной scale (например, SD контроля)
MDE = mde_d * np.sqrt(s1)  # если нормируем на SD контроля
print("MDE в тех же единицах, что данные:", MDE)
```

И output
```
Student: TtestResult(statistic=2.0449580949412622, pvalue=0.040989758277334566, df=1998.0)
Welch:   TtestResult(statistic=2.211521852898595, pvalue=0.02711253892629022, df=1997.9125236843)
Levene p-value: 1.1605667656071176e-25
CI Student (95%): (0.07512001831645265, 3.59089775406264)
CI Welch   (95%): (0.2075177516316098, 3.4585000207474828)
d=0.093, g=0.093, GlassΔ=0.124
n per group (target d=0.2): 328.0
MDE (в d единицах): 0.1279356266258428
MDE в тех же единицах, что данные: 1.888940000422345
```

**Мини‑обёртка «одна кнопка»: автоматический выбор Welch/Student + отчёт**

```python
def ttest_ind_report(x1, x2, alpha=0.05, center='median'):
    import numpy as np
    from scipy import stats

    x1, x2 = np.asarray(x1), np.asarray(x2)
    n1, n2 = len(x1), len(x2)
    m1, m2 = x1.mean(), x2.mean()
    s1, s2 = x1.var(ddof=1), x2.var(ddof=1)

    # Робастная проверка равенства дисперсий
    lev_p = stats.levene(x1, x2, center=center).pvalue
    equal_var = (lev_p >= alpha)  # если не отвергаем равенство дисперсий

    # Сам тест
    t_res = stats.ttest_ind(x2, x1, equal_var=equal_var)

    # CI
    if equal_var:
        sp2 = ((n1-1)*s1 + (n2-1)*s2) / (n1 + n2 - 2)
        sp  = np.sqrt(sp2)
        se  = sp * np.sqrt(1/n1 + 1/n2)
        df  = n1 + n2 - 2
    else:
        se  = np.sqrt(s1/n1 + s2/n2)
        df  = (se**4) / (((s1/n1)**2)/(n1-1) + ((s2/n2)**2)/(n2-1))

    tcrit = stats.t.ppf(1 - alpha/2, df)
    diff  = m2 - m1
    ci    = (diff - tcrit*se, diff + tcrit*se)

    # Эффект‑сайз: d (pooled) + Hedges g
    if equal_var:
        sp = np.sqrt(((n1-1)*s1 + (n2-1)*s2)/(n1+n2-2))
        d  = diff / sp
        J  = 1 - 3/(4*(n1+n2-2) - 1)
        g  = J * d
    else:
        # При неравных дисперсиях сообщим Glass's Δ и Hedges g на pooled для полноты
        sp = np.sqrt(((n1-1)*s1 + (n2-1)*s2)/(n1+n2-2))
        d  = diff / sp
        J  = 1 - 3/(4*(n1+n2-2) - 1)
        g  = J * d
        glass_delta = diff / np.sqrt(s1)

    report = {
        'test': 'Student' if equal_var else 'Welch',
        'levene_p': lev_p,
        't_stat': float(t_res.statistic),
        'df': float(df),
        'p_value': float(t_res.pvalue),
        'mean_1': float(m1),
        'mean_2': float(m2),
        'diff_mean': float(diff),
        'ci_95': ci,
        'cohens_d': float(d),
        'hedges_g': float(g)
    }
    if not equal_var:
        report['glass_delta_controlSD'] = float(glass_delta)
    return report
```

---

## 9. Практические рекомендации по отчётности

- Ясно указывать: тип теста (Student/Welch), дву-/односторонность, $\alpha$, предпосылки и как вы их проверяли.
- Сообщать: $\bar x_1, \bar x_2$, разность, $p$-value, df, **95% CI**, и **эффект‑сайз** ($d/g$, при неравных дисперсиях — также Glass’s $\Delta$).
- При множественных сравнениях — корректировки (Holm, BH/FDR и др.).
- При явной ненормальности/выбросах — подтвердите результат робастными методами (тримированные средние, непараметрические тесты) или трансформациями (например, лог на положительных данных).

---

## 10. Когда t‑тест — не то, что нужно

- **Парные/повторные измерения** → парный t‑тест/линейные смешанные модели.
- **Категориальные бинарные метрики** → тесты для долей (две доли, Фишер, биномиальный).
- **Медианы/квантили** → непараметрические или квантильные методы.
- **Сильная кластеризация/иерархии** → иерархические модели, кластер‑робастные ошибки.