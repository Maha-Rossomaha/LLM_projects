# Бутстрап и перестановочные тесты

> **Идея:** избавиться от жёстких предположений о распределении (нормальность, равенство дисперсий и т.п.) и оценивать неопределённость/значимость **непараметрически**, переиспользуя исходные данные.
>
> - **Бутстрап:** переотбор с возвращением, оценка распределения статистики (среднее, медиана, разность средних, коэффициенты и т.п.).
> - **Перестановочные тесты:** случайно перемешиваем ярлыки групп, чтобы получить нулевое распределение статистики при гипотезе «эффекта нет».
> - Удобно в A/B‑тестах, когда: метрика тяжёлая (выбросы, асимметрия), сложная (медианы, квантильные метрики, CTR, ratio), модельная (произвольный скрипт считает метрику по данным).

---

## 1. Бутстрап: базовая идея

### 1.1. Постановка

Пусть у нас есть выборка $X_1, \dots, X_n$ из неизвестного распределения. Хотим оценить распределение некоторой статистики $T = T(X_1, \dots, X_n)$:

- среднее, медиана,
- разность средних между A и B,
- коэффициент регрессии,
- любая «чёрная коробка», которую можно посчитать по данным.

Классические формулы доверительных интервалов и стандартных ошибок часто опираются на **асимптотику** и нормальность. Бутстрап предлагает более прямой путь:

> Используем **эмпирическое распределение** данных как приближение к настоящему, и моделируем «переизвлечение выборок» из него.

### 1.2. Алгоритм нестрогий, но честный

1. Из исходной выборки $X_1, \dots, X_n$ строим **эмпирическое распределение** $\hat F_n$:
   - оно просто говорит: каждая точка имеет вес $1/n$.
2. Дальше $B$ раз (например, B = 1000):
   - генерируем бутстрап‑выборку $X_1^*, \dots, X_n^*$, выбирая **с возвращением** n наблюдений из $\{X_i\}$;
   - считаем статистику $T^* = T(X_1^*, \dots, X_n^*)$.
3. Получаем выборку $T_1^*, \dots, T_B^*$ — это **бутстрап‑распределение** статистики.

Дальше из него можно брать:

- оценку стандартной ошибки: $\widehat{SE}(T) \approx \text{sd}(T_1^*, \dots, T_B^*)$,
- доверительные интервалы (percentile, BCa и т.п.),
- эмпирическое распределение для построения тестов.

### 1.3. Интуитивная интерпретация

- Мы не знаем настоящее распределение $F$, но думаем, что **наша выборка его неплохо отражает**.
- Поэтому используем выборку как «мини‑модель мира» и смотрим, как бы менялась статистика, если бы мы много раз переизвлекали такие же данные.

---

## 2. Бутстрап‑доверительные интервалы

Пусть хотим 95% доверительный интервал для статистики $T$.

Базовая схема через **percentile bootstrap**:

1. Строим бутстрап‑распределение $T_1^*, \dots, T_B^*$.
2. Берём 2.5‑й и 97.5‑й процентили этой выборки.

Получаем:

$$
CI_{0.95}^{\text{perc}} = [\hat T_{0.025}^*,\ \hat T_{0.975}^*].
$$

Где $\hat T_{p}^*$ — эмпирический p‑квантиль из бутстрап‑значений.

Есть и более продвинутые варианты (BC, BCa, studentized bootstrap), но для понимания концепции достаточно percentile‑подхода.

---

## 3. Бутстрап в A/B‑тестах

### 3.1. Разность средних/медиан

Пусть есть две группы A и B, метрика — чек $X$ (тяжёлые хвосты, выбросы). Хотим оценить распределение $\Delta = \mu_B - \mu_A$ или разности медиан.

Проще всего:

1. Выделяем данные по группам: $\{X_i^A\}_{i=1}^{n_A}, \{X_j^B\}_{j=1}^{n_B}$.
2. На каждом шаге бутстрапа:
   - бутстрапим **внутри каждой группы отдельно**:
     - тянем $n_A$ наблюдений с возвращением из A,
     - $n_B$ — из B;
   - считаем $\Delta^* = T^*(B) - T^*(A)$ (где T — средняя или медиана и т.п.).
3. Получаем бутстрап‑распределение $\Delta^*$.
4. Смотрим на:
   - доверительный интервал для $\Delta$,
   - вероятность $P(\Delta > 0)$ по бутстрап‑распределению.

Это удобно, когда:

- метрика далека от нормальности,
- не хочется полагаться на t‑тест и CLT,
- интересуют медианы/квантили, а не средние.

### 3.2. Сложные метрики

Бутстрап особенно полезен, когда метрика:

- CTR = клики / показы,
- ARPU = выручка / пользователь,
- retention по когортам,
- любая функция от выборки, которую сложно «ручками» проанализировать.

Тогда **софт** просто переобучает твою метрику на бутстрап‑выборках и строит эмпирическое распределение.

---

## 4. Перестановочные тесты: идея

Перестановочный тест — это способ построить **распределение статистики при H₀**, не придумывая модель.

### 4.1. H₀ в виде «переменная группы ничего не меняет»

Пусть:

- есть метрика $Y$ и разметка по группам (A/B/...);
- H₀: распределения метрики во всех группах одинаковые;
- H₁: хотя бы в одной группе отличается.

Ключевая идея:

> Если H₀ верна, то **метка группы — это просто случайный ярлык**, который можно свободно переставлять между наблюдениями.

### 4.2. Общий алгоритм перестановочного теста

1. Считаем «наблюдаемую» статистику $T_{obs}$ по исходным группам:

   - разность средних $\bar Y_B - \bar Y_A$,
   - статистика t‑теста,
   - разность медиан, Gini uplift, AUC — что угодно.

2. Под H₀:

   - перемешиваем метки групп (переставляем ярлыки A/B/...),
   - рассчитываем статистику для этой случайной перестановки: $T^{(b)}$.

3. Повторяем шаг 2 B раз (например, B = 10 000), получаем $T^{(1)}, \dots, T^{(B)}$ — **перестановочное распределение** статистики при H₀.

4. Оцениваем p‑value как долю перестановок, где статистика не менее экстремальна, чем наблюдаемая:

- односторонний тест:

  $$
  p \approx \frac{\#\{b: T^{(b)} \ge T_{obs}\} + 1}{B + 1},
  $$

- двусторонний — через $|T^{(b)}| \ge |T_{obs}|$ или симметричную конструкцию.

Перестановочный тест **по смыслу**: «если бы эффекта не было, насколько маловероятно увидеть такой T, как у нас, чисто из-за случайного распределения ярлыков по данным?»

---

## 5. Отличия бутстрапа и перестановочного теста

Важно не путать:

- **Бутстрап**:

  - моделирует **распределение статистики вокруг «истинного» значения**;
  - исходные группы фиксированы, мы переотбираем наблюдения **внутри них**;
  - чаще используется для доверительных интервалов и стандартных ошибок.

- **Перестановочный тест**:

  - моделирует **распределение статистики при H₀**, когда группа не влияет;
  - ярлыки групп переставляем между всеми наблюдениями;
  - используется именно как замена параметрическим тестам (t‑тест, Манна–Уитни и т.п.).

Оба подхода непараметрические, но отвечают на слегка разные вопросы.

---

## 6. Перестановочные тесты в A/B‑тестировании

### 6.1. Для средних/медиан

Схема для 2 групп A и B:

1. Считаем наблюдаемую статистику, например: $T_{obs} = \bar Y_B - \bar Y_A$.

2. Клеим все данные в один массив, отдельно массив ярлыков групп.

3. B раз:

   - случайно перемешиваем ярлыки;
   - делим данные по новым группам;
   - считаем $T^{(b)}$.

4. p‑value — доля $T^{(b)}$, не менее экстремальных, чем $T_{obs}$.

Плюсы:

- работает с любыми распределениями метрики,
- можно использовать любую разумную статистику: медианы, квантильные метрики, функции потерь.

Минусы:

- дороже по вычислениям (нужно много перестановок),
- по сути «переиспользует» ту же выборку, поэтому при малых n p‑value принимает дискретные значения.

### 6.2. Для сложных метрик

Перестановочный тест особенно полезен, когда:

- метрика = результат сложного пайплайна (модель, скор, кастомный KPI),
- параметрические допущения неочевидны,
- классические формулы для стандартной ошибки/распределения статистики жалко выводить.

Тогда перестановочный тест даёт честное *эмпирическое* нулевое распределение.

---

## 7. Численный мини‑пример (перестановочный тест для разности средних)

Пусть у нас игрушечный A/B тест:

- A: [10, 11, 9, 12]
- B: [13, 14, 15, 12]

Наблюдаемая статистика:

- $\bar Y_A = 10.5$,
- $\bar Y_B = 13.5$,
- $T_{obs} = 13.5 - 10.5 = 3.0$.

Перестановочный тест:

1. Объединяем данные: [10, 11, 9, 12, 13, 14, 15, 12].
2. Случайно перемешиваем и разбиваем на две группы по 4 элемента.
3. Считаем разность средних $T^{(b)}$.
4. Смотрим, как часто разность средних ≥ 3.0 по модулю.

Если таких перестановок мало (например, 5 из 10 000), получаем p‑value ≈ 0.0005.

---

## 8. Примеры на Python

### 8.1. Простой бутстрап‑CI для разности средних в A/B

```python
import numpy as np

rng = np.random.default_rng(42)

A = np.array([10, 11, 9, 12, 8, 15, 7])
B = np.array([13, 14, 15, 12, 16, 11, 18])

n_A, n_B = len(A), len(B)
B_iter = 10_000

deltas = []
for _ in range(B_iter):
    # бутстрап отдельно по группам
    sample_A = rng.choice(A, size=n_A, replace=True)
    sample_B = rng.choice(B, size=n_B, replace=True)
    deltas.append(sample_B.mean() - sample_A.mean())

deltas = np.array(deltas)

# оценка эффекта и бутстрап-CI
point_est = B.mean() - A.mean()
ci_low, ci_high = np.percentile(deltas, [2.5, 97.5])

print(f"Оценка эффекта: {point_est:.3f}")
print(f"95% бутстрап-CI: [{ci_low:.3f}, {ci_high:.3f}]")
```

### 8.2. Перестановочный тест для разности средних

```python
import numpy as np

rng = np.random.default_rng(42)

A = np.array([10, 11, 9, 12])
B = np.array([13, 14, 15, 12])

obs_diff = B.mean() - A.mean()

all_values = np.concatenate([A, B])
labels = np.array([0] * len(A) + [1] * len(B))

B_iter = 50_000
perm_diffs = []

for _ in range(B_iter):
    perm = rng.permutation(labels)
    group_A = all_values[perm == 0]
    group_B = all_values[perm == 1]
    perm_diffs.append(group_B.mean() - group_A.mean())

perm_diffs = np.array(perm_diffs)

# двусторонний p-value
p_value = ((np.abs(perm_diffs) >= abs(obs_diff)).sum() + 1) / (B_iter + 1)

print(f"Наблюдаемая разность средних: {obs_diff:.3f}")
print(f"Перестановочный p-value: {p_value:.5f}")
```

---

## 9. Что писать в отчёте

### 9.1. Для бутстрапа

Минимальный набор:

- что именно бутстрапили:
  > Использован бутстрап по пользователям внутри каждой группы (B = 10 000 переотборов).
- какая статистика:
  > Строился бутстрап‑распределение разности средних/медиан.
- итог:
  > Оценка эффекта, бутстрап‑CI, при желании — бутстрап‑p-value.

Пример формулировки:

> «Для оценки разности средних чеков между вариантами B и A был использован бутстрап (10 000 переотборов по пользователям в каждой группе). Точечная оценка эффекта составила 120 ₽, 95% бутстрап‑доверительный интервал: [80 ₽; 160 ₽]. Интервал не включает 0, что указывает на статистически значимое увеличение среднего чека в варианте B.»

### 9.2. Для перестановочного теста

- чётко сформулировать нулевую гипотезу:
  > H₀: распределение метрики одинаково во всех группах (метка группы не влияет на метрику).
- описать, какие ярлыки переставлялись и сколько раз (B):
  > Использовано 50 000 случайных перестановок меток групп.
- указать статистику и полученный p-value.

Пример:

> «Для проверки эффекта варианта B на средний чек использован перестановочный тест: в нулевой гипотезе предполагалось, что метка группы не влияет на распределение чека. В 50 000 случайных перестановках меток групп разность средних была не менее экстремальной, чем наблюдаемая (Δ = 120 ₽), в 0.4% случаев, что даёт p ≈ 0.004. Таким образом, нулевая гипотеза отвергается на уровне 0.01.»

