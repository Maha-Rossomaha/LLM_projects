# Непараметрические тесты: критерий Манна–Уитни (U‑test)

> **Коротко:** сравниваются **распределения** двух независимых групп по порядку значений.
>
> - Не требует нормальности, работает по **рангам**, устойчив к выбросам.
> - В A/B‑тестах полезен, когда метрика кривая: тяжёлые хвосты, выбросы, сильная асимметрия.
> - Тестирует *сдвиг распределений* (стохастическое доминирование), а не строго «равенство средних».

---

## 1. Постановка задачи и интуиция

Есть две независимые выборки:

- группа A: $X_{1}, \dots, X_{n_1}$,
- группа B: $Y_{1}, \dots, Y_{n_2}$.

Нас интересует, «не больше ли» значения в B, чем в A (или вообще «отличаются ли распределения»).

**Гипотезы (двусторонний тест):**
$$
H_0: F_X(t) = F_Y(t) \text{ для всех } t \ \text{(распределения\ совпадают)}\\
H_1: F_X(t) \neq F_Y(t) \text{\ хотя\ бы\ для\ некоторых\ } t.
$$

Интуиция: 

1. Склеиваем обе выборки в одну, сортируем и заменяем значения **рангами**: 1, 2, 3, ...
2. Считаем, какие в среднем ранги у группы A и у группы B.
3. Если распределения одинаковые, ранги перемешаны, как при случайной тасовке. 
4. Если B «сдвинута вправо» (значения больше), то её ранги систематически **выше**.

Манна–Уитни смотрит, насколько фактическая «сумма рангов» отличается от того, что было бы при полной случайности.

---

## 2. Определение статистики U

Пусть:

- $n_1$ — размер выборки A,
- $n_2$ — размер выборки B,
- после ранжирования по возрастанию посчитали сумму рангов для группы A: $R_1$, для B: $R_2$.

Тогда определяются статистики:
$$
U_1 = n_1 n_2 + \frac{n_1(n_1+1)}{2} - R_1, \\
U_2 = n_1 n_2 + \frac{n_2(n_2+1)}{2} - R_2.
$$

Обычно берут одну из них или
$$
U = \min(U_1, U_2)
$$
для двустороннего теста.

**Эквивалентная интерпретация:**

$U_1$ можно понимать как число пар $(x_i, y_j)$, для которых $x_i > y_j$, плюс половина числа пар с равенством. То есть U измеряет, насколько часто значения одной группы «больше» другой.

---

## 3. Распределение U при H₀

При верной нулевой гипотезе (распределения совпадают):

- математическое ожидание:
  $$
  \mathbb E[U] = \frac{n_1 n_2}{2},
  $$
- дисперсия (без учёта связок):
  $$
  \mathbb Var(U) = \frac{n_1 n_2 (n_1 + n_2 + 1)}{12}.
  $$

При достаточно больших $n_1, n_2$ статистику можно аппроксимировать нормальной:
$$
Z = \frac{U - \mathbb E[U]}{\sqrt{\mathbb Var(U)}} \approx N(0, 1).
$$

Для малых выборок используются точные таблицы/точное распределение (в `scipy` это опция `method="exact"`).

**Связки (ties):** при наличии одинаковых значений дисперсия корректируется, но большинство библиотек делает это автоматически.

---

## 4. Предпосылки и область применимости

### 4.1. Что требуется

1. **Независимость наблюдений** внутри и между группами.
2. **Порядковая шкала минимум.** Значения можно сравнивать по «больше/меньше». Не нужны реальные интервалы, но нужна упорядоченность.
3. Для классического вывода про «сдвиг распределения» предполагается, что формы распределений примерно одинаковы, отличие в основном в сдвиге (позиции).

### 4.2. Когда полезен

- Метрика с **тяжёлыми хвостами**: время отклика, время сессии, деньги на пользователя, количество действий.
- Много выбросов, лог‑нормальные / степенные хвосты.
- Нам больше важен **сдвиг типичных значений** (медиана, большинство), а не среднее, которое может улетать из‑за пары аномальных наблюдений.

### 4.3. Когда лучше не использовать

- Бизнес‑вопрос сформулирован именно про **среднее значение** (средний доход, средний чек). Тогда t‑тест логичнее, даже при ненормальности (или с трансформацией).
- Сильное различие в форме распределений между группами (не только сдвиг, но и разный хвост, мультимодальность). Тогда интерпретация Манна–Уитни как «чистого сдвига» ломается.

---

## 5. Что именно проверяет критерий Манна–Уитни

Классический результат:

$$
U_1 = \sum_{i=1}^{n_1} \sum_{j=1}^{n_2} \Big( \mathbb 1[X_i > Y_j] + \tfrac{1}{2} \mathbb 1[X_i = Y_j] \Big).
$$
т. е. если $X_i > Y_j$, то в сумму идет 1, если $X_i = Y_j$, то 0.5.
> $U_1$ = сколько раз X выигрывает у Y по всем парам, плюс половина ничьих.

Если обозначить
$$
\theta = P(X > Y) + \tfrac{1}{2} P(X = Y),
$$

т. е. $\theta$ - "средний результат игры X против Y", где победа X = 1, поражение = 0, ничья = 0.5.  
Тогда **ожидаемое значение U** пропорционально $\theta$:
$$
\mathbb E[U_1] = n_1 n_2 \theta.
$$

- При **H₀**: $\theta = 0.5$, т.е. обе группы «выигрывают» друг у друга одинаково часто.
- При $\theta > 0.5$: значения X чаще больше Y (или наоборот, в зависимости от того, какую группу мы обозначили как X/Y).

Поэтому можно говорить, что Манна–Уитни фактически тестирует
$$
H_0: P(X>Y) = P(Y>X),
$$
а при равенстве форм распределений это эквивалентно «нет сдвига медианы».

**Важно:** критерий *не* тестирует напрямую $\mu_X = \mu_Y$. Он чувствителен к любому изменению порядка значений, а не только к изменению средних.

---

## 6. Mann–Whitney в A/B‑тестировании

### 6.1. Плюсы

- Не требует нормальности.
- Устойчив к выбросам и длинным хвостам.
- Работает на **сырых данных** без лог‑преобразований.
- Часто более мощный, чем t‑тест, когда распределения сильно нессиметричны.

### 6.2. Минусы

- Отвечает не на вопрос «равны ли средние», а на вопрос про **стохастическое доминирование** / сдвиг распределений.
- Интерпретация для бизнеса менее привычна: надо объяснять не «средний чек вырос на X», а «вероятность, что пользователь из B тратит больше, чем из A, равна ~0.56».
- Для сложных метрик (agg по пользователю, взвешенные показатели) иногда проще остаться в параметрической логике.

### 6.3. Практический рецепт

- Если **метрика примерно нормальная или большой n** → Welch t‑test как дефолт.
- Если распределение **жёстко скошенное**, с кучей нулей и редкими огромными значениями → 
  - либо лог‑трансформация + t‑тест,
  - либо критерий Манна–Уитни как основной, а средние анализировать дополнительно/вторично.

---

## 7. Эффект‑сайз для Манна–Уитни

Чтобы не ограничиваться только p‑value, удобно вводить **рангово‑бисериальную корреляцию**:

$$
r_{rb} = 2\theta - 1 = 2\frac{U}{n_1 n_2} - 1,
$$

где U берём так, чтобы он соответствовал «победе» тестовой группы над контрольной.

Интерпретация:

- $r_{rb} = 0$ → распределения не отличаются (в терминах шансов «кто больше»).
- $r_{rb} = 0.2$ → вероятность, что значение у B больше, чем у A, примерно 0.6.
- По смыслу похоже на корреляцию: $|r_{rb}| \le 1$.

Часто также используют **delta Клиффа**:
$$
\Delta_C = P(X>Y) - P(X<Y),
$$
которая по сути то же самое (альтернативная нормировка того же $\theta$).

---

## 8. Небольшой численный пример

Пусть у нас есть конверсия по доходу (условные цифры за пользователя):

- A: [10, 12, 13, 15, 100]  (один жёсткий выброс)
- B: [11, 14, 15, 16, 18]

По средним:

- $\bar x_A = 30$
- $\bar x_B = 14.8$

Среднее у A «выше» за счёт одного ненормального юзера, хотя по большинству наблюдений B выглядит лучше.

Манна–Уитни по сути скажет: значения B чаще **больше**, чем A, несмотря на выброс в A.

Ручной расчёт:

1. Пишем все числа в порядке возрастания, отмечаем, из какой группы каждое.
2. Назначаем ранги 1..10.
3. Суммируем ранги для A и для B, считаем U.
4. Сравниваем с ожидаемым при $H_0$, получаем p‑value.

---

## 9. Пример на Python (scipy)

Используем `scipy.stats.mannwhitneyu`. Для современных версий обязательно указывать `alternative` и желательно `method`.

```python
import numpy as np
from scipy import stats

# Данные из примера выше
A = np.array([10, 12, 13, 15, 100])
B = np.array([11, 14, 15, 16, 18])

# Двусторонний тест (проверяем просто "отличаются ли")
res_two_sided = stats.mannwhitneyu(A, B, alternative="two-sided", method="exact")
print(res_two_sided)

# Односторонний тест: H1 "B > A" (значения в B стягиваются вправо)
res_greater = stats.mannwhitneyu(A, B, alternative="less", method="exact")
# В scipy аргумент "less" означает P(X < Y) больше, чем при H0,
# поэтому, если мы хотим проверять "B > A", передаём (A, B) и alternative="less".
print(res_greater)

# Посчитаем эффект‑сайз (рангово‑бисериальный)
U = res_two_sided.statistic
n1, n2 = len(A), len(B)
rank_biserial = 2 * U / (n1 * n2) - 1
print("Rank-biserial correlation:", rank_biserial)
```

Типичный вывод будет примерно такого вида:

```text
MannwhitneyuResult(statistic=9.5, pvalue=0.6904761904761905)
MannwhitneyuResult(statistic=9.5, pvalue=0.34523809523809523)
Rank-biserial correlation: -0.24
```

В этом примере критерий Манна–Уитни даёт U = 9.5, двухстороннее $p \approx 0.69$ и одностороннее $p \approx 0.35$, поэтому статистически значимых различий между группами нет. При этом рангово-бисериальная корреляция $r_{rb} \approx 0.24$ по модулю соответствует небольшому/умеренному сдвигу распределений в пользу второй группы, но на таком малом объёме выборки мощности теста недостаточно, чтобы надёжно подтвердить этот эффект.

---

## 10. Bootstrap для интервала разности медиан (дополнительно)

Манна–Уитни сам по себе не даёт доверительный интервал для «разности медиан». Если хочется именно интервал для медиан A и B, практично использовать бутстрап.

Пример (для A/B‑теста):

```python
import numpy as np
from scipy import stats

rng = np.random.default_rng(42)

# Пусть у нас есть произвольные тяжелохвостые данные
A = rng.lognormal(mean=2.5, sigma=1.0, size=2000)  # контроль
B = rng.lognormal(mean=2.6, sigma=1.0, size=2200)  # тест

# 1) Mann-Whitney U-test
res = stats.mannwhitneyu(A, B, alternative="two-sided", method="asymptotic")
print("U-statistic:", res.statistic, "p-value:", res.pvalue)

# 2) Бутстрап для CI по разности медиан (B - A)

def bootstrap_median_diff(x, y, n_boot=5000):
    rng = np.random.default_rng(0)
    diffs = []
    n1, n2 = len(x), len(y)
    for _ in range(n_boot):
        sample_x = x[rng.integers(0, n1, n1)]
        sample_y = y[rng.integers(0, n2, n2)]
        diffs.append(np.median(sample_y) - np.median(sample_x))
    diffs = np.sort(diffs)
    # 95% перцентильный интервал
    lower = np.percentile(diffs, 2.5)
    upper = np.percentile(diffs, 97.5)
    return float(lower), float(upper)

ci_med = bootstrap_median_diff(A, B)
print("95% CI для разности медиан (B - A):", ci_med)

# Для отчёта также полезно вывести медианы
print("median A =", float(np.median(A)))
print("median B =", float(np.median(B)))
```

Такой подход комбинирует:

- U‑тест как строгий непараметрический критерий «распределения отличаются»,
- бутстрап-интервал, дающий бизнес‑интерпретацию в единицах исходной метрики (медиана).

---

## 11. Мини‑обёртка для отчёта по A/B‑тесту

```python
from dataclasses import dataclass
from typing import Tuple
import numpy as np
from scipy import stats

@dataclass
class MWUReport:
    test: str
    n1: int
    n2: int
    U: float
    p_value: float
    alternative: str
    rank_biserial: float
    median_1: float
    median_2: float
    median_diff_ci: Tuple[float, float]


def mann_whitney_report(x, y, alternative="two-sided", n_boot=3000) -> MWUReport:
    x = np.asarray(x)
    y = np.asarray(y)
    n1, n2 = len(x), len(y)

    # Сам тест
    method = "asymptotic" if max(n1, n2) > 20 else "exact"
    res = stats.mannwhitneyu(x, y, alternative=alternative, method=method)
    U = float(res.statistic)

    # Эффект‑сайз
    rank_biserial = 2 * U / (n1 * n2) - 1

    # Бутстрап для CI по разности медиан (y - x)
    rng = np.random.default_rng(0)
    diffs = []
    for _ in range(n_boot):
        sample_x = x[rng.integers(0, n1, n1)]
        sample_y = y[rng.integers(0, n2, n2)]
        diffs.append(np.median(sample_y) - np.median(sample_x))
    diffs = np.sort(diffs)
    lower = float(np.percentile(diffs, 2.5))
    upper = float(np.percentile(diffs, 97.5))

    return MWUReport(
        test="Mann-Whitney U",
        n1=n1,
        n2=n2,
        U=U,
        p_value=float(res.pvalue),
        alternative=alternative,
        rank_biserial=float(rank_biserial),
        median_1=float(np.median(x)),
        median_2=float(np.median(y)),
        median_diff_ci=(lower, upper),
    )
```

Такую функцию можно использовать в пайплайне A/B‑аналитики как непараметрический аналог t‑теста для метрик с тяжёлыми хвостами.

---

## 12. Что писать в отчёте

Для прозрачности в A/B‑отчёте по Манна–Уитни имеет смысл указывать:

- тип теста: «непараметрический критерий Манна–Уитни (двусторонний/односторонний)»;
- $n_1, n_2$, U‑статистику, p‑value;
- эффект‑сайз: рангово‑бисериальная корреляция (или delta Клиффа);
- медианы групп и 95% CI для разности медиан (если считали бутстрап);
- комментарий в человекочитаемом виде: 
  > «Вероятность, что случайный пользователь из теста имеет метрику выше, чем случайный пользователь из контроля, составляет примерно X%».

И не забывать проговаривать, что это тест про **распределения и порядок значений**, а не про «строго среднее». Для бизнес‑решений это приходится объяснять отдельно.