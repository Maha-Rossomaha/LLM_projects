# Fisher’s Exact Test (Точный тест Фишера)

## 1. Постановка и интуиция

Пусть есть две независимые группы (A и B) и бинарный исход (успех/неуспех). Наблюдаем таблицу 2×2:

|           | Успех | Неуспех | Сумма |
| --------- | ----- | ------- | ----- |
| **A**     | a     | b       | a+b   |
| **B**     | c     | d       | c+d   |
| **Сумма** | a+c   | b+d     | n     |

- Оценки долей: $\hat p_A=a/(a+b)$, $\hat p_B=c/(c+d)$.
- Нулевая гипотеза $H_0$: **нет различий** между истинными долями ($p_A=p_B$), эквивалентно **независимости** строки и столбца.

**Идея.**  
Пусть общее количество успехов и общий размер групп уже зафиксированы — то есть мы знаем, сколько всего было успехов (a+c) и сколько человек было в каждой группе (a+b и c+d). Тогда остаётся лишь вопрос: **сколько из этих успехов случайно окажется в группе A**, если успехи распределяются случайным образом между всеми участниками?  

Число успехов в A (a) в этом случае подчиняется гипергеометрическому распределению: мы как бы «вытаскиваем» успехи из общей «урны» без возвращения.  

Fisher’s exact test проверяет, насколько наблюдаемое число успехов в A кажется необычным по сравнению с тем, что могло бы получиться при полном равенстве групп (то есть при H₀). 

---

## 2. Математика: гипергеометрия и p‑value

### 2.1. Вероятность конкретной таблицы (при фиксированных суммах)

Рассматриваем случайную величину $A$ — число успехов в группе A, при известных суммах $a+b$, $c+d$, $a+c$, $b+d$:

$$
P(A=a) = \frac{\binom{a+b}{a}\,\binom{c+d}{c}}{\binom{n}{a+c}}
\;=\; \frac{\binom{a+b}{a}\,\binom{c+d}{a+c-a}}{\binom{n}{a+c}}
$$

Эквивалентно: $A \sim \text{Hypergeom}(N=n, K=a+c, \text{draws}=a+b)$.

### 2.2. Односторонний и двусторонний тест

- **Односторонний** (например, $H_1: p_B>p_A$): суммируем вероятности всех таблиц с $A\le a_{obs}$ (если в A наблюдаем меньше успехов, чем ожидалось).
- **Двусторонний**: суммируем вероятности таблиц, **не менее «экстремальных»** по отношению к наблюдаемой. На практике используют правило: $p_{2\text{-sided}} = \sum_{t:\; P(t)\le P(t_{obs})} P(t)$ (Есть альтернативы — «двойной односторонний», методы Бошлоу/Клаппера–Пирсона. Реализации в ПО могут слегка различаться.)

> Замечание: «точность» теста означает отсутствие асимптотических приближений. Он консервативен: фактическое FWER \le \alpha.

---

## 3. Когда применять в A/B‑контексте

**Подходит:**

- Малые выборки (десятки/сотни наблюдений) или редкие события (ячейки с малыми ожиданиями, в т.ч. нули).
- Ранние этапы тестов, узкие сегменты, e‑mail/Push‑кампании с низким CTR, медицинские/биоэксперименты.
- Когда опасно доверять нормальным/χ²‑аппроксимациям.

**Не идеален:**

- При больших объёмах данных (тысячи+ на ячейку) обычно достаточно двухпропорционного Z‑теста — он быстрее и даёт очень близкие результаты.
- При кластеризации/зависимостях (пользовательские группы, сессии) — нужен учёт дизайна (кластер‑SE, иерархические модели); Fisher этого не учитывает.

---

## 4. Интерпретация результата

- Возвращает **p‑value**; если $p<\alpha$ — отвергаем $H_0$ (доли различаются).
- Часто вместе с тестом дают **отношение шансов (OR)** и **точные доверительные интервалы** для OR: $\text{OR} = \frac{ad}{bc}$ (интервалы строят «условно‑точным» способом; в пакете могут называться *exact* CI).
- Имей в виду: при очень малых $n$ тест **маломощен** (требует больших эффектов, чтобы достичь значимости).

---

## 5. Числовой пример (без кода)

Пусть A: 1 успех из 10, B: 6 успехов из 10.

Таблица:

|           | Успех | Неуспех | Итого |
| --------- | ----- | ------- | ----- |
| **A**     | 1     | 9       | 10    |
| **B**     | 6     | 4       | 10    |
| **Итого** | 7     | 13      | 20    |

Фиксируем суммы. Тогда $A\sim\text{Hypergeom}(N=20, K=7, n=10)$. Считаем вероятности для «левых хвостов» (мало успехов в A):

$$
P(A=1) = \frac{\binom{7}{1}\binom{13}{9}}{\binom{20}{10}} = \frac{7\cdot 715}{184\,756} \approx 0.0271\\
P(A=0) = \frac{\binom{7}{0}\binom{13}{10}}{\binom{20}{10}} = \frac{1\cdot 286}{184\,756} \approx 0.00155
$$

- **Односторонний** $H_1: p_B>p_A$: $p \approx 0.00155+0.0271=0.0286$ → значимо при $\alpha=0.05$.
- **Двусторонний**: добавляем симметричные правые хвосты ($A=6$ и $A=7$ дают те же вероятности 0.0271 и 0.00155), итого $p_{2\text{-sided}} \approx 2\times(0.00155+0.0271) = 0.0573,$ что **чуть выше** 0.05 (на грани значимости).

Так получаем классическую «граничную» ситуацию: односторонний значим, двусторонний — нет.

---

## 6. Практические заметки

- **Выбор одностороннего/двустороннего** фиксируйте **до** запуска; двусторонний — дефолт.
- При множественных сегментах/метриках используйте корректировки (Bonferroni/Holm, BH‑FDR) или двухэтапные дизайны.
- В отчёте показывайте: таблицу 2×2, $p$‑value, OR с точным CI, а также абсолютную/относительную разницу долей.
- Иногда применяют **mid‑p коррекцию** (уменьшает консерватизм): $p_{mid} = p_{exact} - 0.5\cdot P(t_{obs})$.

---

## 7. Связь с другими тестами

- При больших $n$ Fisher и Z‑тест для долей дают очень близкие выводы (различия — в районе округлений).
- Fisher «точный», но может быть консервативным; Z‑тест — быстрый и удобный для power/MDE‑планирования.
- Для нескольких групп (>2) используйте χ²‑тест независимости или точные многомерные процедуры (реже в продакте).

---

## 8. Пример

В `scipy.stats.fisher_exact` возвращается OR и p‑value (по умолчанию — двусторонний):

```python
import numpy as np
from scipy.stats import fisher_exact
from statsmodels.stats.contingency_tables import Table2x2

# Данные A/B: успехи и неуспехи (малые n / редкие события)
# Таблица 2×2 в формате:
#       success  fail
#  A:     a       b
#  B:     c       d
a, b = 1, 9   # A: 1 успех, 9 неуспехов
c, d = 6, 4   # B: 6 успехов, 4 неуспеха

T = np.array([[a, b],
              [c, d]])

# 1) Fisher’s exact: OR и p-value
# alternative='two-sided' — двусторонний (дефолт), 'less'/'greater' — односторонние
or_hat, p_two = fisher_exact(T, alternative='two-sided')
_, p_less     = fisher_exact(T, alternative='less')     # H1: p_A < p_B
_, p_greater  = fisher_exact(T, alternative='greater')  # H1: p_A > p_B

# 2) Оценки долей и простые эффекты
n1, n2 = a + b, c + d
p1_hat, p2_hat = a / n1, c / n2
diff_abs = p2_hat - p1_hat
rel_lift = diff_abs / p1_hat if p1_hat > 0 else np.inf

# 3) Точные доверительные интервалы (OR, RR) через statsmodels
tab = Table2x2(T)
or_ci_lo, or_ci_hi = tab.oddsratio_confint(method='exact')  # точный CI для OR
rr_hat             = tab.riskratio
rr_ci_lo, rr_ci_hi = tab.riskratio_confint()                # CI для RR (метод зависит от реализации)

# 4) Вывод
print(f"A: {a}/{n1} = {p1_hat:.3f};  B: {c}/{n2} = {p2_hat:.3f}")
print(f"Absolute diff = {diff_abs:.3f}; Relative lift = {rel_lift*100:.2f}%")
print(f"Fisher two-sided p-value = {p_two:.4f} | one-sided: less={p_less:.4f}, greater={p_greater:.4f}")
print(f"Odds Ratio (OR) = {or_hat:.3f} with exact CI [{or_ci_lo:.3f}, {or_ci_hi:.3f}]")
print(f"Risk Ratio (RR) = {rr_hat:.3f} with CI [{rr_ci_lo:.3f}, {rr_ci_hi:.3f}]")
```

> При нулях в ячейках OR может стать 0/∞. Для устойчивой оценки иногда применяют коррекцию Халдейна–Анскомба (прибавить 0.5 к ячейкам перед расчётом OR/CI).

```python
# Опционально: Haldane–Anscombe при нулях
T_ha = T + 0.5
tab_ha = Table2x2(T_ha)
or_ha = tab_ha.oddsratio
or_ha_ci = tab_ha.oddsratio_confint(method='exact')
print(f"HA-corrected OR = {or_ha:.3f} with exact CI [{or_ha_ci[0]:.3f}, {or_ha_ci[1]:.3f}]")
```
