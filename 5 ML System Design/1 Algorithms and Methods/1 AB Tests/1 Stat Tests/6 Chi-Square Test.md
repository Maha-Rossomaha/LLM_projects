# $\chi^2$-тест (хи-квадрат) для таблиц сопряжённости

> **Идея:** проверить, связаны ли две категориальные переменные между собой, сравнив наблюдаемые частоты с теми, что ожидались бы при «полном отсутствии связи».
>
> * Для A/B-тестов с бинарной метрикой и **несколькими группами** это основной общий тест:
>   «конверсии одинаковы во всех группах или нет?».
> * Работает по таблице `группа × исход` (успех/неуспех) и даёт один p-value на всё.

---

## 1. Постановка задачи

Есть две категориальные переменные:

* строки: уровни переменной A (например, группы эксперимента: A, B, C, …),
* столбцы: уровни переменной B (например, исход: `success` / `fail`, или несколько категорий).

На выходе имеем **таблицу сопряжённости**:

$$
\begin{array}{c|cccc|c}
 & \text{col}_1 & \text{col}_2 & \dots & \text{col}_C & \text{итого по строке} \\
\hline
\text{row}_1 & O_{11} & O_{12} & \dots & O_{1C} & n_{1\cdot} \\
\text{row}_2 & O_{21} & O_{22} & \dots & O_{2C} & n_{2\cdot} \\
\vdots       & \vdots & \vdots &       & \vdots & \vdots  \\
\text{row}_R & O_{R1} & O_{R2} & \dots & O_{RC} & n_{R\cdot} \\
\hline
\text{итого по столбцу} & n_{\cdot 1} & n_{\cdot 2} & \dots & n_{\cdot C} & N
\end{array}
$$

* строки $i = 1, \dots, R$ — уровни «группы» (варианты эксперимента),
* столбцы $j = 1, \dots, C$ — уровни «исхода» (success/fail или несколько категорий),
* $O_{ij}$ — наблюдаемое число объектов в ячейке $(i,j)$,
* $n_{i\cdot} = \sum_j O_{ij}$ — всего наблюдений в строке $i$,
* $n_{\cdot j} = \sum_i O_{ij}$ — всего наблюдений в столбце $j$,
* $N = \sum_{i,j} O_{ij}$ — всего наблюдений.

### 1.1. Типичная формулировка гипотез

Для A/B/n-тестов с бинарной метрикой:

* строки — группы (варианты эксперимента),
* столбцы — исходы (`success`, `fail`).

**Нулевая гипотеза ($H_0$):**  
> **Версия 1:** Для каждого столбца $j$ доля объектов в этом столбце **одинакова во всех строках**.

Формально:

$$
H_0:\quad P(\text{col}_j \mid \text{row}_1)
= P(\text{col}_j \mid \text{row}_2)
= \dots
= P(\text{col}_j \mid \text{row}_R)
$$

для всех $j = 1,\dots,C$.

То есть структура исходов (`success/fail/...`) **не меняется от группы к группе**.

Эквивалентная запись:

$$
\exists\, \pi_1, \dots, \pi_C \ \mid\ 
P(\text{col}_j \mid \text{row}_i) = \pi_j
\quad \forall i = 1,\dots,R,\ j = 1,\dots,C,\quad
\sum_{j=1}^C \pi_j = 1.
$$

Другими словами: есть один «общий» вектор вероятностей исходов $(\pi_1, \dots, \pi_C)$, и во всех группах он один и тот же.


> **Версия 2:** Переменные «группа» и «исход» независимы.

Формально:

$$
H_0:\quad P(\text{row}_i, \text{col}_j)
= P(\text{row}_i) P(\text{col}_j)
\quad \forall i,j.
$$

Из этого сразу следует формула ожидаемых частот:

$$
E_{ij} = N \cdot P(\text{row}_i)\, P(\text{col}_j)
\approx \frac{n_{i\cdot}}{N} \cdot \frac{n_{\cdot j}}{N} \cdot N
= \frac{n_{i\cdot}\, n_{\cdot j}}{N}.
$$

**Альтернативная ($H_1$):**  

$$
H_1:\quad \exists\, i \ne i',\ \exists\, j\ \mid \ 
P(\text{col}_j \mid \text{row}_i) \neq P(\text{col}_j \mid \text{row}_{i'}).
$$

то есть:

* хотя бы в одной группе распределение по исходам **отличается** от других,
* эквивалентно: «группа» и «исход» **не независимы**.

Если сузиться до классического A/B/n с бинарной метрикой:

* столбцы: `success` / `fail`,
* для группы $i$: $p_i = P(\text{success} \mid \text{group}_i)$.

Тогда:

$$
H_0: p_1 = p_2 = \dots = p_R,
$$
$$
H_1: \exists i,i':\ p_i \neq p_{i'}.
$$

Это просто частный случай общей формулировки выше.

---

## 2. Ожидаемые частоты при $H_0$

Если предположить, что переменные независимы, то:

$$
P(\text{row}_i, \text{col}_j) = P(\text{row}_i) P(\text{col}_j).
$$

Оценки этих вероятностей из данных:

$$
\hat P(\text{row}_i) = \frac{n_{i\cdot}}{N}, \quad
\hat P(\text{col}_j) = \frac{n_{\cdot j}}{N}.
$$


Тогда **ожидаемое количество** наблюдений в ячейке (i, j) при $H_0$:

$$
E_{ij} = \frac{n_{i\cdot} , n_{\cdot j}}{N}.
$$

Интерпретация:

> Если бы переменные были независимы, то частота в ячейке $\approx$ «доля строки»  $\times$  «доля столбца»  $\times$  общее N.

---

## 3. Статистика $\chi^2$

Классическая статистика:

$$
\chi^2 = \sum_{i=1}^R \sum_{j=1}^C \frac{(O_{ij} - E_{ij})^2}{E_{ij}}.
$$

Смысл:

* смотрим, **насколько далеко** наблюдаемые частоты $O_{ij}$ от ожидаемых $E_{ij}$,
* каждое отклонение нормируем на ожидание (чтобы большие группы не доминировали просто из-за масштаба),
* суммируем по всем ячейкам.

Чем **больше** $\chi^2$, тем сильнее данные расходятся с моделью независимости.

При верной $H_0$ (и некоторых условиях) статистика имеет примерно $\chi^2$-распределение с:

$$
df = (R - 1)(C - 1)
$$

степенями свободы.

По нему и считаем p-value:
$p = P(\chi^2_{\text{theoretical}} \ge \chi^2_{\text{observed}})$.

---

## 4. Предпосылки и ограничения

1. **Независимость наблюдений.**
   Каждое наблюдение — отдельный объект. Не должно быть «тот же юзер посчитан 10 раз».

2. **Достаточно большие ожидаемые частоты.**
   Для $\chi^2$-аппроксимации обычно хотят:

   * $E_{ij} \ge 5$ для большинства ячеек;
   * если много ячеек с $E_{ij} < 5$, лучше:

     * объединять категории,
     * или использовать точные тесты (Fisher для маленьких таблиц),
     * или логистическую регрессию.

3. **Фиксированные суммарные частоты.**
   В классической постановке строки/столбцы рассматриваются как фиксированные уровни категории.

---

## 5. Связь с Z-тестом для пропорций (2 $\times$ 2 случай)

Для таблицы 2 $\times$ 2:

|        | success | fail | всего |
| ------ | ------- | ---- | ----- |
| group1 | a       | b    | $n_1$ |
| group2 | c       | d    | $n_2$ |

$\chi^2$-тест с 1 степенью свободы **эквивалентен** двустороннему Z-тесту на разность долей.

Есть формальная связь:

$$
\chi^2 = Z^2.
$$

То есть:

* **для 2 групп и бинарной метрики** можно:

  * либо использовать Z-тест для пропорций,
  * либо $\chi^2$-тест 2 $\times$ 2 — это одно и то же по сути (при больших n).

Разница начинается, когда групп **> 2** → Z-теста уже нет в виде одной цифры, а $\chi^2$-тест остаётся общим.

---

## 6. $\chi^2$-тест в A/B/n-тестировании с бинарной метрикой

Сценарий:

* группы: A, B, C, ..., k вариантов,
* метрика: конверсия (`0/1` по юзеру),
* хотим проверить сразу все: одинаковы ли $p_1, p_2, ..., p_k$.

### 6.1. Построение таблицы

Строим таблицу `k × 2`:

| group | success    | fail          |
| ----- | -------    | ---------     |
| A     | $x_1$      | $n_1 − x_1$   |
| B     | $x_2$      | $n_2 − x_2$   |
| ...   | ...        | ...           |
| k     | $x_k$      | $n_k − x_k$   |

Дальше:

* гоняем $\chi^2$-тест на этой таблице,
* получаем один p-value для гипотезы:

$$
H_0: p_1 = p_2 = \dots = p_k.
$$

### 6.2. Интерпретация

* Если p-value ≥ α (например, 0.05):
  статистических оснований говорить, что конверсии отличаются, **нет** → на уровне модели принимаем $H_0$.
* Если p-value < α:
  различия есть, но **не сказано, где именно**:

  * дальше нужны **пост-hoc** сравнения: попарные тесты долей с поправкой на множественность
    (Holm, Bonferroni, BH и т.п.),
  * или логистическая регрессия + тесты контрастов.

---

## 7. Эффект-сайз: $\phi$ и V Крамера

Сам $\chi^2$ даёт только «насколько всё плохо с $H_0$», но не «насколько сильна связь».

Используют **нормированные меры**, например:

### 7.1. Коэффициент $\phi$ — для 2 $\times$ 2

$$
\varphi = \sqrt{ \frac{\chi^2}{N} }.
$$

Это аналог корреляции для бинарных переменных.

Грубо:

* $\mid\phi\mid \approx 0.1$ — слабая связь,
* $\mid\phi\mid \approx 0.3$ — средняя,
* $\mid\phi\mid \approx 0.5$ — сильная.

### 7.2. V Крамера — для произвольной таблицы

$$
V = \sqrt{ \frac{\chi^2}{N \cdot ( \min(R-1, C-1) )} }.
$$

V ∈ [0, 1]. По смыслу:

> доля «максимально возможной» связи, которую наблюдаем между переменными.

Это можно использовать как эффект-сайз:
$V \approx 0.1$ — небольшой эффект, 0.3 — средний, 0.5 — большой (условные уровни).

---

## 8. Численный пример

Представь A/B/C-тест с конверсией в покупку:

* Группы: A, B, C
* Данные:

| group | success | fail | всего |
| ----- | ------- | ---- | ----- |
| A     | 50      | 150  | 200   |
| B     | 70      | 130  | 200   |
| C     | 40      | 160  | 200   |

Итого:

* N = 600,
* суммы по столбцам:

  * success: 160,
  * fail: 440.

### 8.1. Ожидаемые частоты при $H_0$

Например, для A-success:

$$
E_{A, \text{succ}} = \frac{n_{A\cdot} , n_{\cdot \text{succ}}}{N} = \frac{200 \cdot 160}{600} = 53.\overline{3}.
$$

Аналогично считаем для остальных ячеек.

### 8.2. $\chi^2$

Дальше считаем:

$$
\chi^2 = \sum_{i,j} \frac{(O_{ij} - E_{ij})^2}{E_{ij}}.
$$

Вручную делать скучно, это делегируем Python’у (ниже).

Степени свободы:

* R = 3 (группы),
* C = 2 (success/fail),
* df = (3 − 1)(2 − 1) = 2.

Сравниваем $\chi^2$ с $\chi^2$-распределением с 2 df ⇒ получаем p-value.

---

## 9. Пример на Python (`scipy`)

```python
import numpy as np
from scipy.stats import chi2_contingency

# Таблица: строки - группы, столбцы - исходы (success, fail)
table = np.array([
    [50, 150],  # A
    [70, 130],  # B
    [40, 160],  # C
])

chi2, p_value, dof, expected = chi2_contingency(table, correction=False)

print("chi2 =", chi2)
print("p-value =", p_value)
print("df =", dof)
print("expected frequencies =\n", expected)
```

Пара замечаний:

* `correction=False` — отключает поправку Йейтса (для таблиц 2 $\times$ 2 она включается по умолчанию, но тут 3 $\times$ 2).
* `expected` — это матрица $E_{ij}$.

### 9.1. Эффект-сайз V Крамера

```python
N = table.sum()
V = (chi2 / (N * (min(table.shape) - 1))) ** 0.5
print("Cramer's V =", V)
```

---

## 10. Что писать в отчёте

Минимальная нормальная формулировка для A/B/n-теста с бинарной метрикой:

* Гипотезы:

  > $H_0$: доля успехов одинакова во всех группах;
  > $H_1$: хотя бы в одной группе доля отличается.
* Тип теста:

  > $\chi^2$-тест для таблицы сопряжённости $k  \times  2$.
* Результаты:

  * $\chi^2$, df, p-value,
  * эффект-сайз: $\phi$ (для 2 $\times$ 2) или V Крамера.
* Вывод:

  * **если p ≥ α:**  
    *«На уровне значимости α нет оснований отвергать гипотезу равенства долей во всех группах»*;
  * **если p < α:**  
    *«Хотя бы в одной группе доля успехов отличается. Дальнейший анализ проводится через попарные сравнения с поправкой на множественность / логистическую регрессию».*

Пример текста:

> «$\chi^2$-тест для таблицы 3 $\times$ 2 показал значимые различия конверсии между вариантами: $\chi^2$(2) = 7.8, p = 0.020. Эффект-сайз Cramer's V = 0.11 (небольшой эффект). Это означает, что распределение успехов/неуспехов статистически различается между вариантами, хотя сила связи умеренная. Для уточнения, какие именно пары групп отличаются, проведены попарные тесты долей с поправкой Holm.»
