# üìà Uplift Modeling ‚Äî –ü–æ–ª–Ω—ã–π –ü–ª–∞–Ω –ö–æ–Ω—Å–ø–µ–∫—Ç–æ–≤

## üß≠ –û–±—â–∏–π –ø–ª–∞–Ω –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤

### **1. –ö–æ–Ω—Ü–µ–ø—Ü–∏—è –∏ –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏**
**–¶–µ–ª—å:** –ø–æ–Ω—è—Ç—å, *—á—Ç–æ* –º—ã –∏–∑–º–µ—Ä—è–µ–º –∏ *–∑–∞—á–µ–º*.

**–¢–µ–º—ã:**
- –ß—Ç–æ —Ç–∞–∫–æ–µ **treatment effect** –∏ **uplift**
- –†–∞–∑–ª–∏—á–∏–µ –º–µ–∂–¥—É:
  - Average Treatment Effect (ATE)
  - Conditional / Heterogeneous Treatment Effect (CATE / HTE)
  - Individual Treatment Effect (ITE)
- –ü–æ—á–µ–º—É –æ–±—ã—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ –æ—Ç–∫–ª–∏–∫–∞ –Ω–µ –ø–æ–¥—Ö–æ–¥—è—Ç
- –ë–∞–∑–æ–≤–∞—è –∏–¥–µ—è uplift-–º–æ–¥–µ–ª–µ–π: –ø—Ä–æ–≥–Ω–æ–∑ *—Ä–∞–∑–Ω–∏—Ü—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π*
- –ü—Ä–∏–º–µ–Ω–µ–Ω–∏—è: –º–∞—Ä–∫–µ—Ç–∏–Ω–≥, –∫—Ä–µ–¥–∏—Ç–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –º–µ–¥–∏—Ü–∏–Ω–∞, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã
- –ú–µ—Ç–æ–¥—ã –æ—Ü–µ–Ω–∫–∏: uplift curves, Qini curves, AUUC

üìò *–†–µ–∑—É–ª—å—Ç–∞—Ç:* –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ –≤ —Ç–µ—Ä–º–∏–Ω–∞—Ö –∫–∞—É–∑–∞–ª—å–Ω–æ—Å—Ç–∏.

---

### **2. –û—Å–Ω–æ–≤—ã –∫–∞—É–∑–∞–ª—å–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞**
**–¶–µ–ª—å:** –∑–∞–ª–æ–∂–∏—Ç—å —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º —Å—Ç—Ä–æ–∏—Ç—Å—è uplift.

**–¢–µ–º—ã:**
- –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∏—Å—Ö–æ–¥—ã (Potential Outcomes Framework, Rubin Causal Model)
- Counterfactual reasoning ‚Äî —á—Ç–æ –∑–Ω–∞—á–∏—Ç "—á—Ç–æ –±—ã–ª–æ –±—ã, –µ—Å–ª–∏ –±—ã..."
- Assumptions:
  - Ignorability / Unconfoundedness
  - SUTVA (Stable Unit Treatment Value Assumption)
  - Overlap / Positivity
- –ß—Ç–æ —Ç–∞–∫–æ–µ **confounding** –∏ **selection bias**
- –ö–∞–∫ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å: Propensity score, stratification, matching, weighting

üìò *–†–µ–∑—É–ª—å—Ç–∞—Ç:* –ø–æ–Ω–∏–º–∞–Ω–∏–µ, –ø–æ—á–µ–º—É –Ω—É–∂–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ –∏ –∫–∞–∫ –æ—Ü–µ–Ω–∏—Ç—å ‚Äú—á–∏—Å—Ç—ã–π‚Äù —ç—Ñ—Ñ–µ–∫—Ç.

---

### **3. –î–∏–∞–∑–∞–π–Ω —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –¥–ª—è Uplift**
**–¶–µ–ª—å:** –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ—Ä—Ä–µ—Ç–Ω—ã–π –≤–∏–¥ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è uplift.

**–¢–µ–º—ã:**
- –†–∞–∑–ª–∏—á–∏–µ RCT vs observational uplift
- Random assignment –∏ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ –≥—Ä—É–ø–ø—ã
- –ö–∞–∫ –Ω–∞–∑–Ω–∞—á–∞–µ—Ç—Å—è treatment (–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è, –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, –ª–∏–º–∏—Ç –∏ —Ç.–¥.)
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞ –≥—Ä—É–ø–ø
- Power analysis –∏ sample size
- A/B/n-—Ç–µ—Å—Ç—ã –∏ Sequential Testing
- –õ–æ–≤—É—à–∫–∏: contamination, selection bias, interference

üìò *–†–µ–∑—É–ª—å—Ç–∞—Ç:* –ø–æ–Ω–∏–º–∞–Ω–∏–µ, –∫–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–æ–±–∏—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è uplift

---

### **4. –ú–µ—Ç–æ–¥—ã –æ—Ü–µ–Ω–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∞ (Propensity & Matching)**
**–¶–µ–ª—å:** –Ω–∞—É—á–∏—Ç—å—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è uplift.

**–¢–µ–º—ã:**
- Propensity Score:
  - –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏ –∏–Ω—Ç—É–∏—Ü–∏—è
  - –ú–µ—Ç–æ–¥—ã –æ—Ü–µ–Ω–∫–∏ (–ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è, ML)
- Matching methods:
  - Nearest Neighbor, Mahalanobis, Propensity-based Matching
- Inverse Probability of Treatment Weighting (IPTW)
- Stratification / subclassification
- Doubly robust estimators (–æ–±–∑–æ—Ä, —Å–≤—è–∑–∫–∞ —Å Double ML)

üìò *–†–µ–∑—É–ª—å—Ç–∞—Ç:* –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Å–ø–æ—Å–æ–±–æ–≤ —Å–¥–µ–ª–∞—Ç—å –¥–∞–Ω–Ω—ã–µ "–∫–≤–∞–∑–∏—Å–ª—É—á–∞–π–Ω—ã–º–∏".

---

### **5. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã uplift-–º–æ–¥–µ–ª–µ–π**
**–¶–µ–ª—å:** –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–æ–¥—Ö–æ–¥—ã –∏ –∏—Ö –ª–æ–≥–∏–∫—É.

**–¢–µ–º—ã:**
- –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:
  - S-learner
  - T-learner
  - X-learner
  - R-learner
  - DR-learner (Doubly Robust)
- Direct Uplift Modeling (two-model approach vs single-model)
- –ú–µ—Ç–æ–¥—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ uplift
- Tree-based uplift models:
  - Uplift trees, Uplift Random Forest
  - Causal Tree, Causal Forest (GRF)
- –ü—Ä–∏–º–µ—Ä —Å—Ö–µ–º—ã –æ–±—É—á–µ–Ω–∏—è –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

üìò *–†–µ–∑—É–ª—å—Ç–∞—Ç:* —Å–∏—Å—Ç–µ–º–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ –∏ –∏—Ö –≤–∑–∞–∏–º–æ—Å–≤—è–∑–µ–π.

---

### **6. –ú—É–ª—å—Ç–∏- –∏ –∫–æ–Ω—Ç–∏–Ω—É–∞–ª—å–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã**
**–¶–µ–ª—å:** –≤—ã–π—Ç–∏ –∑–∞ —Ä–∞–º–∫–∏ ‚Äú0/1 treatment ‚Äì 0/1 target‚Äù.

**–¢–µ–º—ã:**
- Non-binary treatment (–º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–µ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏–µ)
- Continuous treatment (–Ω–∞–ø—Ä–∏–º–µ—Ä, —É—Ä–æ–≤–µ–Ω—å –¥–æ–∑—ã/—Å—Ç–∞–≤–∫–∏)
- Non-binary target (–∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–π –∏–ª–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–π –æ—Ç–∫–ª–∏–∫)
- –ü–æ–¥—Ö–æ–¥—ã –¥–ª—è generalization:
  - Causal ML —Å –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–º treatment
  - Meta-learners (Generalized S/T/X learners)
  - Generalized Random Forests

üìò *–†–µ–∑—É–ª—å—Ç–∞—Ç:* –ø–æ–Ω–∏–º–∞–Ω–∏–µ, –∫–∞–∫ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å uplift –∫ —Å–ª–æ–∂–Ω—ã–º —Å–ª—É—á–∞—è–º.

---

### **7. –ú–µ—Ç—Ä–∏–∫–∏ –∏ –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ uplift-–º–æ–¥–µ–ª–µ–π**
**–¶–µ–ª—å:** —É–º–µ—Ç—å –∏–∑–º–µ—Ä—è—Ç—å –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –º–æ–¥–µ–ª–∏.

**–¢–µ–º—ã:**
- Uplift curve, Qini curve, AUUC (Area Under Uplift Curve)
- Qini coefficient
- Difference in Conversion Rate (ŒîCR)
- Policy Value / Expected Profit
- Split-based evaluation:
  - Treatment/control holdouts
  - Cross-validation –≤ uplift-–∑–∞–¥–∞—á–∞—Ö
- –°–∏–º—É–ª—è—Ü–∏–∏ (synthetic uplift data)

üìò *–†–µ–∑—É–ª—å—Ç–∞—Ç:* –ø–æ–Ω–∏–º–∞–Ω–∏–µ, –∫–∞–∫ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å uplift-–º–æ–¥–µ–ª–∏.

---

### **8. –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∏ —Å–≤—è–∑—å —Å –∫–∞—É–∑–∞–ª—å–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏**
**–¶–µ–ª—å:** —É–≤—è–∑–∞—Ç—å uplift —Å –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–æ–π –∫–∞—É–∑–∞–ª—å–Ω–æ–π —ç–∫–æ—Å–∏—Å—Ç–µ–º–æ–π.

**–¢–µ–º—ã:**
- Double Machine Learning (DML)
- Causal Forest / Generalized Random Forest (GRF)
- Meta-learners –∫–∞–∫ —á–∞—Å—Ç–Ω—ã–µ —Å–ª—É—á–∞–∏ DML
- Uplift vs Causal Inference: —Ä–∞–∑–ª–∏—á–∏—è –∏ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–º–∏ –ø–æ–¥—Ö–æ–¥–∞–º–∏ (DragonNet, TARNet, CEVAE)
- –ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã: off-policy learning, causal bandits, personalization

üìò *–†–µ–∑—É–ª—å—Ç–∞—Ç:* –ø–æ–Ω–∏–º–∞–Ω–∏–µ, –≥–¥–µ uplift –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ —à–∫–∞–ª–µ ‚Äúdata science ‚Üí causal ML‚Äù.
