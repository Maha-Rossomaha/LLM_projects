# Uplift Modeling — Дизайн эксперимента для Uplift


## 1. RCT vs Observational Uplift

### 1.1. Randomized Controlled Trial (RCT)
- **Идея:** назначаем воздействие случайно. При соблюдении SUTVA и позитивности получаем идентифицируемые ATE/CATE без корректировок.
- **Плюсы:** минимальный риск конфоундинга, простая интерпретация, чистая валидация Qini/AUUC.
- **Минусы:** 
    - **стоимость контроля (упущенная выгода)** - контрольная группа специально не получает воздействие, из-за чего теряется потенциальная прибыль (или эффект);
    - **организационные ограничения (комплаенс, частоты, квоты)** - нельзя проводить RCT во всех руппах бесконечно часто.

### 1.2. Observational Uplift (наблюдательные данные)
- **Идея:** воздействие назначалось по бизнес‑правилам/скорингам → есть смешение. Нужны корректировки: propensity, стратификация, матчинг, IPTW, DR.
- **Плюсы:** можно учиться на исторических данных, когда RCT невозможен.
- **Минусы:** 
  - **опора на допущение игнорируемости** - считаем, что все факторы, влияющие и на treatment, и на outcome, измерены и учтены;
  - **риск скрытых конфоундеров** - могут существовать невидимые переменные, которые влияют и на вероятность treatment, и на результат — тогда оценка uplift’а смещена;
  - **сложность объяснения и валидирования** - нет истинной контрольной группы → нельзя напрямую проверить эффект → труднее объяснить результаты бизнесу и защитить их статистически.

### 1.3. Где что уместно
- **Есть контроль над каналом/процессом?** Делай RCT (даже небольшой пилот).
- **Нет контроля, но есть логи?** Делай observational uplift с пропенсити и обширной диагностикой баланса/оверлапа.

---

## 2. Рандомизация и контрольные группы

### 2.1. Виды рандомизации

| Тип рандомизации | Суть | Когда применять |
|------------------|------|----------------|
| **Простая (Simple Randomization)** | Каждой единице присваивается treatment с вероятностью *p* независимо от других. | Когда выборка большая и не нужно контролировать баланс. |
| **Блочная / стратифицированная (Blocked / Stratified)** | Разбиваем данные на страты по важным признакам (сегмент, страна, риск-класс) и рандомизируем внутри каждой. | Когда нужно обеспечить баланс по ключевым ковариатам. |
| **Ковариат-адаптивная (Covariate-Adaptive / Minimization)** | Алгоритм подбирает назначение treatment «на лету», чтобы сохранять баланс по заданным ковариатам. | В онлайн-экспериментах, когда группы формируются последовательно. |
| **Кластерная (Cluster / Group / Geo-Randomization)** | Рандомизируем не отдельных людей, а кластеры (магазины, филиалы, регионы). | Когда есть риск взаимного влияния (interference) или логистические ограничения. |


### 2.2. Выбор доли воздействия $p=\Pr(W=1)$
- Для обучения uplift и оценки Qini/AUUC удобно **50/50** (минимум дисперсии разности). Допустимы 40/60…60/40.
- При дорогом воздействии или рисках — **малый пилот** (например, 10–20%) с последующим масштабированием.

### 2.3. Контрольные группы
- **Чистый контроль (W=0):** никаких касаний по целевому каналу.
- **Placebo/«призрачные показы» (ghost ads):** это способ сделать «контроль» в рекламных или онлайн-средах, где невозможно просто не показывать рекламу случайным людям, потому что показ управляется аукционами, таргетингом и сложной системой подбора. 
  - **Вся аудитория участвует в рекламных аукционах**.  
  Для каждого пользователя можно понять: система пыталась показать рекламу или могла бы показать, но не показала.
  - **Пользователи делятся на две группы:**
    - **Treatment (W=1)** — реклама реально была показана (и пользователь мог её увидеть).
    - **Ghost / Placebo (W=0)** — реклама не была показана, но могла бы быть (например, объявление участвовало в аукционе и почти выиграло).
  - **Сравнивают поведение этих двух групп:** насколько выше вероятность конверсии, клика или покупки у тех, кто реально видел рекламу, по сравнению с теми, кто был в аналогичной ситуации, но не увидел её.
    >В онлайн-рекламе простое сравнение «видел рекламу» vs «не видел» даёт смещение — ведь тем, кому реклама показалась, алгоритм и так уже присвоил более высокую вероятность конверсии (они лучше таргетированы).

- **Holdout‑контроль:** зарезервированная доля для честной оценки политики (не обучать на ней).

### 2.4. Несоблюдение (non‑compliance)
- **ITT (intention‑to‑treat):** анализируем по назначению (W), даже если сообщение не было открыто/увидено. Это соответствует реальной политике назначения.
- **TOT (treatment‑on‑the‑treated):** эффект среди фактически получивших воздействие; требует инструментов/моделирования экспозиции; для uplift обычно используем **ITT**.

---

## 3. Как правильно определить и назначать воздействие

### 3.1. Чёткая спецификация W
- **Что именно считается W=1?** Показ оффера? Отправка письма? Пуш в окно сессии? Лимит на кредитной линии? 
- **Единица:** user_id / account_id / household / агент‑кластер.
- **Окно измерения:** период, в котором считаем отклик (чтобы не ловить carryover/seasonality).

### 3.2. Каналы и политика контакта
- **Политика частот:** cap по каналам (например, не более 1 письма/нед.). Рандомизируй **внутри** допустимых контактов.
- **Мультиканальность:** если есть другие каналы, фиксируй их как ковариаты/«фоновые воздействия» или исключай пересечения.
- **Eligibility:** eligibility‑фильтры (критерии, кто может участвовать в эксперименте) должны быть зафиксированы **до** рандомизации и логироваться.

### 3.3. Многоуровневые/многорамные воздействия
- A/B/n: разные тексты/скидки/тайминги.
- Непрерывное воздействие (размер скидки, ставка) — это отдельный дизайн (см. обобщения; здесь фокус на бинарном W).

---

## 4. Проверка баланса групп

### 4.1. Что проверять
- Распределения ключевых X (возраст, активность, риск, сегмент, география).
- Исторические метрики до старта (pre‑period outcomes).

### 4.2. Как проверять
- **Standardized Mean Difference (SMD)**: |SMD| < 0.1 — ок.
- Гистограммы/ECDF/KS‑тест для непрерывных; доли/х^2 для категориальных.
- **Love‑plot** (сводный график SMD по фичам).

### 4.3. Что делать при дисбалансе
- Убедиться, что он случайен и мал; при сильном — применить **стратифицированный анализ**, регрессионную поправку (CUPED/ANCOVA) или перезапустить рандомизацию с блоками.

---

## 5. Power analysis и sample size

### 5.1. Первичный эффект
Для бинарного исхода — разница конверсий: $\Delta = p_1 - p_0$.

Оценка размера выборки на группу (две пропорции, двусторонний тест):
$$
 n \;\approx\; \frac{\big( z_{\alpha/2}\,\sqrt{2\bar p(1-\bar p)} + z_{\beta}\,\sqrt{p_1(1-p_1)+p_0(1-p_0)} \big)^2}{(p_1-p_0)^2},\quad \bar p=\tfrac{p_1+p_0}{2}.
$$
Где $\alpha$ — уровень значимости (обычно 0.05), power = $1-\beta$ (обычно 0.8).

**Пример:** базовая конверсия 5% ($p_0=0.05$), ожидаемый инкремент +1 п.п. ($p_1=0.06$), $\alpha=0.05$, power=0.8 → требуется ≈ **8.1k** наблюдений **в каждой** группе.

**Грубые ориентиры:**
- +1 п.п. при базовой 5% → ~8k/группу;
- +2 п.п. при базовой 5% → ~2k/группу;
- +0.5 п.п. при базовой 5% → ~32k/группу.

### 5.2. Для обучения uplift‑модели
- Нужны **достаточные события** в каждой ветви (W=0/1). Правило: ≥ **1000–2000 положительных исходов** per arm для устойчивого обучения/валидации.
- Доля W=1 близка к 50% даёт минимальную дисперсию разности и лучшую наполняемость бинов в Qini.
- Для редких событий (p<1%) планируйте **длительный** сбор или агрегацию по кластерам.

### 5.3. Корректировки дисперсии
- **CUPED/ANCOVA**: регрессионная поправка на pre‑period outcome снижает дисперсию и сокращает N.
- **Стратификация/блоки** до старта тоже повышают мощность (меньше дисперсия).

---

## 6. A/B/n‑тесты и Sequential Testing

### 6.1. A/B/n (несколько вариантов воздействия)
- Контроль ошибок: FWER/FDR (Bonferroni/Holm/Hochberg) или иерархические тесты.
- Выбираем первичную метрику (например, инкремент покупок) и планируем вторичный анализ (клики, выручка) заранее.

### 6.2. Последовательный анализ и «подглядывание»
- Многократные проверки накапливают риск ложноположительных. Решения:
  - **Групповые последовательные дизайны** (alpha‑spending): Pocock, O’Brien–Fleming.
  - **Всегда‑валидные тесты** (mixture‑SPRT, e‑values) или **байесовские** правила остановки.
- **Рамп‑ап**: сначала малый % трафика, затем расширяем при достижении порогов безопасности.

### 6.3. Bandits vs RCT
- Мульти‑рук. бандиты минимизируют regret онлайн, но **сложнее** для чистой каузальной оценки и Qini. Рекомендуется: сначала RCT→обучение→политика; затем уже bandit‑эксперименты для оптимизации.

---

## 7. Ловушки и как их избегать

### 7.1. Contamination (перекрёстные касания)
- Пользователь из контроля получает воздействие в другом канале/тесте.
- **Меры:** жёсткие исключения пересечений, централизованный *experiment switchboard*, логирование всех касаний, при риске — **кластерная** рандомизация.

### 7.2. Interference (нарушение SUTVA)
- Эффект на одного зависит от назначения другим (соцсети, реферальные цепочки, shared‑device).
- **Меры:** кластеризация (домохозяйства/гео), *geo‑lift* эксперименты, анализ спилловеров.

### 7.3. Selection bias
- Назначение на основе вероятности отклика или «ручного отбора».
- **Меры:** держать назначение случайным; если невозможно — фиксировать все правила, собирать богатые X и применять propensity/DR при анализе.

### 7.4. Пост‑тритмент переменные и коллидеры
- Нельзя условиться на «открытие письма»/«показы после экспозиции». Это искажает эффект.
- **Меры:** используем **ITT**; пост‑события — как вторичные, не для стратификации.

### 7.5. Дрейф/сезонность/несинхронность
- Запуск в разные окна для групп → систематические искажения.
- **Меры:** синхронный запуск, фиксированный pre‑period, длительность ≥ одному полному циклу (неделя/месяц).

### 7.6. Качество трекинга и атрибуции
- Потери логов, разные окна атрибуции, dedup. 
- **Меры:** единая схема событий, обязательные поля (см. ниже), dry‑run перед стартом.

---

## 8. Логирование: что обязательно сохранять
- `unit_id` (user/account/household), `cluster_id` (если кластерная рандомизация).
- `assignment_w` (назначение), `exposed` (факт экспозиции), `eligibility_flags`.
- `timestamp_assign`, `timestamp_exposure`, `window_start/end`.
- Канал/креатив/оффер (`channel`, `creative_id`, `offer_id`).
- Все релевантные **ковариаты до воздействия** (X_pre): демо, активность, риск, история.
- События исхода `Y` и денежные метрики (V, cost C).

> Это позволит: (1) анализ ITT vs. экспозиции; (2) регрессионные поправки; (3) off‑policy оценку политик.

---

## 9. Примеры дизайна

### 9.1. Email‑кампания (бинарный W)
- **Единица:** пользователь. **Окно:** 7 дней после отправки.
- **Рандомизация:** 50/50, блочная по сегменту ценности (High/Low) и частоте покупок.
- **Размер:** базовая CR=4%, ожидаемый uplift +1 п.п. → ≈ **10k** на группу (с запасом на отказы/некомплаенс).
- **Ограничения:** cap 1 письмо/неделя, исключить параллельные кампании.
- **Оценка:** ITT, Qini/AUUC на holdout; вторично — value‑метрика с C и V.

### 9.2. Кредитный оффер КСП
- **Единица:** клиентский счёт. **Eligibility:** правила риска фиксируются до старта.
- **Рандомизация:** 40/60 (дорого показывать всем), стратификация по риск‑классу и продукту.
- **Ловушки:** перекрёстные предложения в приложении (контаминация) → свичборд.
- **Оценка:** ITT по факту показа оффера; TOT как доп. анализ (экспозиция баннеру).

### 9.3. Гео‑эксперимент (интерференция)
- **Кластеры:** города/регионы (N≈40). Случайно назначаем половину в воздействие.
- **Метрика:** региональная выручка/1000 MAU, diff‑in‑diff относительно pre‑period.
- **Плюс:** минимизируем спилловеры между пользователями внутри кластера.
