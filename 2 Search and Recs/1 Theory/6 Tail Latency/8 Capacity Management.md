# Capacity Management

## 1. Concurrency и очереди

### 1.1. Ограничение параллельных запросов

Для каждого тяжёлого компонента должен быть **лимит concurrency**:
- embedder: max одновременных forward’ов,
- ANN: max параллельных запросов к векторному индексу на ноду,
- reranker / LLM: max батчей / запросов на GPU/процесс.

Почему:
- если пускать «сколько влезет», компоненты уходят в **saturation** (CPU/GPU 100%, диск/сеть в стопоре),
- latency перестаёт расти линейно и уходит в экспоненту,
- любая небольшая очередь превращается в **хвост, который сам себя раздувает**.

Идея простая: **ограниченный пул** для каждого этапа. Всё, что сверх — идёт в очередь или отклоняется.

### 1.2. Почему иногда лучше “не взять” запрос

Иногда честнее сказать «не могу сейчас» или дать деградированный ответ, чем:
- взять все запросы,
- положить очередь на минуты,
- убить tail всем пользователям.

Причины:
- при переполнении очереди **каждый новый запрос увеличивает задержку для всех предыдущих**;
- пользователь лучше переживает быстрый “soft-fail” (ошибка/упрощённый ответ), чем 10 секунд молчания.

Практически:
- каждая очередь должна иметь **ограниченную глубину**;
- при превышении глубины — drop / fallback (см. ниже про circuit breaker).

---

## 2. Circuit breaker и rate limiting

### 2.1. Circuit breaker

**Circuit breaker** — механизм, который при деградации сервиса переводит его в режим:
- либо вообще не принимает новые запросы,
- либо сразу отвечает упрощённо/ошибкой.

Примеры триггеров:
- p99 latency компонента > X мс несколько интервалов подряд,
- error rate > Y%,
- очередь длиной > Z.

В этом режиме:
- «дорогие» этапы (rerank, LLM) можно **отключить** для части запросов;
- ANN/Embedder работают в минималистичном режиме (малый nprobe/efSearch, ограниченный max tokens).

### 2.2. Rate limiting

**Rate limiting** — жёсткое ограничение RPS из внешнего мира.

Политики:
- глобальный лимит на сервис (например, 1000 RPS),
- отдельные лимиты по клиентам/ключам/сегментам:
  - критичные клиенты → более высокий лимит,
  - некритичные/бесплатные → ограниченный.

Если лимит превышен:
- часть запросов сразу отклоняется (429 / retry later),
- или переводится в **упрощённый режим** (без rerank/LLM).

Это защищает tail для важных пользователей, когда нагрузка внезапно выросла.

---

## 3. Warm-up и pre-loading

### 3.1. Почему холодный старт убивает p99

После релиза/рестарта часто видим картину:
- первые 10–30 минут p99 «в космосе», потом всё норм.

Причины:
- embedding‑модель делает первый forward (нагрев GPU/CPU, компиляция, JIT),
- ANN индекс прогружает cold pages в память/кэш,
- LLM поднимается, alocate’ит память и KV‑буферы,
- кэши (embedding/ANN/rerank) пустые.

### 3.2. Прогрев (warm-up)

Чтобы этого не было, при релизе делаем **pre‑warm**:

1. **Embedding-модель**
   - отправить серию synthetic/реальных запросов,
   - прогреть веса, граф, компиляции.

2. **ANN индекс**
   - сделать несколько запросов по head‑запросам,
   - прогреть hot‑кластер/страницы в память (особенно для дисковых индексов).

3. **LLM**
   - выполнить несколько коротких генераций (chat/RAG–шаблоны),
   - заполнить KV‑кэш базовыми паттернами.

### 3.3. Как избежать “после релиза p99 в космос”

Стратегия:

1. **Staged rollout + canary**
   - поднимаем новую версию на части трафика (1–5%),
   - прогреваем модели и кэши,
   - следим за p95/p99 и ошибками.

2. После прогрева и стабилизации метрик:
   - постепенно увеличиваем долю трафика до 100%,
   - при проблемах откатываемся по alias‑switch / деплою.

В результате пользователи почти не видят “холодного” хвоста — он отрабатывается на маленькой доле трафика во время canary/warm-up.