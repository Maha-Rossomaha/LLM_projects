# Cache Layers 

## 1. Зачем нужны кэш-слои в retrieval‑пайплайне

Типичный каскад: **Preprocess → Embedder → ANN → Rerank → LLM/Output**.

Каждый этап может быть дорогим. Многие запросы (особенно head) **повторяются**:
- один и тот же текст запроса,
- один и тот же embedding,
- похожие top‑K кандидаты,
- одинаковые пары query–doc для rerank’а.

Кэш‑слои позволяют:
- снизить среднюю latency,
- подрезать tail (особенно p95/p99 для частых запросов),
- экономить compute на embedder/ANN/reranker.

Главная идея: **сделать горячий путь максимально дешёвым**, а тяжёлую работу оставить редким/новым запросам.

---

## 2. Embedding cache

### 2.1. Что кэшируем

1. **Эмбеддинги запросов**
   - `emb_q = f(query_text, embedder_version, preprocessing)`
   - это самый частый и выгодный кейс.

2. **Иногда эмбеддинги документов/ответов**, если они считаются “на лету”
   - чаще всё же считаются оффлайн и живут в embedding store, но бывают гибридные сценарии (runtime feature‑инженерия, персонализация).

### 2.2. Ключ для кэша эмбеддингов

Базовая схема:

```text
key = hash(
  query_text,
  embedder_version,
  preprocessing_version
)
```

Почему так:
- **query_text** — очевидно; одинаковый текст → одинаковый embedding;
- **embedder_version** — при смене модели пространство векторов меняется;
- **preprocessing_version** — изменения токенизации / нормализации тоже должны менять ключ.

Можно дополнительно включить:
- язык (если разные модели по языкам),
- тип запроса (search/chat/FAQ).

### 2.3. Эффект от embedding cache

- **Средняя latency embedder’а падает**:
  - head‑запросы полностью обслуживаются из кэша,
  - реальный embedder живёт в основном на длинном хвосте.

- **Tail подрезается для частых запросов**:
  - для горячих query p95/p99 становятся близки к latency кэша (зачастую ~мс);
  - хвост embedder’а остаётся только для сложных/редких запросов.

### 2.4. TTL и размер

- TTL можно делать **длинным** (часы/дни), если embedder_version редко меняется;
- размер: ограничивается по памяти;
- политика eviction — LRU/LFU, иногда с приоритетом head‑запросов.

---

## 3. ANN-topK cache

### 3.1. Что кэшируем

**Результат ANN‑поиска**:

```text
topK_docs = ANN(query_embedding, index_version)
```

Где:
- `query_embedding` может быть взят из embedding cache,
- `index_version` — версия векторного индекса (IVF/HNSW/Qdrant/OpenSearch и т.п.).

Кэшируем либо:
- **только список doc_ids** (дёшево по памяти),
- либо doc_ids + базовые расстояния/скор.

### 3.2. Ключ для ANN-topK кэша

Варианты:

1. Через текст и версии:

```text
key = hash(
  query_text,
  embedder_version,
  index_version
)
```

2. Через embedding:

```text
key = hash(
  query_embedding_quantized,
  index_version
)
```

Практика чаще идёт по варианту 1 (через текст), чтобы избежать
проблем с float‑сравнением и экспоненциальным разнообразием эмбеддингов.

Главное — **версионирование ключа index_version**:
- при переиндексации (alias‑switch) index_version меняется,
- старый кэш автоматически «протухает».

### 3.3. Invalidation и stale‑результаты

Проблемы:
- **stale‑результаты**: документ удалён / изменён, а кэш его всё ещё выдаёт;
- **смена индекса**: изменилась структура, фильтры, политика отбора.

Как с этим жить:

1. **Версионирование ключей**
   - `index_version` в ключе → после alias‑switch кэш ANN для старого индекса не используется.

2. **TTL на ANN‑кэш**
   - короткий TTL (секунды/минуты) снижает риск долгого «застревания» старого topK;
   - особенно важно в доменах с быстро меняющимся контентом (новости, фиды).

3. **Soft‑validation**
   - при использовании кэш‑выдачи можно проверять, не стали ли некоторые doc_ids недоступны/запрещены;
   - при обнаружении — частично дополнить выдачу свежими результатами.

### 3.4. Влияние на tail

- Head‑запросы часто полностью обслуживаются из **embedding cache + ANN‑topK cache** →
  - p95/p99 для них становятся очень низкими.
- Хвост ANN (hot‑shard, nprobe/efSearch) остаётся только для редких запросов.

Плюс такой кэш очень помогает в режимах высокого QPS, разгружая vector DB.

---

## 4. Rerank scores cache

### 4.1. Что кэшируем

**Дорогостоящий rerank**, особенно cross‑encoder.

Варианты:

1. **Покординатно для пар (query, doc)**

```text
score = RERANK(query_text, doc_id, model_version)
```

2. **Целый топ‑K список**

```text
reranked_topK = RERANK(query_text, topK_docs, model_version)
```

Чаще выгоднее кэшировать **score для пары (query, doc)**, потому что:
- один и тот же документ может встречаться в разных top‑K наборов;
- кэш можно переиспользовать в рекомендациях, разных виджетах и т.п.

### 4.2. Где это особенно полезно

1. **Head‑queries**
   - популярные запросы: «курсы доллара», «погода Москва», «кредит наличными»;
   - для них rerank (cross‑encoder) можно посчитать один раз и потом только переиспользовать.

2. **Статические корпуса**
   - FAQ, документация, справка;
   - корпус почти не меняется → scores долго остаются актуальными.

3. **Сценарии, где reranker очень тяжёлый**
   - большие cross‑encoder’ы,
   - много кандидатов (N=100–200),
   - GPU‑батчинг и очереди.

### 4.3. Ключ и версионирование

Примеры ключей:

1. Для пары query–doc:

```text
key = hash(
  query_text,
  doc_id,
  reranker_version,
  embedder_version,
  index_version
)
```

2. Для целого списка (реже, но бывает):

```text
key = hash(
  query_text,
  [doc_id_1, ..., doc_id_K],
  reranker_version,
  embedder_version,
  index_version
)
```

Важно включать:
- **reranker_version** — сменили модель → старые scores нельзя использовать;
- **embedder_version** и **index_version** — если изменились кандидаты или их приоритеты, старый порядок может быть невалиден.

### 4.4. Связь с embedding lifecycle и alias-switch

Когда мы:
- переходим на новый embedder (embedder_version v2),
- переиндексируемся и делаем alias‑switch (index_version v2),

то **все кэш‑слои** должны это почувствовать по ключам:
- embedding cache → новые ключи из‑за embedder_version v2;
- ANN‑topK cache → ключи с новым index_version;
- rerank cache → включает оба и reranker_version.

Иначе будет каша: кэшированные scores и топы перестанут соответствовать текущему пространству эмбеддингов.

### 4.5. Влияние кэша rerank’а на tail

Cross‑encoder обычно самый дорогой шаг до LLM.

- Для head‑queries rerank scores cache делает **latency почти константной** (кэш‑hit);
- p95/p99 rerank‑этапа сильно снижается: хвост остаётся только на cold‑кейсах;
- при высоких нагрузках кэш заметно разгружает GPU.

---

## 5. Тёплый vs холодный кэш и tail‑latency

### 5.1. Холодный запуск

После деплоя / перезапуска:
- кэши пусты → все запросы идут полной дорогой;
- p95/p99 выше, чем в steady‑state;
- нагрузка на embedder/ANN/rerank максимальная.

### 5.2. Тёплый кэш

Через некоторое время:
- head‑queries и head‑документы прогрелись,
- embedder cache + ANN cache + rerank cache сильно сокращают работу.

В steady‑state:
- p95/p99 по всему пайплайну ближе к «стоимости холодного хвоста на tail‑запросах + стоимости кэша для head»;
- пользовательский опыт стабилизируется.

### 5.3. Что важно измерять

1. Hit‑rate по каждому кэш‑слою (embedding / ANN‑topK / rerank).
2. p95/p99 по этапам **по сегментам**:
   - head queries (частые),
   - mid,
   - tail.
3. Разницу между холодным и тёплым состоянием.

Если кэш не даёт заметного эффекта:
- либо ключи выбраны плохо,
- либо TTL слишком мал,
- либо запросы в домене слишком уникальны и кэш нужен в других местах (например, на уровне doc features, а не query).