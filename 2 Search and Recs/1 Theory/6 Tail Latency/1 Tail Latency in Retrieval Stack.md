# Tail Latency in Retrieval Stack

## 0. Что такое tail‑latency

### 0.1. p50 / p90 / p95 / p99 / p999

Latency — случайная величина: каждый запрос имеет своё время ответа.
Мы смотрим на **квантили** распределения:

- **p50 (median)**: половина запросов быстрее, половина медленнее.
- **p90**: 90% запросов быстрее этого значения.
- **p95**: 95% быстрее.
- **p99**: 99% быстрее.
- **p999**: 99.9% быстрее.

**“Хвост распределения”** — это как раз область после p95/p99: редкие, но очень медленные запросы.

Интуиция:
- p50 говорит: *«как обычно»*.
- p99 говорит: *«как бывает в худших 1% случаев»*.
- p999 — *«самые адовые единичные запросы»*.

### 0.2. Почему средняя латентность мало что говорит

Средняя (mean) латентность — коварная штука:

- если 999 запросов по 50 мс и 1 запрос 5 секунд → средняя ≈ 55 мс.
  Звучит отлично, **но один пользователь из тысячи поймал 5 секунд**.
- Для пользователя важна не “средняя температура”, а **шанс попасть в лаг**.

Поэтому продуктовые SLO почти всегда задаются так:
- p95 ≤ X мс,
- p99 ≤ Y мс.

Потому что именно это определяет ощущение «сервис быстрый/тормозит».

### 0.3. Откуда берётся хвост (главные источники)

Хвост — это не одна причина, а смесь «редких плохих событий».

1. **Дисбаланс нагрузки по шардам/репликам**
   - Один шард перегружен (hot‑shard), другой простаивает.
   - Случайный запрос попал в перегруженный → улетел в хвост.

2. **Холодный кэш, GC, IO spikes**
   - cold cache: первые запросы после перезапуска/прогрева.
   - GC паузы (особенно в JVM‑движках, Python‑процессах с большим количеством объектов).
   - всплески IO: диск/сеть/облачный сторедж “подвис”.

3. **“Тяжёлые” запросы**
   - больше кандидатов (широкий запрос),
   - длинные тексты (больше токенов для embedder/LLM),
   - сложные фильтры (метаданные, geo, price‑ranges),
   - редкие сегменты, где индекс хуже локализует соседей.

4. **Вариативность сетевых задержек**
   - jitter в сети,
   - очереди на балансере,
   - деградация одной AZ/нод.

Важно: хвост появляется даже у «идеально оптимизированного» кода, если мир стохастичен (а он такой).

---

## 1. Tail‑latency в retrieval‑стеке

### 1.1. Типовой пайплайн

Векторный retrieval сегодня почти всегда цепочка:

1. **Embedder**
   - кодирует запрос/документ в вектор.
2. **ANN search**
   - быстро достаёт top‑N кандидатов.
3. **Reranker**
   - пересортировывает кандидатов (cross‑encoder / LTR).
4. **LLM stage** (если RAG/search)
   - читает top‑k, строит ответ.

### 1.2. Как хвост на любом этапе размазывается на всю систему

Если этапы выполняются последовательно, то

$$
T_{total} = T_{emb} + T_{ann} + T_{rerank} + T_{llm} + overhead
$$

Тогда **хвост любого компонента превращается в хвост всего пайплайна**:
- достаточно, чтобы **один** компонент оказался в p99 → весь запрос в p99.

Простой образ:
- пайплайн — как эстафета; если один бегун споткнулся, вся команда пришла последней.

### 1.3. Механика усиления хвоста

Есть три эффекта, из‑за которых хвост «ухудшается» дальше по стеку.

1. **Суммирование квантили не линейно**
   - p99 суммы обычно больше, чем сумма p99,
   - потому что редкие плохие события могут совпадать.

2. **Backpressure**
   - медленный ANN задержал поток → очередь на reranker,
   - очередь на reranker → задержка за счёт ожидания,
   - хвост сам себя усиливает.

3. **Адаптивная сложность**
   - “тяжёлый” запрос часто тяжёлый на всех этапах:
     длинный текст → медленный embedder → больше кандидатов → медленный rerank → больше токенов для LLM.

Именно поэтому иногда p99 системы вырастает в 3 раза, хотя «каждый компонент по отдельности вырос только на 20%».

---

## 2. Что измерять (минимальный набор)

Чтобы понимать хвост, нужно мерить не только total latency, но и **поэтапно**.

1. **Этапные метрики**
   - p50/p95/p99 для `T_emb`, `T_ann`, `T_rerank`, `T_llm`.

2. **Очереди и лимиты**
   - depth очереди на каждом сервисе,
   - время ожидания в очереди.

3. **Профили запросов**
   - длина текста,
   - число кандидатов N,
   - число фильтров,
   - shard/replica id.

Без этого ты видишь хвост, но не понимаешь, кто его создал.

---

## Как это выглядит в жизни

1. **Hot‑shard в ANN**
   - 1% запросов летит в p99, потому что попадает в один перегруженный шард.
   - p50 нормальный, средняя нормальная, пользователи пишут «иногда тупит».

2. **Cold cache после деплоя**
   - первые 10–30 минут p99 в 5–10 раз выше.
   - если деплой днём — ты ловишь волну жалоб, хотя через час всё ок.

3. **Длинные tail‑запросы в RAG**
   - “вопрос‑письмо” на 700 токенов → embedder + LLM становятся хвостом.
   - именно эти запросы формируют p99, хотя их мало.

---

## 4. Что делать с хвостом (коротко)

1. **Разделяй latency по этапам** → найдёшь виновника.
2. **Лимитируй сложность запросов**
   - max tokens, max candidates, max filters.
3. **Сглаживай hot‑shards**
   - правильный шард‑ключ,
   - репликация, adaptive routing.
4. **Кэш + прогрев при деплое**
   - warmup для embedder/ANN.
5. **Timeouts и fallback**
   - лучше быстрый “чуть хуже” ответ, чем 5 секунд тишины.