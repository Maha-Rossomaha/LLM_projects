# Adaptive to SLA

## 1. База: IVF и HNSW, какие ручки есть

### 1.1. IVF (Inverted File Index)

Идея IVF:
- пространство делим на **nlist** кластеров (centroids),
- каждый вектор попадает в один или несколько кластеров,
- при запросе считаем embedding запроса и смотрим **только часть кластеров**, а не весь индекс.

Параметры:
- **nlist** — количество кластеров (ячейки).
  - больше nlist → кластеры мельче → потенциально выше качество, но больше overhead на построение и выбор кластеров.
- **nprobe** — сколько кластеров мы **просматриваем при запросе**.
  - маленький nprobe → мало кластеров, быстрый ответ, но можно пропустить релевантные соседи;
  - большой nprobe → смотрим больше кластеров, лучше recall, но медленнее.

IVF‑интуиция:
> nlist ~ «разрешение пространства», nprobe ~ «насколько широко мы его просматриваем».

### 1.2. HNSW (Hierarchical Navigable Small World)

HNSW — графовая структура, где у тебя есть многоуровневый граф соседства. 
Мы ищем ближайших соседей, «гуляя» по графу.

Параметры построения:
- **M** — среднее число связей (degree) у вершины.
  - больше M → граф более плотный, лучше качество, но больше память/время построения.
- **efConstruction** — насколько тщательно ищем соседей при построении.
  - больше efConstruction → лучше структура, лучше качество, но дороже build.

Параметр поиска:
- **efSearch** — ширина/глубина поиска при запросе.
  - маленький efSearch → поиск обрываем рано, быстрый, но хуже recall;
  - большой efSearch → исследуем больше узлов, лучше recall, но медленнее.

HNSW‑интуиция:
> efSearch — «сколько мы готовы побродить по графу, прежде чем сказать “хватит, вот соседи”».

---

## 2. Trade-off качество ↔ latency

### 2.1. Как растёт recall@K

Если зафиксировать nlist/M/efConstruction и увеличивать **nprobe (IVF)** или **efSearch (HNSW)**:
- recall@K **монотонно растёт**, но с убывающей отдачей:
  - вначале каждый шаг сильно улучшает качество,
  - дальше приходим к плато: +10 к efSearch даёт +0.001 к recall.

Графически: кривая напоминает логистику / затухающую.

### 2.2. Как растёт latency

Latency растёт почти линейно/квазилинейно:
- больше кластеров (nprobe) или вершин (efSearch) → больше сравнений расстояний → больше CPU/памяти/IO.

По факту:
- $T \approx a + b \cdot nprobe$ (для IVF),
- $T \approx a' + b' \cdot efSearch$ (для HNSW),

где a, a' — оверхед, b, b' — «цена» одного добавочного шага.

### 2.3. Кривые «recall vs latency»

Чтобы не гадать, строят эмпирические кривые.

Процедура:
1. Берём eval‑датасет запросов + ground truth nearest neighbors.
2. Прогоняем его по индексу с разными настройками nprobe/efSearch.
3. Для каждой настройки считаем:
   - средний/median/p95/p99 latency,
   - recall@K.
4. Строим график: по оси X — latency (например, p95), по оси Y — recall@K.

Получаем **«Pareto‑фронт»**:
- точки, где за тот же latency есть лучший recall,
- точки, где за тот же recall есть меньший latency.

На этот фронт потом навешивают SLA.

---

## 3. Adaptive policies: подстраиваем nprobe/efSearch под SLA

Предположим, SLA/SLO выглядит так:
- **p95 latency < 200 мс**, 
- **offline recall@50 ≥ 0.95** (на важных сегментах).

Задача: подобрать политику, которая динамически выбирает nprobe/efSearch, чтобы:
- не вываливаться из latency‑SLO,
- и не просаживать recall ниже минимального уровня.

### 3.1. Политики по текущей нагрузке

Идея: если кластер нагружен, надо чуть экономить на качестве; если свободен — можно «крутить ручки на максимум».

Примеры сигналов нагрузки:
- текущий QPS,
- CPU/IO utilization на нодах ANN,
- глубина очереди запросов.

**Пример ступенчатой политики для IVF:**

- low load (CPU < 50%, queue depth ~ 0):
  - `nprobe = 16` (максимальное качество);
- medium load (CPU 50–75% или небольшая очередь):
  - `nprobe = 8`;
- high load (CPU > 75% или очередь растёт):
  - `nprobe = 4`.

Аналогично для HNSW:
- low load → `efSearch = 256`, 
- medium → `128`,
- high → `64`.

**Линейная/плавная функция:**

Можно задать зависимость вида:
$$
 nprobe(load) = nprobe_{min} + (nprobe_{max} - nprobe_{min}) \cdot (1 - load\_normalized)
$$

где `load_normalized ∈ [0, 1]` (например, CPU‑util кладём в этот интервал).

### 3.2. Политики по типу запроса / сегменту

Не все запросы одинаково важны.

Примеры сегментов:
- premium / платный трафик,
- критические маршруты (оплаты, рисковые решения),
- внешние пользователи vs внутренняя аналитика.

Политика:
- для **важных сегментов** держим **высокий nprobe/efSearch**, даже при высокой нагрузке;
- для обычных/внутренних запросов можем сильнее ужиматься.

Пример:
- premium user + normal load → `efSearch = 256`;
- обычный user + high load → `efSearch = 64`;
- offline batch аналитика → `efSearch = 32` (максимальная экономия).

### 3.3. Адаптация по очереди/latency в реальном времени

Ещё одна ось адаптации — **смотреть прямо на latency и очереди ANN‑сервиса**.

Пример псевдокода:

```python
# inputs: current_p95, target_p95, queue_depth
if queue_depth > Q_HIGH or current_p95 > target_p95 * 1.2:
    # слишком медленно / большая очередь — урезаем качество
    nprobe = max(nprobe_min, nprobe - 1)
elif queue_depth < Q_LOW and current_p95 < target_p95 * 0.8:
    # всё хорошо — можно чуть повысить качество
    nprobe = min(nprobe_max, nprobe + 1)
```

Эта политика «подстраивает» параметр в сторону нужного SLO.

Важно: корректировать параметр **медленно** (по чуть‑чуть), чтобы не раскачивать систему.

---

## 4. Пограничные случаи и pitfalls

### 4.1. Когда adaptive шатает качество

Опасность: при сильной адаптации по нагрузке можно внезапно просадить качество:
- вечером вырастает QPS → политика агрессивно режет nprobe/efSearch,
- recall падает заметно,
- пользователи в прайм‑тайм получают хуже поиск.

Чтобы этого не произошло, нужна связка с **quality guardrails**:

- оффлайн: проверить, что при минимально допустимом nprobe/efSearch recall ≥ порога;
- онлайн: мониторить proxy‑метрики качества (CTR, successful clicks, жалобы) по сегментам.

### 4.2. Баги в SLA и где хранить реальные p95/p99

Ещё один типичный фейл:
- SLA прописали на бумаге,
- но нигде **централизованно не считаются и не хранятся** p95/p99 по этапам.

Нужно:
1. Явный мониторинг ANN‑этапа: `lat_p50`, `lat_p95`, `lat_p99`, queue depth.
2. История этих метрик (time series), чтобы адаптивная политика могла опираться не на разовый спайк.
3. Возможность быстро подглядеть, **какие настройки nprobe/efSearch действовали**, когда p99 вылетел.

Без этого адаптивная схема превращается в «магическую коробку», которую никто не понимает.

### 4.3. Слишком частая адаптация

Если менять nprobe/efSearch слишком часто (каждые пару секунд на основании маленького окна), получаем:
- флуктуации качества и latency,
- сложность анализа инцидентов.

Лучше:
- использовать сглаженные метрики (moving average),
- обновлять параметры раз в N секунд/минут,
- иметь **минимальный и максимальный** уровень, ниже/выше которых алгоритм не ходит.

### 4.4. Неоднородность по шард‑ключу

Иногда адаптация делается глобально, а проблема локальна:
- один шард перегружен и у него хвост,
- адаптация режет nprobe для всех, хотя надо лечить конкретный шард.

Значит, часть логики стоит делать **per‑node/per‑shard**, а не только глобально.