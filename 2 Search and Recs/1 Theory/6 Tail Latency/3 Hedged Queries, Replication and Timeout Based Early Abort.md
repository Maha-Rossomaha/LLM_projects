# Hedged Queries, Replication and Timeouy Based Early Abort

## 1. Репликация и распределённый поиск

### 1.1. Зачем вообще нужны реплики

**Реплика индекса/сервиса** — это копия данных + логики на другой ноде.

Зачем:
- **Read scaling**: можно распределить запросы по нескольким нодам и обслуживать больше QPS.
- **Fault tolerance**: падение одной ноды не приводит к полной остановке сервиса.
- **Maintenance без даунтайма**: можно выводить часть реплик в обновление.
- **Geo/zone‑размещение**: ближе к пользователю, ближе к данным.

### 1.2. Как репликация помогает p99 даже без hedged

Даже если ты отправляешь каждый запрос только на одну реплику, репликация всё равно помогает хвосту:

1. **Балансировка нагрузки**  
   - LB может распределять запросы равномерно; меньше шанс получить *super‑hot* ноду.

2. **Health‑based routing**  
   - если одна реплика деградировала (CPU, GC, диск), её можно временно выключить из ротации.

3. **Shard rebalancing**  
   - с репликами легче разнести hot‑shards по разным нодам.

Интуитивно: p99 падает уже от того, что «редкие медленные ноды» меньше влияют на общий поток.

---

## 2. Hedged queries

### 2.1. Идея

**Hedged query** — это стратегия:  
*«отправь запрос дважды (или на несколько реплик) и возьми первый ответ»*.

Она помогает, когда задержки по репликам **heavy‑tailed**: иногда одна нода внезапно очень медленная, а остальные в норме.

### 2.2. Базовый алгоритм с задержкой Δt

1. Приходит запрос.
2. Отправляем его на **основную реплику R1**.
3. Ждём до Δt миллисекунд.
4. Если за это время ответ не пришёл:
   - отправляем **дубликат** на вторую реплику R2.
5. Берём **первый завершившийся ответ** (R1 или R2).  
   Второй **отменяем**, если можем, или игнорируем, если отмена невозможна.

Вариант без задержки: сразу отправлять на две реплики, но это удваивает QPS всегда, а не только для хвостовых запросов.

### 2.3. Когда это окупается

Hedged queries особенно полезны, если:

1. **Распределение задержек heavy‑tailed**  
   - большинство запросов быстрые,
   - но иногда отдельная реплика «залипает» на GC/IO/CPU.

2. **Есть достаточное количество реплик**  
   - как минимум 2–3 рабочие копии,
   - вероятность, что все одновременно улетят в хвост, мала.

3. **Кластер не стоит на пределе CPU/IO**  
   - hedging увеличивает суммарный QPS (часть запросов будет дублироваться),
   - если ресурсов нет, можно только добить систему.

Для retriever‑сервисов это часто хороший trade‑off: p99 падает сильно, а overhead по QPS ограничен хвостовыми случаями.

### 2.4. Как выбирать Δt

Δt — ключевой параметр. Если сделать его слишком маленьким, ты будешь **слишком часто** посылать дубликаты. Если слишком большим — не успеешь «перехватить» хвост.

Подход:

1. **Смотрим распределение задержек без hedged**  
   - строим CDF или просто квантили p50/p90/p95/p99.

2. **Выбираем Δt где‑то между p50 и p95**  
   - идея: дать шанс «нормальным» запросам на R1 ответить,  
     и хеджить только ту часть, которая уже выглядит как хвост.

3. **Оценка overhead по QPS**

Пусть `F(t)` — CDF задержек на одной реплике.  
Тогда доля запросов, которые не ответили к моменту Δt (и будут захеджены), равна `1 - F(Δt)`.

- если Δt = p50 → около 50% запросов будут хеджиться,
- если Δt ≈ p95 → около 5% запросов будут хеджиться,
- если Δt ≈ p99 → это почти не помогает, потому что хвост уже случился.

4. **Практическое правило**

- начать с Δt ~ p90/p95,
- посмотреть, как меняются p95/p99 и общий QPS,
- дальше подпилить Δt под свои SLO и capacity.

### 2.5. Важные детали реализации

1. **Идемпотентность**  
   - сервис должен корректно обрабатывать дубликаты (по request_id).

2. **Отмена/игнор второго ответа**  
   - если есть протокол отмены — шлём cancel,
   - иначе на стороне клиента игнорируем любой ответ после первого.

3. **Scope применения**  
   - можно применять не ко всем запросам, а только к:
     - самым важным (head, платный трафик),
     - детектируемым хвостовым (по признакам профиля запроса).

4. **Где hedging особенно полезен**  
   - ANN‑сервисы (vector DB),
   - LLM‑прокси (если есть несколько провайдеров/реплик),
   - удалённые heavy сервисы, где много GC/IO‑спайков.

---

## 3. Timeout-based early abort

### 3.1. Идея

**Timeout-based early abort** — это стратегия:  
*«не ждать бесконечно; если этап не уложился в бюджет, прекращаем его и деградируем ответ»*.

То есть вместо:
- «лучше поздний идеальный ответ, чем никакой»,

мы делаем:
- «лучше быстрый чуть ухудшенный ответ, чем 3 секунды ожидания».

### 3.2. Таймауты из latency budget

Если у тебя есть per‑stage budget (например, из предыдущего конспекта):
- $T_{emb} \le 40 м\text{с}$,
- $T_{ann} \le 80 м\text{с}$,
- $T_{rerank} \le 120 \text{мс}$,
- $T_{llm} \le 300 \text{мс}$,

то таймауты ставятся чуть больше этих значений (чтобы оставить запас на сеть и очереди).

Пример:
- $\text{timeout}_\text{emb} = 50 \text{мс}$,
- $\text{timeout}_\text{ann} = 120 \text{мс}$,
- $\text{timeout}_\text{rerank} = 180 \text{мс}$,
- $\text{timeout}_\text{llm} = 350 \text{мс}$.

Если этап не успевает — мы:
- возвращаем fallback,
- пропускаем этап,
- сокращаем объём работы (например, меньше кандидатов/меньше токенов).

### 3.3. Типы деградации

1. **Пропустить тяжёлый этап**
   - не успел reranker → возвращаем raw ANN выдачу,
   - не успел LLM полный ответ → отдаём короткий/частичный.

2. **Упрощённый режим**
   - сокращаем N кандидатов,
   - ограничиваем длину контекста,
   - включаем более простой/быстрый ранжировщик.

3. **Кэш/предзаготовки**
   - если есть кэш прошлых результатов для пользователя/запроса,  
     используем его как fallback.

### 3.4. Связка с hedged queries

Hedged queries и timeouts сочетаются так:

1. На **каждой реплике** есть свой timeout.
2. Hedging запускаем до того, как сработает общий timeout этапа.
3. Если даже хедж не помог и timeout произошёл, включается fallback.

Интуиция: hedging уменьшает шанс поймать хвостовую ноду,  
timeouts спасают от ситуаций, когда все реплики «пошли гулять».

### 3.5. Ограничение

Применяя early abort, нужно помнить:
- мы сознательно ухудшаем качество;  
- поэтому важно явно контролировать долю запросов, на которых срабатывает timeout и fallback.

---

## 4. Когда всё это реально даёт профит

### 4.1. Условия, при которых hedged + timeouts работают хорошо

1. **Heavy‑tailed latency** по репликам.
2. **2+ реплики** в зоне, к которым можно быстро обратиться.
3. **Запас по ресурсам** (CPU/IO), чтобы выдержать дополнительные дубликаты.
4. **Готовность к деградации качества** на малой доле запросов.

### 4.2. Что нужно мониторить

1. p95/p99/p999 по этапам и по total.  
2. Долю запросов, где:
   - сработал hedging (отправили второй запрос),
   - победила вторая реплика,
   - сработал timeout и включился fallback.

3. Бизнес‑метрики по этим запросам:  
   - CTR/успешность,  
   - жалобы/ошибки.

Если p99 сильно падает, а доля fallback‑ответов < 1–2% и качество по ним терпимое — значит, схему настроили хорошо.