# Quality Guardrails 

## 0. Зачем нужны guardrails

Когда ты меняешь эмбеддинги, ANN‑параметры, reranker или фильтры, ты хочешь два гарантируемых свойства.

1. **Качество не ухудшилось** (или ухудшилось только там, где ты готов это принять).
2. **Система не стала медленнее/нестабильнее**.

Это и есть guardrails.

Обычно их делят на:
- **quality guardrails**: ΔRecall@K, ΔnDCG, coverage,
- **performance guardrails**: latency p95/p99, error rate, timeouts,
- **business guardrails**: CTR/CR/GMV/retention/complaints.

---

## 1. ΔRecall@K

### 1.1. Смысл

**Recall@K** отвечает на вопрос: *«как часто в топ‑K выдачи есть правильные (релевантные) объекты?»*

Для retriever’а это самая базовая “безопасная” метрика: если recall упал — значит система стала хуже находить нужное.

**ΔRecall@K** — разница между новой и старой версией.
- положительная → улучшение,
- отрицательная → регрессия.

### 1.2. Расчёт

Есть датасет запросов Q с известными релевантными документами `Rel(q)`.

Для каждого запроса:
- `TopK(q)` — выдача по системе,
- `hit(q) = 1`, если `TopK(q) ∩ Rel(q) ≠ ∅`, иначе 0.

Тогда
$$
Recall@K = \frac{1}{|Q|}\sum_{q\in Q} hit(q)
$$

И
$$
\Delta Recall@K = Recall@K_{v2} - Recall@K_{v1}
$$

### 1.3. Нюансы

- Если у запроса много релевантных объектов, можно считать «долю найденных релевантных», но в retriever‑guardrails чаще берут бинарный hit для простоты.
- Считай отдельно по сегментам: head/mid/tail, язык, регион, тип запроса.

---

## 2. ΔnDCG

### 2.1. Смысл

Recall@K говорит “нашли ли мы хоть что‑то правильное”.

**nDCG@K** отвечает на вопрос *«насколько высоко в топ‑K стоят правильные объекты?»*.
То есть это метрика **качества ранжирования внутри топа**.

**ΔnDCG** показывает, стало ли ранжирование лучше/хуже после изменений.

### 2.2. Расчёт

Для каждого запроса есть бинарные или градуированные релевантности `rel_i` у позиции i.

DCG:
$$
DCG@K = \sum_{i=1}^{K} \frac{2^{rel_i}-1}{\log_2(i+1)}
$$

IDCG — DCG для идеального (отсортированного по релевантности) списка.

Нормализуем:
$$
nDCG@K = \frac{DCG@K}{IDCG@K}
$$

Разница версий:
$$
\Delta nDCG@K = nDCG@K_{v2} - nDCG@K_{v1}
$$

### 2.3. Нюансы

- Если лейблы только бинарные, nDCG всё равно полезен: штрафует «правильное, но на 9‑й позиции».
- В RAG важно брать nDCG не только по true‑doc, но и по “группам документов‑эквивалентов”.

---

## 3. Bootstrap CI

### 3.1. Смысл

Одна разница метрик ничего не значит без понимания **статзначимости**.

**Bootstrap CI** даёт доверительный интервал для Δметрики без сложностей использования мат статистики.

Ты проверяешь: *«ноль попал в интервал или нет?»*
- если **ноль вне интервала** → изменение статистически значимо,
- если **ноль внутри** → эффект может быть шумом.

### 3.2. Как считать

Пусть у тебя есть список per‑query значений `m_v1(q)` и `m_v2(q)`.

1. Делаешь B раз (обычно 1000–5000):
   - случайно выбираешь |Q| запросов **с возвращением**,
   - считаешь метрику на этой подвыборке,
   - сохраняешь Δ.
2. Получаешь распределение Δ.
3. Берёшь, например, 2.5% и 97.5% квантили → 95% CI.

### 3.3. Практическое правило

Guardrail формулируют так:
- «ΔRecall@K >= -0.002 и 95% CI не пересекает -0.002»
- «ΔnDCG@K >= 0»

То есть ты заранее задаёшь **допустимую просадку**.

---

## 4. Latency regression tests (ANN + rerank)

### 4.1. Смысл

Retriever‑pipeline часто двуступенчатый:
1. **ANN поиск** выбирает кандидатов (быстро, грубо).
2. **Reranker** уточняет порядок (медленнее, умнее).

Регрессия может случиться в любом шаге, поэтому latency нужно мерить раздельно и вместе.

### 4.2. Что мерить

- `t_ann` — время kNN (p50/p95/p99).
- `t_rerank` — время rerank (на N кандидатов).
- `t_total = t_ann + t_rerank + overhead`.
- error/timeout rate.

### 4.3. Regression‑критерии

Пример guardrail:
- `p95(t_ann)` не хуже чем +10% от baseline.
- `p99(t_total)` не хуже чем +15%.
- timeout rate не вырос.

Это важно, потому что качество легко “купить” ценой взрыва latency.

---

## 5. Как реализовать мониторинг guardrails

### 5.1. Оффлайн регресс‑пакет

Периодичность: при каждом релизе модели/индекса и по расписанию (например, ежедневный sanity).

Шаги.
1. Берёшь **фиксированный eval‑набор запросов** (и сегменты).
2. Прогоняешь через v1 и v2.
3. Считаешь Recall@K, nDCG@K.
4. Считаешь bootstrap CI для Δ.
5. Сравниваешь с порогами.
6. Печатаешь отчёт и “светофор”.

Результат: релиз не проходит, если нарушен guardrail.

### 5.2. Shadow‑serve онлайн мониторинг

Пока v2 в тени:
- на каждый реальный запрос делай shadow‑запрос в v2,
- логируй top‑k и latency.

Дальше:
- считаешь Δметрики по лейблам (если есть) или прокси‑лейблам,
- смотришь распределение latency.

Это ловит баги, которые не видны на оффлайн‑наборе.

### 5.3. Canary с guardrails

Канарейка запускается только если оффлайн guardrails зелёные.

Во время canary:
- realtime метрики качества (если есть лейблы) или бизнес‑прокси,
- latency p95/p99,
- алерт на превышение порога → авто‑rollback.

### 5.4. Что хранить в логах

Минимальный формат лога:
- `query_id, user_segment, version, topk_ids, latency_ann, latency_rerank, latency_total`.

Без этого потом невозможно честно посчитать Δ и понять где регрессия.