# RecSys Intro

## 1. Content-based (item-centric)

Идея: описываем каждый объект (item) признаками и строим профиль пользователя как агрегат признаков просмотренных/купленных объектов.

### 1.1. Представление item

Каждый объект описываем вектором признаков $v_i$:

- категория (one-hot или embedding),
- теги (multi-hot / embedding),
- бренд,
- цена (логарифм, биннинг),
- текст описания (TF-IDF, BM25, text-embedding),
- картинка (image-embedding), если нужно.

В итоге получаем вектор $v_i \in \mathbb R^d$.

### 1.2. Профиль пользователя

Пусть пользователь посмотрел/купил объекты $i_1, \dots, i_k$.

Простейший профиль:

$$
u = \text{avg}(v_{i_1}, \dots, v_{i_k}).
$$

Можно сделать взвешенное среднее по типу действий:

$$
u = \frac{\sum_{j=1}^k w_{a_j} v_{i_j}}{\sum_{j=1}^k w_{a_j}},
$$

где $a_j$ — тип действия (view / like / purchase), а $w_{a_j}$ — вес действия (например, покупка важнее просмотра).

### 1.3. Скоринг кандидатов

Скор для пары $(u, i)$ часто берут как схожесть векторов:

$$
score(u, i) = \cos(u, v_i) = \frac{\langle u, v_i \rangle}{\lVert u \rVert \, \lVert v_i \rVert},
$$

или другую similarity (dot-product, L2-distance со знаком минус и т.п.).

На практике:

1. Собираем список кандидатов (по популярности, по фильтрам, по поисковому запросу).
2. Считаем $score(u, i)$ для каждого кандидата.
3. Сортируем по убыванию score.

### 1.4. Особенности content-based

**Плюсы:**

- почти не страдает от cold-start items: если у нового товара есть мета-фичи, его можно сразу представить вектором $v_i$;
- легко дообогатить модель (новые признаки → новая версия $v_i$);
- можно использовать мощные zero-shot эмбеддеры текста/картинок (E5, BGE-M3, CLIP и т.п.).

**Минусы:**

- плохо учитывает «коллективную мудрость» (collaborative эффекты): два пользователя с похожими вкусами, но разной историей, могут получить разные рекомендации;
- сложно напрямую учесть популярность, сезонность, эффекты позиций и др. поведенческие паттерны без дополнительных моделей.

---

## 2. Collaborative filtering (user-based / item-based kNN)

Collaborative filtering (CF) использует структуру взаимодействий, а не только контент.

### 2.1. Матрица взаимодействий

Пусть $U$ — множество пользователей, $I$ — множество объектов.

Матрица взаимодействий:

$$
R \in \mathbb R^{|U| \times |I|},
$$

где элемент $r_{u,i}$ — рейтинг/клик/просмотр (явный или имплиситный сигнал).

Примеры $r_{u,i}$:

- рейтинг 1–5 (явный),
- бинарный клик $0/1$ (implicit),
- взвешенный счётчик взаимодействий.

### 2.2. User-based kNN

Идея: ищем пользователей, похожих на текущего, и рекомендуем то, что они смотрели.

1. Строка $R_u$ — вектор взаимодействий пользователя $u$ (его row в матрице $R$).
2. Определяем похожесть между пользователями, например, косинусную:

   $$
   sim(u, v) = \cos(R_u, R_v).
   $$

3. Для пользователя $u$ выбираем $k$ ближайших соседей по $sim(u, v)$.
4. Считаем «оценку» объекта $i$ для $u$ как агрегат по соседям (вариантов много):

   $$
   \hat r_{u,i} = \sum_{v \in N_k(u)} sim(u, v) \cdot r_{v,i}.
   $$

Рекомендуем объекты с максимальным $\hat r_{u,i}$, которых $u$ ещё не видел.

### 2.3. Item-based kNN

Зеркальная идея: ищем похожие объекты.

1. Столбец $R^i$ — вектор взаимодействий с объектом $i$.
2. Похожесть объектов:

   $$
   sim(i, j) = \cos(R^i, R^j),
   $$

   либо Jaccard по множествам пользователей, которые взаимодействовали с $i$ и $j$.

3. Для каждого объекта $i$, с которым взаимодействовал пользователь $u$, находим $N_k(i)$ — похожие объекты.
4. Рекомендуем объединённый список похожих объектов, возможно с взвешиванием по $sim(i, j)$ и важности исходных объектов в истории пользователя.

### 2.4. Метрики похожести

Часто используются:

- косинусная похожесть (cosine similarity),
- Jaccard (если работаем с бинарными множества ми пользователей),
- корреляция Пирсона (для рейтингов с центровкой).

Пример Jaccard между двумя объектами $i, j$:

$$
J(i, j) = \frac{|U_i \cap U_j|}{|U_i \cup U_j|},
$$

где $U_i$ — множество пользователей, взаимодействовавших с объектом $i$.

### 2.5. Особенности CF kNN

**Плюсы:**

- использует коллективную информацию: «пользователи, похожие на тебя, смотрели X»;
- иногда даёт очень интерпретируемые рекомендации (особенно item-based: «похожее на этот фильм»).

**Минусы:**

- плохо работает при очень холодных пользователях/товарах (нет соседей, пустые строки/столбцы в $R$);
- страдает от разреженности: оценка похожести может быть шумной, если пересечений мало;
- масштабирование kNN на миллионы пользователей и объектов требует хитрых структур данных и/или приближённых методов.

---

## 3. Matrix Factorization (MF: ALS, BPR и др.)

Matrix factorization — шаг от «буквальных соседей» к скрытым факторам.

### 3.1. Базовая идея

Хотим аппроксимировать матрицу взаимодействий $R$ произведением двух низкоранговых матриц:

$$
R \approx U V^\top,
$$

где:

- $U \in \mathbb R^{|U| \times k}$ — матрица user-факторов (эмбеддинги пользователей),
- $V \in \mathbb R^{|I| \times k}$ — матрица item-факторов (эмбеддинги объектов),
- $k \ll \min(|U|, |I|)$ — размерность скрытого пространства.

Предсказанное взаимодействие:

$$
\hat r_{u,i} = \langle u_u, v_i \rangle = u_u^\top v_i,
$$

где $u_u$ — $k$-мерный вектор пользователя, $v_i$ — $k$-мерный вектор объекта.

### 3.2. ALS (Alternating Least Squares)

Для явных рейтингов можно оптимизировать квадратную ошибку с регуляризацией:

$$
\min_{U, V} \sum_{(u,i) \in \mathcal O} (r_{u,i} - u_u^\top v_i)^2 + \lambda (\lVert u_u \rVert^2 + \lVert v_i \rVert^2),
$$

где $\mathcal O$ — множество наблюдаемых пар $(u,i)$.

ALS по очереди оптимизирует $U$ при фиксированном $V$ и наоборот (каждый шаг — набор независимых задач линейной регрессии).

### 3.3. BPR (Bayesian Personalized Ranking)

Для имплиситных данных (клики/просмотры) часто оптимизируют **pairwise ranking** вместо MSE.

Идея: для пользователя $u$ объект $i$ с взаимодействием должен ранжироваться выше, чем объект $j$ без взаимодействия.

Формально:

- есть тройки $(u, i, j)$, где $i$ — «позитивный» item (у пользователя $u$ есть взаимодействие), $j$ — «негативный» (нет взаимодействия);
- хотим, чтобы $\hat r_{u,i} > \hat r_{u,j}$.

Loss BPR:

$$
\mathcal L_{\text{BPR}} = - \sum_{(u,i,j)} \log \sigma(\hat r_{u,i} - \hat r_{u,j}) + \lambda (\lVert u_u \rVert^2 + \lVert v_i \rVert^2 + \lVert v_j \rVert^2).
$$

Здесь $\sigma$ — сигмоида.

### 3.4. Плюсы MF

- учитывает скрытые факторы вкусов и похожести: векторы $u_u$ и $v_i$ могут кодировать сложные паттерны;
- хорошо работает для warm-users / warm-items, когда у них есть история;
- даёт компактные эмбеддинги, пригодные для интеграции в другие модели (two-tower, LTR и т.д.).

### 3.5. Минусы «чистой» MF

- чистая MF по id-шникам плохо работает для cold-items и cold-users: для новых пользователей/объектов нет обученных векторов $u_u, v_i$;
- сложно использовать контент (категорию, текст, цену) без расширения модели (factorization machines, нейронные расширения, гибридные модели);
- требует аккуратной работы с разреженностью и регуляризацией.

На практике MF часто выступает как базовая модель для «тёплой» зоны (warm users/items), а для cold-start добавляют content-based и/или дополнительные ML-модели поверх.

---

## 4. Как эти три подхода сочетаются

В реальных системах они почти никогда не используются по одному:

- **Content-based** — даёт основу для cold-items и объяснимых признаков.
- **CF kNN** — добавляет «коллективную мудрость» и простые похожести «люди, похожие на тебя» или «похожие товары».
- **MF** — даёт компактное скрытое пространство вкусов и позволяет эффективно делать персонализацию для warm-зоны.

Дальше на эту базу уже навешиваются:

- two-tower модели (где фактически делаем обучаемый MF с признаками),
- графовые модели типа LightGCN,
- bandit-алгоритмы для exploration,
- сложные ранжирующие модели (GBDT/NN) для reranking.