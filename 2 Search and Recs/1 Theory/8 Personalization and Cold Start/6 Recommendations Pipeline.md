# Как всё живёт вместе: пайплайн рекомендаций и взаимодействие алгоритмов

Этот конспект — «склейка» всех предыдущих модулей:

- базовые модели (content-based, CF kNN, MF),
- cold-start items/users (meta-features, zero-shot, граф),
- two-tower и LightGCN,

и то, **как они взаимодействуют в одном пайплайне**.

---

## 0. Общая картина пайплайна

Типичный продовый рексистем-пайплайн:

1. **Candidate generation (retrieval)** — быстро выбираем из миллионов объектов несколько сотен/тысяч кандидатов.
2. **Ranking** — более тяжёлая модель, которая сортирует кандидатов по вероятности клика/покупки/просмотра.
3. **Бизнес-логика и фильтры** — пост-обработка ранжированного списка (дедупликация, блок-листы, ограничения частот и т.п.).

В candidate generation обычно живут:

- популярность/тренды,
- content-based методы,
- CF / MF / two-tower / LightGCN,
- спец-источники (поиск, ручные подборки, рекламные блоки).

В ranker’е живёт мощная ML-модель (GBDT/NN), которая объединяет всё — user-фичи, item-фичи, графовые и контентные эмбеддинги.

---

## 1. Многоступенчатый стек кандидатов

### 1.1. Candidate generation

Задача: для конкретного пользователя $u$ и/или контекста $c$ выбрать множество кандидатов $C(u,c)$ из большого каталога $I$:

$$
C(u,c) \subset I, \quad |C(u,c)| \ll |I|.
$$

Обычно кандидатов берут из **нескольких источников** (recall-каналов).

#### 1.1.1. Популярные и тренды

- **Global popular**: объекты с высоким CTR/конверсией в целом.
- **Segment popular**: популярные в сегменте (страна, язык, платформа, категория).
- **Trending**: объекты с резким ростом показов/кликов за последние $N$ часов.

Используются как:

- базовый fallback для всех,
- источник кандидатов для cold-start пользователей.

#### 1.1.2. Content-based кандидаты

Работают, даже если мало истории:

1. **Meta-features**: категория, цена, бренд, теги и др.
2. **TF-IDF / BM25** на текстах (описания, заголовки, отзывы).
3. **Zero-shot эмбеддинги** (E5, BGE-M3, GTE и т.п.):
   - $e_i = \text{Encoder}(\text{text}_i)$ для объекта,
   - $e_u$ — агрегат эмбеддингов просмотренных объектов или persona.

Dense retrieval:

- строим ANN-индекс по $e_i$,
- для $e_u$ ищем ближайшие $K$ соседей по косинусу / dot-product.

Content-based источник кандидатов хорош для:

- cold-items (новый объект сразу попадает в ANN по тексту/мета-фичам),
- cold-users с persona/контекстом.

#### 1.1.3. Collaborative источники (warm-зона)

Когда user и/или item достаточно тёплые, включаются **коллаборативные** модели:

1. **User-based / item-based kNN**:
   - "похожие пользователи смотрели" / "похожие объекты";
   - работает на матрице $R$.

2. **Matrix Factorization / BPR**:
   - $R \approx U V^\top$, $
     \hat r_{u,i} = \langle u_u, v_i \rangle$;
   - candidate generation: берём топ-$K$ объектов по $
     \hat r_{u,i}$ для каждого пользователя.

3. **Two-tower**:
   - user-эмбеддинг $u = f_u(\text{user\_features})$;
   - item-эмбеддинг $v = f_i(\text{item\_features})$;
   - retrieval через ANN по $
     \langle u, v_i \rangle$;
   - учитывает и id, и фичи → работает и для warm, и для частичной cold-зоны.

4. **LightGCN / GraphCF**:
   - user×item граф,
   - эмбеддинги $e_u, e_i$ после нескольких слоёв message passing,
   - retrieval так же через dot-product.

Каждый из этих источников возвращает свой список кандидатов; затем их **объединяют и дедуплицируют**.

### 1.2. Ranking

После candidate generation получаем $C(u,c) = \{i_1, \dots, i_K\}$.

Ranker — тяжёлая модель, которая для каждой пары $(u,i)$ считает скор:

$$
score(u,i) = F(\text{user-features}, \text{item-features}, \text{user} \times \text{item-features}, \text{context}).
$$

Типичные варианты $F$:

- градиентный бустинг (CatBoost / XGBoost / LightGBM),
- нейронные модели (MLP, Wide&Deep, DeepFM, DIN/DIEN и др.).

#### 1.2.1. User-фичи

- демография (возраст, пол, регион),
- device / канал (iOS/Android/Web, organic/ads),
- persona embedding (из анкеты/текстов),
- агрегированные фичи истории:
  - число покупок в категории X,
  - средний чек,
  - recency/frequency (RFM),
  - user-эмбеддинги из MF/two-tower/LightGCN.

#### 1.2.2. Item-фичи

- мета-информация: категория, бренд, цена, скидка,
- текстовые фичи (TF-IDF, эмбеддинг),
- визуальные фичи (image embedding),
- глобальные метрики: CTR, конверсия, тренды,
- item-эмбеддинги из MF/two-tower/LightGCN.

#### 1.2.3. User×item features

- similarity между эмбеддингами:
  - $
    \cos(u, v)$,
  - $
    u^\top v$,
- поэлементные взаимодействия:
  - $u \odot v$ (Hadamard product),
  - $|u - v|$, $u + v$, т.п.,
- графовые признаки:
  - число общих соседей в графе,
  - длина кратчайшего пути,
  - PageRank-степень $i$ в подграфе интересов $u$.

Ranker учится на исторических данных (клики/покупки) и комбинирует сигналы:

- контент,
- коллаборатив,
- граф,
- контекст.

Результат — **отсортированный список** рекомендаций, который затем проходит через бизнес-фильтры.

---

## 2. Логика для разных состояний user/item

Состояния:

- **Warm user**: у пользователя достаточно взаимодействий (история, эмбеддинг надёжный).
- **Cold user**: мало или нет взаимодействий.
- **Warm item**: объект уже достаточно показывался/кликался.
- **Cold item**: новый или мало сигналов.

Система должна вести себя по-разному в четырёх комбинациях.

### 2.1. Warm user, warm item

Это "идеальная" зона — данных много и по пользователю, и по объекту.

**Candidate generation:**

- CF kNN,
- MF / BPR,
- two-tower,
- LightGCN,
- плюс популярные/тренды и контентка.

**Ranking:**

- full ML-stack:
  - user-фичи: история, эмбеддинги, RFM,
  - item-фичи: мета, эмбеддинги, популярность,
  - user×item: similarity, граф-фичи.

Сюда обычно направляется основное внимание при оптимизации качества (NDCG, MAP и т.п.).

### 2.2. Warm user, cold item

Пользователь известен, объект — новый.

**Candidate generation:**

- контентные источники:
  - meta-features (категория, цена, бренд),
  - zero-shot эмбеддинг текста/картинок;
- two-tower item-tower умеет посчитать $v_{\text{new}} = f_i(features(i))$;
- популярность/тренды пока ещё нет или мало данных.

**Ranking:**

- у ranker’а есть сильные user-фичи (warm user),
- item-фичи — только контентные и zero-shot эмбеддинг,
- user×item similarity на этих эмбеддингах.

По мере появления первых взаимодействий:

- объект начинает попадать в CF/LightGCN,
- его эмбеддинг становится гибридным (контент + граф).

### 2.3. Cold user, warm item

Объект известен, пользователь новый.

**Candidate generation:**

- popular / trending:
  - global + segment popular;
- contextual priors:
  - сегментные модели $score(u,i) = f(context(u), features(i))$;
- persona embeddings, если есть анкета/тексты:
  - $e_u = \text{Encoder}(persona)$,
  - content-based dense retrieval по $e_u$.

**Ranking:**

- user-фичи: контекст (регион, канал, устройство), persona,
- item-фичи: сильные (warm item, много статистики),
- user×item: similarity persona ↔ item-контент.

Постепенно, по мере кликов/просмотров:

- пользователь переходит в warm-зону,
- включаются two-tower/LightGCN для него.

### 2.4. Cold user, cold item

Самая тяжёлая комбинация: новый пользователь и новый объект.

**Candidate generation:**

- глобальные и сегментные популярности (но новый объект ещё не популярен),
- контентка:
  - similarity между persona (если есть) и item-контентом,
  - zero-shot эмбеддинги;
- иногда — ручные/курируемые подборки для cold-start.

**Ranking:**

- пользователь — почти только контекст + persona,
- объект — только контентные фичи и zero-shot,
- user×item: similarity persona ↔ контент.

По мере того, как:

- пользователь совершает действия,
- объект начинает получать показы и клики,

оба постепенно выходят из полной cold-зоны, и к ним начинают применяться обычные модели.

---

## 3. Связь с quality metrics и A/B-тестированием

### 3.1. Какие метрики важны именно для cold-start

Для оценки стратегий cold-start нужно смотреть не только на общий CTR/конверсию, но и на **специальные метрики**.

#### 3.1.1. Время до первой покупки / целевого действия

Для нового пользователя можно измерять распределение по времени (или по числу показов/сессий) до первого целевого события:

- первая покупка,
- первое добавление в избранное,
- первая подписка и т.п.

Чем **меньше** медиана/среднее этого времени, тем лучше система заводит новых пользователей.

#### 3.1.2. CTR первых $N$ рекомендаций

Смотрим CTR **в первых $N$ показах** для нового пользователя (или для нового item’а):

- $N=5,10,20$ — сколько из первых рекомендаций вообще привели к кликам;
- это даёт представление о том, насколько холодный старт "тёплый" с точки зрения relevance.

#### 3.1.3. Конверсия новых пользователей

- доля новых пользователей, которые совершили целевое действие (покупка, регистрация, подписка) за первый день/неделю;
- retention 1/7/30 дней для новых пользователей;
- конверсия из новичков в активных.

#### 3.1.4. Скорость "обогрева" (warm-up speed)

Можно определить метрику "скорости обогрева":

- для каждого пользователя считать, после скольких взаимодействий качество рекомендаций (NDCG@K, Recall@K) достигает некоего порога (скажем, 80% от уровня warm user);
- усреднить по новым пользователям.

Аналогично для новых объектов:

- сколько показов/кликов нужно, чтобы модель начала размещать объект на адекватных позициях.

### 3.2. Как сравнивать варианты: A/B-тесты

#### 3.2.1. A/B на новых пользователях

Классический подход:

- рандомно разделяем **новых пользователей** на группы A и B;
- в A используем старую стратегию cold-start,
- в B — новую (например, с persona embeddings или новым exploration);
- измеряем:
  - CTR первых $N$ рекомендаций,
  - время до первой покупки,
  - retention 1/7/30,
  - конверсию в активных.

Важно: не смешивать новых пользователей с существующими при расчёте метрик, иначе эффект размоется.

#### 3.2.2. A/B для новых items

Аналогично:

- берём новые объекты по времени создания,
- половину кидаем в группу A (старый алгоритм обращения с новинками),
- половину — в B (новый алгоритм),
- сравниваем:
  - coverage (сколько новых объектов вообще получили показы),
  - скорость набора показов/кликов,
  - CTR по новым объектам,
  - вклад новых объектов в выручку/engagement.

### 3.3. Офлайн simulation: подрезка истории

Если A/B-тест быстро сделать нельзя, можно сделать **офлайн-симуляцию cold-start**:

1. Берём исторические логи пользователей за длительный период.
2. Для каждого пользователя выбираем "точку старта" $t_0$:
   - обрезаем всю историю после $t_0$;
   - считаем, что система "видит" только события до $t_0$.
3. Иммитируем работу алгоритма:
   - считаем рекомендации на шаге $t_0 + 1$;
   - сравниваем с тем, что пользователь реально сделал в логах (clicks/purchases).
4. Повторяем с наращиванием числа известных взаимодействий (1, 2, 3, ...).

Так можно оценить:

- как быстро растёт NDCG@K / Recall@K по мере увеличения истории,
- как разные алгоритмы ведут себя в заведомо "холодных" условиях.

---

## 4. Резюме

1. **Многоступенчатый стек кандидатов**:
   - candidate generation на смеси источников: popular, content-based, CF/MF/two-tower/LightGCN;
   - ranker объединяет все сигналы (user, item, user×item, контекст) и даёт финальный порядок.

2. **Логика по состояниям user/item**:
   - warm/warm: full ML-stack, максимальная персонализация;
   - warm/cold-item: опора на meta-features и zero-shot, графовые модели после первых взаимодействий;
   - cold-user/warm-item: popular + контекст + persona, плавный переход к обычным моделям;
   - cold/cold: контентка + глобальные/сегментные популярности, постепенный прогрев.

3. **Метрики и A/B**:
   - для cold-start важны не только общий CTR/конверсия, но и скорость обогрева, CTR первых $N$ показов, время до первой покупки;
   - сравнение стратегий делается через A/B-тесты на новых пользователях/объектах и офлайн-симуляции (обрезка истории).

Этот слой «как всё живёт вместе» завершает базовый блок про персонализацию и cold-start. Дальше можно отдельными конспектами расписать:

- конкретные архитектуры ranker’ов (Wide&Deep, DeepFM, DIN),
- bandit-алгоритмы для exploration (особенно для новых объектов),
- онлайн-метрики и мониторинг деградации качества рекомендаций во времени.

