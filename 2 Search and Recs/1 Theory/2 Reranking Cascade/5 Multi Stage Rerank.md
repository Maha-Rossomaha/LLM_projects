# Мульти-этапные каскады reranking

Мульти-этапный (многоступенчатый) reranking — это стратегия, в которой несколько моделей с разной точностью и скоростью работают **последовательно**, отбирая всё меньшие и более релевантные подмножества кандидатов. Это позволяет:

- соблюдать SLA по времени,
- минимизировать вычислительные ресурсы,
- приблизиться к качеству cross-encoder на малой выборке.

---

## 1. Типовые стратегии

### Bi-encoder → Cross-encoder (2-ступенчатый)

- Быстрый retrieval bi-encoder (ANN)
- Финальный rerank top-M через cross-encoder
- Наиболее частый и простой паттерн

### Bi-encoder → ColBERT → Cross-encoder (3-ступенчатый)

- Bi-encoder быстро отбирает top-K кандидатов
- ColBERT оценивает token-level взаимодействия и формирует top-M
- Cross-encoder применяет reranking к top-N (например, N=10)
- Баланс между скоростью и точностью на всех уровнях

### Hybrid retrieval (BM25 + Dense) → Reranking

- Первый шаг: объединение sparse (BM25) и dense (bi-encoder) retrieval
- Можно использовать:
  - score fusion (w_lex·BM25 + w_dense·cosine)
  - reciprocal rank fusion (RRF)
- Затем: reranking ColBERT / cross-encoder

---

## 2. Деление кандидатов: $K \to M \to N$

Обозначения:

- $K$ — количество кандидатов после первого этапа (обычно 500–2000)
- $M$ — после intermediate rerank (ColBERT / LightReranker), обычно 50–200
- $N$ — финальный top-N (отдаётся в UI или LLM), обычно 5–20

Примеры:

| Этап | Метод        | Размер | Время      |
| ---- | ------------ | ------ | ---------- |
| 1    | Bi-encoder   | K=1000 | <100 мс    |
| 2    | ColBERT      | M=100  | 200–300 мс |
| 3    | CrossEncoder | N=20   | 100–200 мс |

Общее latency: <600 мс (в рамках SLA поиска / RAG)

---

## 3. Динамический cut-off по SLA

Когда нагрузка на систему высокая, можно адаптировать глубину каскада:

- При **низкой нагрузке**: проходить все 3 слоя (bi → ColBERT → cross)
- При **перегрузке**:
  - Пропустить cross-encoder (ColBERT = финальный rerank)
  - Или даже ColBERT (отдавать сразу top-K от bi-encoder)

> Можно установить SLA-порог (например, 500 мс), и адаптировать число кандидатов или глубину rerank в реальном времени.

---

## 4. Edge cases и риски

- **Перегрузка GPU**: cross-encoder не влезает в память → обрезать $N$ или batch size
- **Низкая релевантность кандидатов**: bi-encoder подобрал мусор → rerank не спасает → нужен hybrid retrieval
- **Уменьшение $K$ слишком сильно** → потеря recall
- **Длинные документы** → на финальных этапах применять чанкинг и best‑chunk стратегии

---

## 5. Когда это использовать

- В системах, где важно и качество, и скорость (поиск, рекомендации, RAG)
- Когда есть GPU, но они ограничены
- Когда нужно масштабироваться под нагрузку
- Когда хочется дообучать каждый слой независимо и контролировать pipeline

---

## 6. Пример схемы

```
User Query
   ↓
Bi-encoder ANN → Top-1000
   ↓
ColBERT reranker → Top-100
   ↓
Cross-encoder → Top-10
   ↓
Ответ в UI / LLM
```

---

## 7. Выводы

- Многоступенчатые каскады позволяют управлять качеством и скоростью.
- Bi-encoder / BM25 — быстрый отбор; ColBERT — уточнение; cross — максимальная точность.
- Деление $K \to M \to N$ должно учитывать SLA и доступные ресурсы.
- Система должна быть гибкой: уметь **пропускать тяжёлые шаги при перегрузке**, не теряя полностью в качестве.
