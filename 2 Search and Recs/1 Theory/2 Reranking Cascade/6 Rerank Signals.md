# Фичи и сигналы для rerank

На этапе reranking можно использовать не только raw-модельные скоры (например, из cross-encoder), но и дополнительные **сигналы (features)**, которые помогают уточнить итоговый порядок документов. Это особенно актуально, если используется классический learning-to-rank или ручная логика (score fusion).

---

## 1. Dense similarity (cosine / dot product)

- **Для bi-encoder:** после кодирования запроса и документа можно вычислить:

$$
\text{sim}(q, d) = \frac{q^\top d}{\|q\| \cdot \|d\|} \quad \text{или просто} \quad q^\top d
$$

- **Используется как основной сигнал** в ранжировании, если нет cross-encoder.
- Может быть нормализован min-max или z-score для комбинирования с другими признаками.

---

## 2. Lexical matching (BM25 / term overlap)

- Отвечает за точные совпадения слов между запросом и документом.
- Особенно полезен для редких слов, имен, терминов.
- **BM25** — стандартная метрика, может быть рассчитана заранее или во время ранжирования.

$$
\text{score}_{BM25}(q, d) = \sum_{i \in q} IDF(i) \cdot \frac{tf(i, d) \cdot (k_1 + 1)}{tf(i, d) + k_1(1 - b + b \cdot \frac{|d|}{avg_d})}
$$

- **Альтернатива:** использовать term frequency, Jaccard, количество общих токенов и т.п.

---

## 3. Позиционные признаки

- Расстояние между совпавшими словами
- Появляется ли совпадение в начале / заголовке / первом абзаце
- Совпадает ли порядок слов (query subsequence in doc)

> Эти признаки особенно полезны при ранжировании длинных документов, где ключевые слова могут встречаться в случайном порядке.

---

## 4. Temporal decay (свежесть)

- Временные признаки:

  - timestamp публикации
  - разница между текущим временем и временем документа

- Функции затухания:

  - экспоненциальное: $\exp(-\lambda t)$
  - линейное: $\max(0, 1 - \alpha t)$

> Особенно актуально для новостей, тикеров, пользовательских логов.

---

## 5. User behavior signals

Без применения ML можно использовать простые агрегаты:

- **CTR** (click-through rate)
- **Dwell time** (время просмотра документа)
- **Number of views / opens**

> Важно нормализовать эти сигналы (по ID документа или сегменту), чтобы избежать переобучения на популярности.

---

## 6. Комбинация сигналов (score fusion)

Если доступно несколько сигналов, их можно агрегировать вручную:

### Примеры:

- Взвешенное объединение:

  $$
  \text{score} = w_1 \cdot \text{cosine} + w_2 \cdot \text{BM25} + w_3 \cdot \text{freshness}
  $$

- Reciprocal Rank Fusion (RRF):

  $$
  \text{RRF}(r_1, r_2, ...) = \sum_i \frac{1}{k + r_i}
  $$

- Нормализация скоров:

  - **z-score**: $(x - \mu) / \sigma$
  - **min-max**: $(x - \min) / (\max - \min)$
  - **rank-based**: нормировать по позиции в ранге

---

## 7. Пример: ручной rerank top-K

```python
import numpy as np

# Три сигнала на каждый документ:
cosine = np.array([0.91, 0.72, 0.88])
bm25 = np.array([7.1, 8.5, 5.9])
freshness = np.array([0.9, 0.4, 0.7])

# Нормализация (min-max)
def minmax(x):
    return (x - x.min()) / (x.max() - x.min())

cosine = minmax(cosine)
bm25 = minmax(bm25)
freshness = minmax(freshness)

# Комбинация весов
final_score = 0.5 * cosine + 0.3 * bm25 + 0.2 * freshness
reranked = np.argsort(-final_score)
print("New ranking:", reranked)
```
