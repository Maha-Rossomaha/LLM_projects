# Pointwise / Pairwise / Listwise подходы

LTR-задачи можно решать с помощью трёх различных подходов к формализации задачи: **pointwise**, **pairwise** и **listwise**. Они различаются по уровню, на котором определяется loss-функция, и по способу представления ранговой информации.

---

## 1. Pointwise подход

**Идея:** рассматривать каждый (query, document) как независимую точку и предсказывать её "оценку релевантности" напрямую.

### Формализация

* Модель: $f(q, d) \to \hat{y} \in \mathbb{R}$
* Loss: регрессия (MSE) или классификация (cross-entropy)

$$
\mathcal{L}_{\text{point}} = \sum_{i} \ell(\hat{y}_i, y_i)
$$

### Преимущества

* Простота реализации и интерпретации
* Может использовать любую модель (MLP, GBDT, LogisticReg)

### Недостатки

* Не учитывает **сравнение между документами (контекст других кандидатов при ранжировании)**
* Не оптимизирует ранговые метрики (nDCG, MRR)

### Пример

```python
# Pointwise через регрессию
model = LGBMRegressor()
model.fit(X, y)  # X — признаки (q, d), y — relevance score
```

---

## 2. Pairwise подход

**Идея:** минимизировать количество инверсий — обучать модель на парах документов, сравнивая, какой релевантнее.

### Формализация (RankNet)

* Пара $(d_i, d_j)$ с разными метками: $y_i > y_j$
* Прогноз: $P_{ij} = \sigma(f(q,d_i) - f(q,d_j))$
* Loss: бинарная cross-entropy между предсказанной вероятностью и меткой:

$$
\mathcal{L}_{\text{pair}} = - \sum_{i,j} y_{ij} \log P_{ij} + (1 - y_{ij}) \log (1 - P_{ij})
$$

Где $y_{ij} = 1$, если $d_i$ > $d_j$ (т е не оригинальные метки, а бинарные предпочтения).

### Преимущества

* Учитывает **относительный порядок** документов
* Легко объясним через инверсии
* Подходит для binary relevance

### Недостатки

* Обучается на $O(n^2)$ парах → неэффективно на больших группах
* Не всегда оптимизирует метрики (например, nDCG)

### Пример

```python
# Группируем пары вручную или используем built-in 'pairwise' objective
model = LGBMRanker(objective='rank:pairwise')
```

---

## 3. Listwise подход

**Идея:** рассматривать сразу **всю перестановку** кандидатов как объект обучения.

### Примеры

* **ListNet**: softmax по score и label → cross-entropy

$$
P_i = \frac{\exp(f(q,d_i))}{\sum_j \exp(f(q,d_j))}, \quad Y_i = \frac{\exp(y_i)}{\sum_j \exp(y_j)}
$$

$$
\mathcal{L}_{\text{list}} = - \sum_i Y_i \log P_i
$$

* **ListMLE**: вероятностная модель перестановки (Plackett-Luce)
* **Softmax CrossEntropy over scores**: вариант с обучением по логитам — работает за счёт преобразования логитов в вероятностное распределение через softmax. Аналогично, метки (graded relevance) тоже нормализуются softmax-ом: это приближает задачу к вероятностной оценке идеального ранга и позволяет использовать cross-entropy как loss.

### Преимущества

* Учитывает весь список
* Хорошо коррелирует с метриками (nDCG)
* Подходит для graded relevance

### Недостатки

* Сложнее реализация (особенно ListMLE)
* Неустойчиво к шуму и большому числу кандидатов

---

## 4. Когда что выбирать?

| Сценарий                        | Рекомендуемый подход |
| ------------------------------- | -------------------- |
| Binary relevance                | Pairwise             |
| Graded relevance (0,1,2,3)      | Listwise             |
| Ограниченные вычисления         | Pointwise            |
| Нужно максимум качества по nDCG | Listwise             |
| Ограничен в данных (мало пар)   | Pointwise            |

---

## 5. Выводы

* **Pointwise** — просто, но неэффективно с точки зрения ранга
* **Pairwise** — компромисс: учитывает порядок, легко обучается
* **Listwise** — сложнее, но даёт наилучшие метрики
* На практике часто используют hybrid-подходы: distillation cross-encoder → soft-labels → listwise или pointwise обучение
