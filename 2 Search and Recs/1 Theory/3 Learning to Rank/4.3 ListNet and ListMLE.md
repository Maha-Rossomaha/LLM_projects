# ListNet и ListMLE — listwise обучение по перестановкам

**ListNet** и **ListMLE** — это listwise-модели обучения ранжированию, которые оценивают сразу весь список документов (перестановку), а не пары или отдельные элементы. Вместо классификации пар (как в RankNet / LambdaMART), они сравнивают вероятностные распределения перестановок, навеянные истинной релевантностью и предсказанными скорингами.

---

## 1. Мотивация и отличие от pairwise

**Pairwise** методы (RankNet, LambdaRank) обучают модель поднимать релевантные документы над нерелевантными — по парам. Но не учитывают всю структуру списка.

**Listwise** методы обучают модель предсказывать такую перестановку, которая максимально приближена к идеальной (по меткам релевантности).

Они хорошо согласуются с ранговыми метриками (например, nDCG), потому что работают с позициями сразу всех документов.

---

## 2. ListNet и top-1 probability model

В классической формулировке ListNet мы хотим сравнивать **распределения по перестановкам документов**. Но пространство перестановок имеет размерность $n!$, и работать с ним напрямую невозможно.

Поэтому используется упрощение — **top-1 probability model**:

* Рассмотрим вероятность того, что документ $i$ окажется на первой позиции.
* Эта вероятность определяется как softmax от значений (релевантностей или скоров).

Формально:

$$
P_y(i) = \frac{\exp(y_i)}{\sum_{j=1}^n \exp(y_j)},
$$

$$
P_s(i) = \frac{\exp(s_i)}{\sum_{j=1}^n \exp(s_j)}.
$$

Здесь:

* $P_y(i)$ — вероятность того, что документ $i$ окажется на первом месте, если упорядочить документы по истинной релевантности $y_i$.
* $P_s(i)$ — аналогичная вероятность, но на основе предсказанных скорингов $s_i$.

Таким образом, мы не моделируем полное распределение по всем $n!$ перестановкам, а ограничиваемся распределением на множестве документов для **первой позиции**.

Это даёт две ключевые выгоды:

1. Уходим от экспоненциальной сложности.
2. Сохраняем информацию о глобальном порядке (softmax использует все $y_j$ и $s_j$ одновременно).

Далее loss определяется как кросс-энтропия между этими двумя распределениями:

$$
\text{ListNetLoss} = - \sum_{i=1}^{n} P_y(i) \cdot \log P_s(i).
$$

Таким образом, модель обучается так, чтобы её softmax-распределение по документам совпадало с softmax-распределением, построенным по истинным релевантностям.

### Интерпретация

* $P_y$ и $P_s$ — распределения внимания, куда «модель» и «реальность» ставят фокус.
* Модель обучается фокусироваться на тех документах, которые важны с точки зрения меток.

---

## 3. ListMLE и softmax по перестановкам

В отличие от ListNet, который упрощает задачу до распределений для **первой позиции**, метод **ListMLE** работает непосредственно с **конкретной перестановкой документов**.

### Идея:

Мы знаем правильный порядок документов по меткам релевантности $y_i$. Обозначим эту перестановку как $\pi^*$. Например, если документы должны быть упорядочены как (документ 3, затем 1, затем 2), то $\pi^* = [3, 1, 2]$.

### Модель вероятности перестановки

ListMLE строит вероятность для всей перестановки пошагово, по принципу autoregressive генерации:

* Сначала вероятность того, что на первой позиции окажется $s_{\pi^*_1}$, среди всех $n$ документов.
* Затем вероятность того, что на второй позиции окажется $s_{\pi^*_2}$, среди оставшихся $n-1$.
* И так далее, пока не закончим последовательность.

Формально:

$$
P(\pi^*|s) = \prod_{i=1}^{n} \frac{\exp(s_{\pi^*_i})}{\sum_{j=i}^{n} \exp(s_{\pi^*_j})}.
$$

### Loss-функция

Чтобы максимизировать вероятность правильной перестановки, минимизируем её **отрицательный логарифм**:

$$
\text{ListMLELoss} = - \sum_{i=1}^{n} \log \left( \frac{\exp(s_{\pi^*_i})}{\sum_{j=i}^{n} \exp(s_{\pi^*_j})} \right).
$$

### Интуиция

* На каждом шаге мы проверяем: «Вероятность, что именно этот документ должен стоять выше всех оставшихся?»
* Таким образом, ListMLE обучает модель формировать распределение, которое максимально согласуется с правильным порядком.

Это делает ListMLE более строгим методом, чем ListNet: он учитывает полный порядок, а не только относительные вероятности для первой позиции.

---

## 4. Примеры

### 4.1 ListNet 

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class ListNetLoss(nn.Module):
    def __init__(self):
        super(ListNetLoss, self).__init__()

    def forward(self, preds, targets):
        """
        preds: тензор предсказанных скоров (batch_size, n_docs)
        targets: тензор истинных релевантностей (batch_size, n_docs)
        """
        # Строим распределения softmax
        P_s = F.softmax(preds, dim=1)
        P_y = F.softmax(targets, dim=1)

        # Кросс-энтропия между распределениями
        loss = -torch.sum(P_y * torch.log(P_s + 1e-12), dim=1)
        return loss.mean()

# ===== Пример использования =====

batch_size = 2
n_docs = 4

# Случайные предсказанные скоры модели
preds = torch.randn(batch_size, n_docs, requires_grad=True)

# Истинные релевантности (например, клики или оценки от 0 до 4)
targets = torch.tensor([[3.0, 0.0, 1.0, 2.0],
                        [0.0, 2.0, 1.0, 0.0]])

criterion = ListNetLoss()
loss = criterion(preds, targets)

loss.backward()
print("ListNet loss:", loss.item())
```

### 4.2 ListMLE

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class ListMLELoss(nn.Module):
    def __init__(self):
        super(ListMLELoss, self).__init__()

    def forward(self, preds, targets):
        """
        preds: тензор предсказанных скоров (batch_size, n_docs)
        targets: тензор истинных релевантностей (batch_size, n_docs)
        """
        batch_size, n_docs = preds.shape

        # Получаем правильную перестановку документов (сортируем по убыванию релевантности)
        sorted_idx = torch.argsort(targets, dim=1, descending=True)

        # Переставляем предсказанные скоры согласно правильной перестановке
        preds_sorted = torch.gather(preds, 1, sorted_idx)

        # Считаем ListMLE loss
        loss = 0.0
        for i in range(n_docs):
            numerator = preds_sorted[:, i]
            denominator = torch.logsumexp(preds_sorted[:, i:], dim=1)
            loss += (denominator - numerator)

        return loss.mean()

# ===== Пример использования =====

batch_size = 2
n_docs = 4

# Случайные предсказанные скоры
preds = torch.randn(batch_size, n_docs, requires_grad=True)

# Истинные релевантности
targets = torch.tensor([[3.0, 0.0, 1.0, 2.0],
                        [0.0, 2.0, 1.0, 0.0]])

criterion = ListMLELoss()
loss = criterion(preds, targets)

loss.backward()
print("ListMLE loss:", loss.item())
```

---

## 5. Преимущества и недостатки

### Преимущества:

* Учитывают **весь список**, а не только пары
* Лучше согласованы с метриками типа nDCG
* Теоретически более выразительны

### Недостатки:

* Менее интерпретируемы, чем пары
* Требуют ранжированного ground truth (ListMLE)
* Тяжелее масштабируются при большом числе документов

---

## 6. Когда выбирать listwise-подходы и как они связаны с дистилляцией

### Graded relevance

Если у нас есть **многоуровневая шкала релевантности** (например, 0 = нерелевантный, 1 = частично релевантный, 2 = хороший, 3 = отличный), то listwise-методы (ListNet, ListMLE) более информативны, чем pairwise.

* Pairwise учитывает только бинарное сравнение («лучше / хуже»).
* Listwise использует всю градацию и строит распределение по всему списку, что даёт более точный сигнал обучения.

### Максимизация метрики

Listwise напрямую приближает метрики качества ранжирования (nDCG, MAP и др.), потому что:

* softmax-распределение фокусируется на относительных позициях,
* кросс-энтропия или log-likelihood подталкивает модель к согласованию с глобальным порядком,
* при graded relevance высокие значения метки сильнее влияют на распределение.

### Размер кандидатов

Для **умеренных размеров списка** (до \~100 документов на запрос) softmax ещё вычисляется эффективно. Если документов тысячи, то listwise-подходы становятся дорогими, и чаще переходят к pairwise.

### Distillation через ListNet

Один из популярных сценариев — **distillation**:

1. Teacher-модель (обычно cross-encoder) строит распределение релевантностей для набора кандидатов.
2. Эти предсказания превращаются в **soft-labels** через softmax.
3. Student-модель (обычно bi-encoder) обучается с **ListNet loss**, минимизируя кросс-энтропию между своим распределением и распределением teacher.

Преимущества:

* soft-labels содержат больше информации, чем бинарные метки (например, teacher может распределить 0.7 / 0.2 / 0.1 между документами).
* student учится имитировать полный порядок, а не только отдельные сравнения.
* обучение устойчивее, особенно на больших корпусах, где релевантность субъективна.

### ListMLE

* Применяется, когда известен точный порядок документов (например, при ручной разметке).
* Задаёт строгую вероятность для всей перестановки.
* Используется реже как distillation-loss, так как teacher обычно даёт **оценки**, а не полный порядок.