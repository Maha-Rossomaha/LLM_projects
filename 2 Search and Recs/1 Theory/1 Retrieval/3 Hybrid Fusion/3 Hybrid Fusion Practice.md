# Hybrid Fusion Practice

## 1. Lexical fallback (резервный сценарий)

Иногда dense-модель может не вернуть релевантных документов:

* редкие термы не представлены в embedding-пространстве;
* числовые/морфологические различия не уловлены семантикой;
* запрос состоит из терминов, отсутствующих в обучающей выборке dense-модели.

**Решение — lexical fallback:**

* Если dense-выдача пустая или очень низкого качества (по порогу), система возвращает только BM25-результаты.
* Можно также использовать top-N из BM25 как обязательный baseline: даже если dense-модель возвращает результаты, определённое количество (например, top-5) документов из BM25 можно принудительно включать в финальный список. Это повышает надёжность системы, особенно при коротких или редких запросах, обеспечивая как минимум лексическое покрытие запроса.

---

## 2. Проблемы балансировки

### 1. Разный масштаб скоров

* BM25 может давать значения в диапазоне \[0, 20+]
* Cosine similarity — в \[-1, 1] или \[0, 1]
* Без нормализации BM25 доминирует или наоборот

### 2. Разная релевантность

* Dense может быть слишком «мягким» и вытеснять точные совпадения
* Веса требуют тонкой настройки под домен, язык, формат документов

---

## 3. Нормализация

#### Min-max:

$$
score_{norm} = \frac{score - min}{max - min}
$$

#### Z-score:

$$
score_{norm} = \frac{score - \mu}{\sigma}
$$

#### Rank-based:

$$
score_{norm} = \frac{1}{rank + 1}
$$

> **Важно:** нормализация должна применяться отдельно к каждому списку!

---

## 4. Автоматический подбор весов

### Grid Search:

* Задаём диапазон весов: $w_{lex}$ и $w_{dense}$ от 0 до 1 с шагом 0.05
* Перебираем все комбинации
* Для каждой — считаем nDCG, MRR, Recall

### Bayesian Optimization:

* Более эффективный метод при большом пространстве параметров
* Использует предсказание метрик на основе уже измеренных точек

### Coordinate Descent:

* Фиксируем один вес, оптимизируем второй, чередуем

---

## 5. Query Expansion (расширение запроса)

Query expansion — это метод дополнения запроса терминами, которые могут помочь улучшить полноту поиска. Особенно полезен в гибридных системах, где dense-модель может недоучесть редкие термы или синонимы.

### Зачем это нужно:

* Короткие запросы не дают модели достаточно сигнала.
* Dense-модели не всегда понимают числовые фильтры или терминологию.
* Лексическая компонента может усилиться за счёт дополнительного контекста.

### Варианты query expansion:

* **Thesaurus-based:** ручные словари синонимов (WordNet, пользовательские домены).
* **Embedding-based:** найти ближайшие по cosine similarity слова в space эмбеддингов.
* **Pseudo relevance feedback (PRF):** взять топ-результаты и выбрать часто встречающиеся термы.
* **LLM-based expansion:** использовать LLM (GPT, BGE-M3) для генерации уточнённого или более полного запроса.

### Пример:

Запрос: `«купить смартфон»`

* Расширение: `«купить смартфон мобильный телефон Android iPhone»`

BM25 лучше охватит документы с «мобильный», а dense — уловит синонимию «телефон» ↔ «смартфон».

### Как использовать в гибриде:

* Расширять только для lexical компоненты (BM25).
* Либо расширять оба запроса — но dense компонент нужно перезапускать.
* Можно делать fusion оригинального и расширенного запроса (dual query fusion).

### Потенциальные риски:

* Переобобщение (слишком много нерелевантных слов).
* Увеличение латентности.
* Нарушение намерения пользователя (если expansion слишком агрессивный).

### Как фиксить:

* Использовать top-N термов по IDF.
* Ограничивать количество expansion-слов (3–5).
* Валидировать эффекты на метриках (Recall, MRR).

---

## 6. Edge cases — когда гибрид вредит

### 1. Короткие запросы

**Причина:**

* Одно-два слова запроса («такси», «пицца») не дают dense-модели достаточно контекста для генерации устойчивого эмбеддинга.
* Семантическое представление оказывается слишком обобщённым.

**Следствие:**

* Модель возвращает документы, которые "вроде бы похожи", но неточно релевантны (например, «поездка», «услуги» вместо «такси»).

**Как фиксить:**

* Усиливать вклад BM25 для коротких запросов (динамически менять $w_{lex}$).
* Использовать lexical fallback по длине запроса (например, len < 3 → fallback).
* Добавлять query expansion для уточнения семантики (если dense остаётся).

### 2. Запросы с числовыми фильтрами

**Причина:**

* Dense модели обычно не обучены на числовых сравнениях и не различают «30 тыс» от «300 тыс».
* Цифры обрабатываются как обычные токены без понимания их количественного смысла.

**Следствие:**

* Модель возвращает документы без учёта ограничения по цене или дате.

**Как фиксить:**

* Использовать структурные фильтры в индексе (например, фильтрация по метаданным до dense retrieval).
* Повышать вес BM25 в подобных случаях.
* Обнаруживать числовые шаблоны в запросе и принудительно использовать fallback.

### 3. Необученный домен

**Причина:**

* Dense модель обучалась на новостях, Википедии и т.п., но применяется к медицине, праву или технической документации.
* Эмбеддинги не отражают специфику терминов.

**Следствие:**

* Потеря семантической точности, нерелевантные результаты даже при наличии термов.

**Как фиксить:**

* Провести дообучение модели на in-domain корпусе (domain adaptation).
* Использовать гибрид с повышенным вкладом BM25.
* Добавлять словари ключевых терминов как дополнительные фичи.

### 4. Повторная выдача нерелевантных документов

**Причина:**

* Dense модель переобучилась на частых паттернах (например, общих фразах, популярных заголовках).
* Эмбеддинги сдвигаются в сторону "популярных" кластеров, а не смысла запроса.

**Следствие:**

* В топ-результатах повторяются нерелевантные, но «знакомые» документы.

**Как фиксить:**

* Удалять дубликаты и шаблонные документы при построении индекса.
* Применять diversity-фильтрацию на уровне reranker'а.
* Ограничивать частоту документа в выдаче (например, penalize за high frequency).
