# Rank Fusion

## Введение

Когда поисковая система использует несколько моделей (BM25, dense retriever, SPLADE и т.д.), возникает задача объединения их результатов. Если скоры моделей имеют разную шкалу (BM25: [0, 20+], cosine: [-1, 1]), то **простое суммирование** скоров невозможно без нормализации. Альтернатива — **ранговое объединение**, где используются **позиции (ранги)** документа в списках.

Ранговое объединение:

- не зависит от шкалы скоров;
- просто в реализации;
- эффективно при объединении разных моделей или индексов.

---

## 1. Reciprocal Rank Fusion (RRF)

Один из самых популярных методов:

$$
score(d) = \sum_{i=1}^m \frac{1}{k + rank_i(d)}
$$

- $m$ — количество систем/моделей.
- $rank_i(d)$ — позиция документа $d$ в $i$-м списке (1 — лучший).
- $k$ — сглаживающий гиперпараметр (обычно $k = 60$).

**Интерпретация:** чем выше документ в каждом списке, тем больше его вклад. Даже если документ не на первом месте, он может часто встречаться в топе и получить высокий итоговый балл.

### Пример на Python

```python
import torch

# Пример: документ d1 на позиции 3 и 7 в двух списках
ranks = torch.tensor([3, 7])
k = 60

rrf_score = sum(1 / (k + r) for r in ranks)
print(f"RRF score: {rrf_score:.4f}")
```

---

## 2. Borda Count

Метод из теории голосования. Если список длины $N$, то документ на $i$-м месте получает $N - i$ очков.

$$
score(d) = \sum_{i=1}^m (N - rank_i(d))
$$

**Особенность:** сильнее награждает высокие позиции, чем RRF.

### Пример на Python

```python
N = 10  # длина списка
doc_ranks = [2, 5]  # позиции документа в двух системах

borda_score = sum(N - r for r in doc_ranks)
print(f"Borda score: {borda_score}")
```

---

## 3. Другие методы

### CombSUM (по скору):

$$
score(d) = \sum_{i=1}^m norm(score_i(d))
$$

- Используются нормализованные скоры (min-max, z-score).
- Чувствителен к выбросам.

### CombMNZ:

$$
score(d) = CombSUM(d) * count(d)
$$

- Учитывает как величину, так и число систем, в которых документ появился.

### Voting (голосование):

- Каждое вхождение документа в топ-K — голос.
- Итоговая оценка — число голосов.

---

## 4. Сравнение с Score Fusion

| Метод         | Использует скоры | Требует нормализации | Устойчив к шкале | Учитывает ранги | Особенности                          |
| ------------- | ---------------- | -------------------- | ---------------- | --------------- | ------------------------------------ |
| Score Fusion  | ✅                | ✅                    | ❌                | ❌               | Тонкая настройка возможна            |
| CombSUM / MNZ | ✅                | ✅                    | ❌                | ❌               | Быстро, но чувствительно к масштабу  |
| RRF           | ❌                | ❌                    | ✅                | ✅               | Хорошо работает без тюнинга          |
| Borda         | ❌                | ❌                    | ✅                | ✅               | Прост и интуитивен                   |
| Voting        | ❌                | ❌                    | ✅                | ✅               | Идеален для демократического слияния |

---

## 5. Сценарии применения

### 1. **Гибридный поиск** (BM25 + dense retriever)

- BM25 даёт точные совпадения.
- Dense помогает найти синонимы и семантически близкие документы.
- RRF — способ объединить их без сложной настройки весов.

### 2. **Мульти-языковой поиск**

- Каждый движок индексирует разную языковую версию.
- RRF объединяет результаты без жёстких требований к метрике.

### 3. **Разные индексы / шарды**

- Индексы построены по разным правилам (по времени, по тематике).
- Ранговая объединения помогает собрать частичные выдачи.

### 4. **Ensemble моделей**

- Есть несколько retriever-моделей (например, E5, GTE, bge).
- Можно агрегировать их выводы через Borda / RRF, повышая устойчивость.
