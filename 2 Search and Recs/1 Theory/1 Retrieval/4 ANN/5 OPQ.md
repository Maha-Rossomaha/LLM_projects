# OPQ — подробный разбор (FAISS)

Optimized Product Quantization (OPQ) — это улучшение классического PQ за счёт линейного преобразования пространства (поворота/перемешивания координат) перед квантизацией. Цель — равномернее распределить информацию между подпространствами и уменьшить среднюю ошибку квантования без роста кода.

---

## 1. Идея и формализация
Пусть $x \in \mathbb{R}^d$, а $R \in \mathbb{R}^{d\times d}$ — ортогональное преобразование (поворот). Стандартный PQ аппроксимирует $x$ как $\hat{x} = \tilde{q}(x)$, где $\tilde{q}$ — поэлементная квантизация по $M$ независимым подпространствам. В OPQ аппроксимация строится как
$$
\hat{x} = R^T\, \tilde{q}\big(R x\big),
$$
то есть сначала поворачиваем вектор, затем квантуем, а потом возвращаемся в исходное пространство. Матрица $R$ и кодбуки подпространств подбираются совместно для минимизации
$$
\sum_{i} \big\|x_i - R^T\, \tilde{q}(R x_i)\big\|^2.
$$
Интуитивно: OPQ «перемешивает» координаты так, чтобы каждый под‑вектор содержал сопоставимое количество информации.

---

## 2. Архитектура в FAISS
- **OPQMatrix(d, M):** обучаемое линейное преобразование с разбиением на $M$ подпространств перед PQ.  
- **IndexPreTransform(OPQ, BaseIndex):** конвейер «преобразование → базовый индекс». В роли базового индекса часто выступают `IndexPQ` или `IndexIVFPQ`.
- **IVFOPQ:** комбинация IVF + OPQ + PQ: сперва coarse‑квантизация по центрам, затем OPQ‑поворот и PQ‑кодирование (обычно по остаткам).

---

## 3. Поиск расстояний (ADC) с OPQ
При асимметричном вычислении расстояний (ADC) запрос $q$ тоже прогоняется через $R$:
1) Вычисляем $q' = R\, q$.  
2) Составляем $M$ LUT‑таблиц расстояний между под‑векторами $q'$ и центрами каждого кодбука.  
3) Для кандидата суммируем значения из LUT по его PQ‑кодам.  
В FAISS это прозрачно делает `IndexPreTransform`: на этапе поиска он применяет $R$ к запросам автоматически.

---

## 4. Параметры и их влияние
- **$M$ (число под‑векторов):** как и в PQ, большее $M$ повышает точность аппроксимации и стоимость кода (байт/вектор). OPQ особенно полезен при умеренных $M$ (например, 64–96 при $d=768$).
- **$nbits$ (бит на под‑вектор):** 4/5/6/8. Рост $nbits$ улучшает качество и увеличивает LUT/код. OPQ даёт наибольшую пользу при небольших $nbits$ (6–8) и несбалансированных признаках.
- **Обучающая выборка:** как и для PQ/IVFPQ, критично репрезентативное $X_{train}$; объём порядка $10^5$–$10^6$ примеров.
- **Совместное обучение:** в FAISS `OPQMatrix` и базовый индекс (PQ/IVFPQ) обучаются **совместно** в составе `IndexPreTransform.train()`.

---

## 5. Память и скорость
- **Память:** такая же, как у соответствующего PQ/IVFPQ‑кода (доп. матрица $R$ размера $d\times d$ ничтожна по сравнению с кодами на миллионы векторов).  
- **Скорость:** накладные расходы на умножение $R q$ малы (одна матрица×вектор), а выигрыш в качестве позволяет уменьшить $nprobe$ (в IVFOPQ) или $M/nbits$ при той же точности.

---

## 6. Когда OPQ помогает особенно заметно
- Сильно коррелированные признаки или «неудачное» разбиение координат при классическом PQ.  
- Жёсткие ограничения по памяти: хотим держать $M$ и $nbits$ на низком уровне, но сохранить recall.  
- Большие коллекции с IVFPQ: OPQ даёт бесплатный прирост качества при фиксированном коде.

---

## 7. Примеры кода

### 7.1. OPQ + PQ (IndexPreTransform)
```python
import numpy as np
import faiss

# Размерность и код
d = 128
M, nbits = 16, 8  # 16 под-векторов по 8 бит → 16 байт/вектор

# Данные
N_train, N_base = 100_000, 1_000_000
xb = np.random.randn(N_base, d).astype('float32')

# Преобразование OPQ
opq = faiss.OPQMatrix(d, M)
opq.niter = 25        # (необязательно) число итераций обучения
opq.verbose = True    # (необязательно) лог обучения

# Базовый индекс PQ
pq = faiss.IndexPQ(d, M, nbits)  # чистый PQ без IVF

# Конвейер: OPQ → PQ
index = faiss.IndexPreTransform(opq, pq)

# Обучение (OPQ и PQ обучаются совместно)
train = xb[np.random.choice(N_base, N_train, replace=False)]
index.train(train)

# Добавление базы и поиск
index.add(xb)
xq = np.random.randn(1000, d).astype('float32')
D, I = index.search(xq, 10)
```

### 7.2. OPQ + IVFPQ (IVFOPQ)
```python
import numpy as np
import faiss

d = 768
nlist = 4096
M, nbits = 96, 8

# Данные под cosine (используем IP)
xb = np.random.randn(1_000_000, d).astype('float32')
faiss.normalize_L2(xb)

# OPQ-преобразование
opq = faiss.OPQMatrix(d, M)

# Базовый IVFPQ (residual encoding по умолчанию)
quantizer = faiss.IndexFlatIP(d)
ivfpq = faiss.IndexIVFPQ(quantizer, d, nlist, M, nbits, faiss.METRIC_INNER_PRODUCT)

# Конвейер: OPQ → IVFPQ
index = faiss.IndexPreTransform(opq, ivfpq)

# Тренировка (учится и OPQ, и IVF+PQ)
train = xb[np.random.choice(xb.shape[0], 200_000, replace=False)]
index.train(train)

# Добавление и поиск
index.add(xb)
index.nprobe = 64
xq = np.random.randn(1000, d).astype('float32')
faiss.normalize_L2(xq)
D, I = index.search(xq, 10)
```

### 7.3. Сохранение и загрузка индекса OPQ
```python
# Сохранение
faiss.write_index(index, 'ivfopq.index')

# Загрузка
loaded = faiss.read_index('ivfopq.index')
D2, I2 = loaded.search(xq, 10)
```

---

## 8. Практические советы
- **Стартовые настройки:** для $d=768$ использовать $M=64$–$96$, $nbits=8$; для $d=128$ — $M=16$–$32$, $nbits=8$.  
- **Объём обучения:** не менее $10^5$ примеров; при миллиардах объектов лучше $\ge 5\cdot10^5$.  
- **Cosine:** нормализовать базу и запросы, использовать метрику IP в индексе.  
- **IVFOPQ тюнинг:** подбирать $nlist \approx \sqrt{N}$, затем `nprobe` под SLA. Часто OPQ позволяет снизить `nprobe` на 25–50% при том же recall.  
- **Drift:** при смене эмбеддера переобучать OPQ+PQ/IVFPQ (shadow index → alias switch).  
- **Refine:** для top‑R кандидатов можно пересчитать точное расстояние (IVFPQR) — OPQ совместим с refine.

---

## 9. Типичные ошибки
- Обучение OPQ/PQ на нерепрезентативной выборке → падение качества на проде.  
- Несогласованная метрика: cosine без нормализации или L2 с заранее нормализованными базовыми векторами.  
- Слишком малый $M$ при большом $d$ (например, $d/M > 32$) — подпространства становятся слишком «толстыми», выигрыши OPQ снижаются.  
- Забыли завернуть базовый индекс в `IndexPreTransform` → OPQ не применяется на запросах.

---

## 10. Чеклист тюнинга
- Выбрать $M$ так, чтобы $d/M \in [8,16]$.  
- Начать с $nbits=8$, затем экспериментировать с 6/4 при жёстких ограничениях памяти.  
- Для IVFOPQ: $nlist \approx \sqrt{N}$, `nprobe`=32–64 как старт; затем уменьшать `nprobe` до тех пор, пока Recall@K удовлетворяет SLA.  
- При росте нагрузки — адаптивный `nprobe`; при росте корпуса — пересборка центров IVF.

