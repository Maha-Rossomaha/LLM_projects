# Inverted File Index (IVF) 

Inverted File Index (IVF) — классический метод приближённого поиска ближайших соседей, основанный на кластеризации пространства на центры (ячейки) и ограничении поиска только на $nprobe$ ближайших кластерах.

---

## 1. Идея

* Разбиваем все векторы $X = {x_i}$ на $nlist$ кластеров с центрами $c_j$.
* Каждый вектор попадает в ближайшую «ячейку» (inverted list).
* При поиске запроса $q$ смотрим не во все кластеры, а только в $nprobe$ ближайших.
* Таким образом резко сокращаем число сравниваемых кандидатов.

---

## 2. Архитектура индекса

1. **Coarse quantizer** (обычно IndexFlatL2/IP) — выбирает ближайшие центры:
   1. Это первый слой индекса.
   2. Мы обучаем простенький k-means кластеризатор (обычно L2 или inner product).
   3. Он создаёт $n_{\text{list}}$ “центров” (centroids).
   4. Каждый вектор базы прикрепляется к ближайшему центру.
   5. По сути это “грубая сетка”, которая делит всё пространство на ячейки (Voronoi cells).
2. **Inverted lists** — массивы $(id, vector)$, сгруппированные по ближайшему центру:  
   1. Для каждого центра есть список $(id, vector)$, куда складываются все вектора, прикреплённые к этому центру.
   2. Каждый элемент списка = $(id, vector)$.
   3. Векторы одной группы можно хранить подряд, иногда даже на диске (DiskANN, IVF on SSD).
3. (Опционально) Внутри ячеек можно использовать компрессию (IVFPQ, IVFScalarQuantizer).

---

## 3. Обучение

1. Сэмплируем $X_{train}$ (обычно $10^5$–$10^6$).
2. Обучаем k-means на $nlist$ центров.
3. Индекс готов принимать векторы.

---

## 4. Добавление векторов

Для каждого $x$ находим ближайший центр $c_j$ и сохраняем $(id, x)$ в список $j$.

---

## 5. Поиск

1. Приходит запрос (query-vector).
2. Ищем его ближайшие центры среди $n_{\text{list}}$ (coarse quantizer). Это дешево, потому что центров мало.
3. Выбираем $n_{\text{probe}}$ центров (не один, а несколько, чтобы не потерять хорошие кандидаты).
4. Смотрим только в inverted lists этих центров.
5. Внутри них считаем точное расстояние (или приближённое, если используется сжатие).
6. Оттуда возвращаем global top-$k$

---

## 6. Параметры

* $nlist$ — число кластеров. Эвристика: $nlist \approx \sqrt{N}$. Большее $nlist$ уменьшает среднюю длину списков, ускоряет сканирование, но требует больше памяти и времени на обучение центров.
* $nprobe$ — число просматриваемых ячеек. Чем больше $nprobe$, тем выше recall и качество, но тем выше задержка. Обычно 8–128.
* Метрика: L2 (евклидово), IP (inner product), cosine (реализуется через L2-нормализацию векторов и использование IP).

---

## 7. Сложность и память

* Память: $O(Nd)$ (так как храним полные float-вектора).
* Поиск: $O\big((N/nlist) \cdot nprobe \cdot d\big)$.

**Пример:** $N=10^7, d=768, nlist=4096, nprobe=64$.
Ожидаемое число сканируемых кандидатов ≈ $(10^7 / 4096) * 64 ≈ 156k$ (вместо $10^7$ при Flat).

---

## 8. Достоинства

* Простота реализации.
* Сильное ускорение поиска.
* Хорошая точность при достаточном $nprobe$.

---

## 9. Недостатки

* Память почти как у Flat (так как вектора хранятся полностью).
* Баланс качества/скорости зависит от $nlist$, $nprobe$.
* Требует переобучения центров при drift.

---

## 10. Практические советы

* Начинать с $nlist \approx \sqrt{N}$ и $nprobe=32$–$64$.
* Для cosine нормализовать базу и запросы.
* Переобучать центры при крупных апдейтах.
* Для экономии памяти лучше использовать IVFPQ.

---

## 11. Примеры кода 

### 11.1. IVFFlat под cosine (Inner Product)

```python
import numpy as np
import faiss

# Параметры
d = 768
N = 1_000_000
nlist = 4096
k = 10

# База
xb = np.random.randn(N, d).astype('float32')
faiss.normalize_L2(xb)  # для cosine

# Квантайзер и IVF
quantizer = faiss.IndexFlatIP(d)
index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_INNER_PRODUCT)

# Тренировка
train = xb[np.random.choice(N, 200_000, replace=False)]
index.train(train)

# Добавление
index.add(xb)

# Поиск
xq = np.random.randn(1000, d).astype('float32')
faiss.normalize_L2(xq)
index.nprobe = 64
D, I = index.search(xq, k)
print(I[:5])
```

### 11.2. IVFFlat под L2

```python
import numpy as np
import faiss

d = 512
N = 500_000
nlist = 2048
k = 5

xb = np.random.randn(N, d).astype('float32')

quantizer = faiss.IndexFlatL2(d)
index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)

train = xb[np.random.choice(N, 100_000, replace=False)]
index.train(train)

index.add(xb)

xq = np.random.randn(100, d).astype('float32')
index.nprobe = 16
D, I = index.search(xq, k)
print(I[:5])
```

---

## 12. Чеклист тюнинга

* Выбрать $nlist$ как $\sqrt{N}$.
* Подбирать $nprobe$ под SLA.
* Следить за распределением размеров списков (неравномерность ухудшает latency).
* При больших $N$ и ограниченной памяти — переходить к IVFPQ.
