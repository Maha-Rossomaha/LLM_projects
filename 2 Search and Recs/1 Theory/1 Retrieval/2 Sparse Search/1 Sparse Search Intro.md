# Sparse Search 

Sparse search (разреженный поиск) — классический подход к retrieval, в котором документы и запросы представляются как **разреженные векторы признаков** (обычно слова или n-граммы). Это противоположность dense search, где используются плотные эмбеддинги.

---

## 1. Идея

* Каждое слово (терм) — измерение вектора.
* Документ/запрос описывается частотами терминов (bag-of-words, TF-IDF).
* Поиск осуществляется через совпадение термов.
* Для эффективности используется **инвертированный индекс**: term → список документов (posting list).

---

## 2. Основные методы

* **Bag-of-Words (BoW):** бинарное присутствие термов.
* **TF (term frequency):** частота термов.
* **TF-IDF:** TF, скорректированный обратной частотой документа (IDF).
* **BM25:** улучшенный вариант TF-IDF с насыщением частоты и нормализацией длины документа.

### 2.1 TF-IDF

**TF (term frequency):** частота терма $t$ в документе $d$.

$$
TF(t,d) = \frac{f(t,d)}{|d|}
$$

* $f(t,d)$ — число вхождений $t$ в $d$.
* $|d|$ — длина документа (число слов).

**IDF (inverse document frequency):** обратная частота документа.

$$
IDF(t) = \log \frac{N}{df(t)}
$$

* $N$ — общее число документов.
* $df(t)$ — число документов, содержащих $t$.

**TF-IDF:**

$$
score_{tfidf}(d,q) = \sum_{t \in q} TF(t,d) \cdot IDF(t)
$$

Проблема TF-IDF: слишком высокие веса у редких термов, отсутствие нормализации длины документа.

### 2.2 BM25

BM25 решает проблемы TF-IDF за счёт насыщения TF и нормализации по длине документа.

Формула BM25:

$$
score_{BM25}(d,q) = \sum_{t \in q} IDF(t) \cdot \frac{f(t,d) \cdot (k+1)}{f(t,d) + k \cdot (1 - b + b \cdot \frac{|d|}{avgdl})}
$$

Где:

* $f(t,d)$ — число вхождений $t$ в $d$.
* $|d|$ — длина документа.
* $avgdl$ — средняя длина документа в коллекции.
* $k$ — параметр насыщения TF (обычно 1.2–2.0).
* $b$ — параметр нормализации длины (0.75 по умолчанию).

**IDF в BM25:**
Обычно берётся так:

$$
IDF(t) = \log \frac{N - df(t) + 0.5}{df(t) + 0.5}
$$

#### Интуиция по частям

1. **$f(t,d)$ — частота терма в документе**  
   Чем чаще термин встречается в документе, тем он «важнее». Но рост **не бесконечный**: 100 повторов не делают документ в 100 раз релевантнее. Поэтому вводится механизм насыщения (см. $k$).

2. **$k$ — параметр насыщения TF**
   Контролирует, насколько быстро прирост значимости от повторений терма «замедляется».
   * При $k \to 0$: даже одно вхождение уже достаточно, дальнейшие повторы почти не учитываются.
   * При большом $k$: рост значимости ближе к линейному.
   * Типичные значения $1.2–2.0$ дают компромисс: 1–3 вхождений достаточно, дальше эффект уменьшается.

3. **Нормализация по длине документа ($b$)**  
   Длинные документы естественно содержат больше вхождений, что может искусственно повышать их score.
   $b$ контролирует степень нормализации длины:  
   * $b=0$: длина документа игнорируется.
   * $b=1$: полная нормализация (сильный штраф для длинных документов).
   * Обычно $b=0.75$: частичная нормализация.
   Множитель $\tfrac{|d|}{avgdl}$ сравнивает длину документа с «средней длиной».

4. **$(k+1)$ в числителе**  
   Обеспечивает, что при $f(t,d)=1$ вклад терма будет близок к $IDF(t)$. Одно вхождение сразу делает термин «работающим», а последующие учитываются с убывающим весом.

5. **IDF**  
   Подавляет слишком частые термины (stop-words, общие слова «и», «the»).
   Интуиция: если термин встречается почти в каждом документе ($df(t) \approx N$), его вклад стремится к нулю. Если термин редкий, его вес выше → помогает лучше различать документы.

#### Вариации: BM25+ 

* **Проблема**: в классическом BM25 очень короткие документы могут получать нулевой или слишком низкий вклад от редких терминов (bias против коротких текстов).
* **Решение**: вводится добавка $\delta$ в числителе, которая гарантирует ненулевой вклад:

$$
score_{BM25+}(d,q) = \sum_{t\in q} IDF(t)\,\Bigg( \underbrace{\frac{ f(t,d)\,(k+1)}{ f(t,d) + k\,\big(1 - b + b\,\tfrac{|d|}{avgdl}\big) }}_{\text{BM25-TF}} \; + \; \delta \Bigg).
$$

* **Интуиция**: даже одно вхождение редкого терма в коротком документе должно учитываться положительно.
* **Практика**: $\delta$ обычно маленькая (0.1–0.5).

#### Вариации: BM25L
* **Проблема**: BM25 иногда слишком жёстко штрафует длинные документы (особенно если они содержат много уникальных термов).
* **Решение**: изменяется формула нормализации TF так, чтобы насыщение было «мягче»:  
**TF-компонента:**

$$
TF_{BM25L}(t,d) = \frac{ f(t,d) }{ f(t,d) + k\,\Big( (1-b) + b\,\tfrac{|d|}{avgdl} \Big) } \; + \; \epsilon.
$$

$\;\;\;\;\;\;\;\;$**Полный скор:**

$$
score_{BM25L}(d,q) = \sum_{t\in q} IDF(t)\, TF_{BM25L}(t,d).
$$
$\;\;\;\;\;\;\;\;$где $\epsilon$ — малое смещение (часто $\epsilon\approx 0.25$), смягчающее штраф длины.
* **Интуиция**: длинные документы часто содержат шум и вспомогательные слова, но это не должно полностью обесценивать редкие и значимые термины внутри них.
* **Практика**: BM25L применяется в коллекциях с сильно разнородными по длине документами.

---

## 3. Отличия TF-IDF и BM25

* TF-IDF линейно растёт с частотой терма, BM25 вводит насыщение (дальнейшие повторения терма дают меньший прирост).
* BM25 учитывает длину документа (длинные документы не получают искусственно высокий скор).
* BM25 более устойчив к шуму и лучше работает на практике.
* BM25+ улучшает обработку коротких документов.
* BM25L лучше подходит для коллекций с очень длинными текстами.

---

## 4. Архитектура

1. **Токенизация и нормализация**: разбиение на слова, стемминг, лемматизация, фильтр стоп-слов.
2. **Словарь (vocabulary):** список всех термов.
3. **Документные векторы:** sparse-векторы по словарю.
4. **Индекс:** inverted index (term → posting list).
5. **Поиск:** пересечение списков кандидатов + ранжирование по метрике (TF-IDF, BM25).

---

## 5. Метрики

* **Cosine similarity**: $sim(q,d) = \tfrac{q \cdot d}{|q||d|}$
* **Dot product**: $q \cdot d$
* **BM25 score** (стандарт в поиске).

---

## 6. Сложность и память

* Построение индекса: $O(N \cdot L)$, где $L$ — средняя длина документа.
* Поиск: $O(\sum_{t\in q}|posting(t)|)$, где $posting(t)$ — список документов с термом $t$.
* Память: хранение словаря + posting lists.
* Сжатие: используется block compression, skip lists.

---

## 7. Достоинства

* Простота и интерпретируемость.
* Очень быстро для коротких запросов.
* Хорошо работает на точных совпадениях (названия, ключевые слова).
* Интеграция с SQL/Elastic/OpenSearch.

---

## 8. Недостатки

* Не улавливает семантику (синонимы, перефразировки).
* Проблемы с мультиязычием (разные словари).
* Редкие слова → длинные списки.
* Длинные документы → bias.

---

## 9. Практические советы

* Для текста → BM25 как базовый метод.
* Для мультиязычия → отдельные индексы или машинный перевод.
* Для редких термов → сглаживание (BM25+, BM25L).
* Для очень длинных документов → BM25L или усечение.
* Для современных систем → использовать в гибриде (sparse + dense).

---

## 10. Примеры

### 10.1. TF-IDF + cosine

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

corpus = [
    "the cat sat on the mat",
    "the dog barked at the cat",
    "the cat meowed"
]

vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(corpus)

query = ["cat on mat"]
q_vec = vectorizer.transform(query)

sim = cosine_similarity(q_vec, X)
print(sim)
```

### 10.2. BM25 (Rank-BM25)

```python
from rank_bm25 import BM25Okapi

corpus = [
    "the cat sat on the mat",
    "the dog barked at the cat",
    "the cat meowed"
]

tokenized_corpus = [doc.split() for doc in corpus]
bm25 = BM25Okapi(tokenized_corpus)

query = "cat mat".split()
scores = bm25.get_scores(query)
print(scores)
```

---

## 11. Чеклист тюнинга

* Проверить токенизацию (стемминг, лемматизация).
* Настроить stop-word list.
* Подобрать параметры BM25 (k, b).
* Использовать индексацию с компрессией.
* Для качества: гибридный поиск (BM25 + dense ANN).