# DocT5Query и Query Expansion — подробный разбор

DocT5Query — это метод **query expansion** (расширения запроса), направленный на повышение качества поиска. В отличие от моделей типа SPLADE, он работает через **генерацию псевдозапросов для документов**, которые затем индексируются в стандартный sparse‑индекс.

---

## 1. Идея

- Модель (обычно T5) обучается «представлять себя пользователем»: для каждого документа она генерирует набор возможных формулировок запроса, которые отражают то, как люди могли бы искать этот документ. Это не просто набор синонимов, а имитация поведения реального пользователя.
- Сгенерированные псевдозапросы конкатенируются с исходным текстом документа и индексируются.
- В результате документ получает «расширенную сигнатуру» из исходного содержания и дополнительных формулировок, что значительно увеличивает вероятность совпадения с пользовательскими запросами.

---

## 2. Архитектура

1. **Base encoder-decoder (T5):**
   - На вход: текст документа.
   - На выход: несколько псевдозапросов.
2. **Expansion:** псевдозапросы добавляются к тексту документа.
3. **Индексирование:** используется стандартный inverted index (Lucene/Elastic), без изменения инфраструктуры.

---

## 3. Почему это повышает recall

- Классические sparse‑методы (BM25/TF-IDF) учитывают только пересечение слов между запросом и документом.
- DocT5Query дополняет индекс **синонимами, перефразировками и близкими формулировками**, которые генерирует модель.
- Даже если запрос пользователя сформулирован иначе, он может совпасть с одним из псевдозапросов и привести к корректному результату.

**Пример:** документ «Tesla launches new electric car». Псевдозапросы: *"tesla new model", "electric vehicle release"*. Теперь по запросу «new model» документ тоже будет найден.

---

## 4. Ограничения и проблемы

1. **Шумные псевдозапросы:** модель способна генерировать нерелевантные запросы → снижение precision.
2. **Рост индекса:** каждый документ расширяется за счёт добавленных псевдозапросов, индекс может увеличиться в несколько раз.
3. **Затраты памяти:** поиск остаётся быстрым, но потребление диска и памяти растёт.
4. **Доменная зависимость:** модель T5 должна быть дообучена на целевых данных; иначе псевдозапросы будут менее релевантны.

---

## 5. Edge cases

- **Очень короткие документы:** расширение особенно полезно, так как добавляет недостающие формулировки.
- **Редкие термины:** могут быть дополнены синонимами, что увеличивает шанс нахождения документа.
- **Мультиязычие:** требуется мультиязычная модель T5 или отдельные модели для каждого языка.
- **Длинные документы:** при чрезмерной генерации псевдозапросов индекс разрастается.

---

## 6. Практические советы

- Применять DocT5Query там, где пользователи склонны формулировать запросы по-разному (QA-системы, поиск по форумам, новостям).
- Контролировать количество генерируемых псевдозапросов (обычно 10–20 на документ).
- Использовать в гибриде с BM25 или SPLADE.
- Для продакшена обучать T5 на парах query-document из конкретного домена.

---

## 7. Пример (псевдокод)

```python
from transformers import T5ForConditionalGeneration, T5Tokenizer

model = T5ForConditionalGeneration.from_pretrained("docT5query")
tokenizer = T5Tokenizer.from_pretrained("docT5query")

doc = "Tesla launches new electric car"
input_ids = tokenizer(f"expand: {doc}", return_tensors="pt").input_ids

# Генерация псевдозапросов
outputs = model.generate(input_ids, num_beams=4, num_return_sequences=5)
queries = [tokenizer.decode(o, skip_special_tokens=True) for o in outputs]

print("Псевдозапросы:", queries)
```

---

## 8. Чеклист тюнинга

- Определить оптимальное число псевдозапросов на документ.
- Проверять баланс между recall и precision.
- Контролировать рост индекса и нагрузку на память.
- Дообучать T5 на доменных данных.
- Валидировать качество через A/B‑тесты.

