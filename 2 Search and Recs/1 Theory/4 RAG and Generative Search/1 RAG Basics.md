# Основы RAG и архитектура

## 1. Определение и мотивация RAG

**Retrieval-Augmented Generation (RAG)** — это архитектура, в которой генеративная языковая модель (LLM) дополняется внешним модулем поиска (retriever). Идея: вместо того, чтобы хранить все знания в весах модели, можно динамически подгружать релевантные документы и использовать их в процессе генерации.

### Зачем нужен RAG?

1. **Уменьшение галлюцинаций**: LLM не всегда надёжен при фактических вопросах; RAG даёт grounding на реальные документы.
2. **Обновляемость**: база знаний может обновляться без полного дообучения модели.
3. **Эффективность**: можно использовать меньшую LLM, опираясь на внешний корпус.
4. **Контролируемость**: RAG позволяет ссылаться на источники, обеспечивая прозрачность.

Формально, если запрос $q$ и корпус документов $D = {d_i}$, то:

- retriever возвращает множество $R(q) = {d_{i_1}, ..., d_{i_k}}$, релевантное запросу;
- генератор LLM выдаёт $y \sim p(y | q, R(q))$.

## 2. Классическая архитектура RAG

Стандартный пайплайн состоит из трёх звеньев:

### 2.1 Retriever

- **Sparse** (BM25, SPLADE) — быстрый, устойчив к редким словам.
- **Dense** (bi-encoder эмбеддинги + ANN) — лучше захватывает семантику.
- **Hybrid** — комбинация sparse и dense сигналов.

Формально retriever решает задачу: \(R(q) = \underset{d \in D}{\arg\max} \, sim(f(q), g(d))\) где $f, g$ — функции кодирования запроса и документа, $sim$ — косинусное сходство или скалярное произведение.

### 2.2 Reranker

- **Bi-encoder**: быстрое приближение.
- **Cross-encoder**: точное ранжирование (высокая стоимость).
- **Late interaction (ColBERT)**: компромисс (токеновые векторы, MaxSim).

Формула cross-encoder: \(score(q, d) = h([q; d])\) где $h$ — трансформер, совместно кодирующий запрос и документ.

### 2.3 Generator

- LLM получает $q$ и топ-K документов $R(q)$.
- Встраивание: "Answer the question based on the following docs: ...".
- Output: $y \sim p(y | q, R(q))$.

Классическая схема:

```
Query q → Retriever → Reranker → Top-K docs → Generator (LLM) → Answer y
```

## 3. Варианты архитектуры

### 3.1 Single-hop RAG

- Однократный вызов retriever.
- Подходит для простых фактических вопросов.

### 3.2 Multi-hop RAG

- Несколько шагов поиска: сначала retriever извлекает документ, затем на основе найденного формируется уточнённый под‑запрос, после чего retriever снова вызывается. Этот процесс может повторяться несколько раз, пока не будет собрана цепочка фактов.
- Подходит для сложных вопросов, где ответ требует последовательного связывания нескольких источников (multi‑hop reasoning).

### 3.3 Conversational RAG

- Поддержка диалога: при формировании запроса retriever учитывает не только текущий вопрос пользователя, но и предыдущую историю диалога (context carry‑over). Это позволяет адаптировать поиск к многотуровому взаимодействию, уточнениям и переформулировкам запроса.
- Метрики: cumulative recall (суммарная полнота на протяжении всей сессии), groundedness across turns (насколько ответы остаются опорными на найденные документы от хода к ходу), consistency (согласованность ответов между сообщениями).

### 3.4 Memory-augmented RAG

- Хранение долговременного состояния (memory store): в систему добавляется внешний модуль памяти (например, векторное или ключ-значение хранилище), куда сохраняются предыдущие запросы и ответы. Такая память может быть краткосрочной (несколько последних шагов) или долговременной (вся история).
- Используется для агентов, которым важно помнить предысторию взаимодействия, контекст сессии или индивидуальные предпочтения пользователя. Это особенно актуально для ассистентов и диалоговых систем, которые должны поддерживать консистентность, персонализацию и возможность возвращаться к прошлым темам.

## 4. Области применения

1. **Корпоративный поиск** — доступ к внутренним документам компании.
2. **QA-системы** — чат-боты, отвечающие на фактические вопросы.
3. **Медицина** — помощь врачу на основе базы клинических статей.
4. **Юриспруденция** — поиск и суммаризация законов, судебных прецедентов.
5. **E-commerce** — ответы о товарах и рекомендациях.
6. **Наука и образование** — автоматический справочник по статьям.

## Вывод

- RAG = retriever + reranker + generator.
- Позволяет LLM использовать актуальные внешние знания.
- Есть несколько архитектурных вариантов (single-hop, multi-hop, conversational, memory-augmented).
- Применим в реальных бизнес- и научных сценариях.

