# Conversational retrieval 

## 1. Conversational retrieval: мотивация и отличие от single-turn RAG

Большинство запросов в продакшене — это не одиночные вопросы, а **диалоговые цепочки**. В них:

* смысл запроса зависит от предыдущего контекста;
* пользователь уточняет, переформулирует, ссылается на предыдущие вопросы.

RAG для диалога требует **динамического управления историей** и адаптивного выбора контекста на каждом шаге.

---

## 2. Query carry-over (context retention)

### Проблема:

Модель retriever обычно получает только текущий запрос $q_t$, игнорируя историю $H = {(q_1, a_1), \dots, (q_{t-1}, a_{t-1})}$.

### Подходы:

#### 2.1 Query rewriting

**Query rewriting** — это техника, при которой текущий запрос пользователя (обычно неполный или контекстно-зависимый) преобразуется в **самостоятельный, полносвязный запрос**, содержащий необходимую информацию из предыдущих шагов диалога.

* Люди часто говорят неполными фразами:

  * *"А когда он родился?"*
  * *"А что с ней потом стало?"*
* Такие запросы непонятны retriever'у без диалогового контекста.

**Как работает:**

1. Вход: история диалога и текущий запрос $q_t$.
2. Seq2Seq-модель (например, T5, GPT) генерирует уточнённую формулировку $q_t'$.
3. Новый запрос подаётся в retriever.

**Недостатки:**

* Может искажать исходный смысл (hallucination).
* Не всегда улавливает нужную часть истории (особенно без fine-tuning).

#### 2.2 Context-aware retrieval

**Context-aware retrieval** — это подход, при котором retriever получает не только $q_t$, но и всю (или часть) истории диалога, из которой формируется контекстный эмбеддинг.

* Используется вектор $v = f(q_1, a_1, ..., q_t)$ вместо обычного $f(q_t)$.
* Часто используется в ConvDR, QReCC и других специализированных retriever'ах.
* **Преимущество:** retriever напрямую обучен учитывать историю, не требуя query-rewriting.
* **Недостатки:**

  * Требуется обучение на диалоговых датасетах (QReCC, TopiOCQA).
  *  Вычислительно дороже (иногда приходится пересчитывать embedding по мере роста истории).
  * История может «зашумлять» query — нужен контекстный attention/pooling.&#x20;

---

## 3. Query planning

### Проблема:

Некоторые вопросы требуют рассуждений в несколько шагов:

* Пример: "Кто был президентом США, когда был основан Google?"

### Подход:

* Разбиваем исходный запрос на подзапросы (decomposition).
* Выполняем их поэтапно (ReAct, Tree-of-Thought).
* Каждый шаг может использовать retrieval + генерацию.

**Пример:**

```
Question: Кто был президентом США, когда был основан Google?
Thought: Нужно узнать, в каком году был основан Google.
Action: Search("год основания Google")
Observation: 1998
Thought: Теперь узнаем президента США в 1998.
Action: Search("президент США 1998")
Observation: Билл Клинтон
Answer: Билл Клинтон
```

---

## 4. Query refinement

### Цель:

Устранить неоднозначности и улучшить формулировку текущего запроса $q_t$ на основе:

* Истории,
* Retrieved-контекста,
* Предыдущих результатов.

### Подходы:

#### 4.1. LLM-based переформулировка
Смысл - генерация уточнённого $q_t'$ с помощью GPT/T5. Модель получает:

  * историю общения (1–3 предыдущих пар вопрос–ответ),

  * текущий неполный или контекстно-зависимый вопрос,
    и генерирует новую, **самодостаточную версию** вопроса, пригодную для подачи в retriever.
    Пример:

Был диалог:

  * Пользователь: «Расскажи про Эйнштейна.»
  * Модель: «Альберт Эйнштейн был физиком, родился в 1879…»
  * Пользователь: «А где он учился?»

  После переформулировки модель генерирует: **«Где учился Альберт Эйнштейн?»**

#### 4.2. Pseudo-relevance feedback
Смысл - переформулируем запрос после первичного retrieval.

  1. **Первичный запрос $q_t$** отправляется в retriever.
  2. Получаем top-K документов: ${d_1, d_2, ..., d_k}$.
  3. Предполагаем, что они релевантны (отсюда «pseudo»).
  4. Используем содержимое этих документов для:

     * добавления новых терминов в запрос (в sparse retrieval),
     * генерации нового запроса через LLM (в dense retrieval),
     * или повторной формулировки $q_t'$, учитывая термины и семантику top-K.

  **Зачем:**

  * Повысить **recall**: извлечь больше релевантных документов, даже если они не были в top-K изначально.
  * Уточнить **semantic intent**: если в документах часто встречаются определённые темы, можно сделать запрос более точным.

  **Пример:**

  ```
  Исходный запрос: "Что известно про Марию Кюри?"
  Top-3 документа упоминают:
  - радиоактивность
  - полоний, радий
  - Нобелевская премия

  → Новый запрос: "Открытия Марии Кюри в области радиоактивности, включая полоний, радий и Нобелевскую премию"
  ```