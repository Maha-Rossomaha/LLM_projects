# Персонализированный выбор контекста и источников

## 1. Мотивация

RAG усиливает генеративные LLM внешними источниками знаний. Однако стандартный RAG опирается на фиксированный retriever, одинаковый для всех пользователей. В реальных системах (поиск, ассистенты, рекомендации) важно учитывать **персонализацию**: разные пользователи ожидают разные документы в контексте.

---

## 2. Постановка задачи

Пусть у нас есть база документов $D = {d_1, d_2, \dots, d_N}$. При запросе $q$ retriever возвращает top-K кандидатов $C(q)$. В персонализированном RAG хотим вместо универсального $C(q)$ получить $C(q, u)$, где $u$ — профиль пользователя.

**Примеры задач:**

- Вопрос о «Python»: разработчик ждёт код, школьник — туториал, менеджер — обзор рынка.
- Вопрос «новости спорта»: один пользователь читает только про футбол, другой — про баскетбол.

---

## 3. Источники персонализации

### 3.1. Явные сигналы

- **Профиль**: возраст, язык, локация, профессия.
- **Интересы**: указанные теги/темы.

### 3.2. Неявные сигналы

- **История взаимодействия**: просмотренные документы, клики, dwell-time.
- **Диалоговый контекст**: что спрашивал пользователь раньше.
- **Социальные связи**: какие каналы/авторов читает.

### 3.3. Runtime-сигналы

- **Сессия**: временные интересы (например, во время чемпионата мира).
- **Устройство**: формат ответа (короткий vs детализированный).

---

## 4. Архитектуры персонализированного retrieval

### 4.1. User-augmented embeddings

Формируем совместное представление запроса и профиля пользователя: объединяем вектор запроса и вектор профиля (через конкатенацию, взвешенную сумму или внимание) и подаём их в совместный энкодер. 
$$
    h(q, u) = f([q; u])
$$
Здесь $f$ — bi-encoder, обученный на query–user–doc триплетах, где положительные примеры соответствуют реально выбранным пользователем документам, а отрицательные — нерелевантным. Такая схема позволяет учитывать индивидуальные предпочтения в самом векторном пространстве.

### 4.2. Two-tower архитектуры

- **Query tower** кодирует $q$.
- **User tower** кодирует $u$.
- Их объединение используется для вычисления финального представления запроса с учётом особенностей пользователя. На практике это может быть конкатенация или взвешенное среднее эмбеддингов, после чего полученный вектор применяется для поиска в индексе. Таким образом формируется персонализированная весовая схема: документы, ближе связанные с предпочтениями конкретного пользователя, получают более высокий ранг при поиске.

### 4.3. Hybrid reranking

Retriever возвращает общий пул кандидатов. Далее reranker учитывает профиль $u$ при переоценке релевантности более детально: он может использовать отдельный user encoder для построения эмбеддинга профиля и объединять его с эмбеддингом запроса, либо работать как cross-encoder, принимая на вход одновременно запрос, документ и профиль пользователя. На основе этого модель вычисляет функцию score(q, d, u), где d — документ, и формирует обновлённый рейтинг. Обучение такого reranker’а обычно проводится на пользовательских логах — кликах, времени чтения, признаках отказа, что позволяет системе адаптироваться к реальному поведению конкретного пользователя.

### 4.4. Memory-augmented personalization

Хранение «памяти пользователя» в отдельном векторном индексе: туда записываются эмбеддинги документов, с которыми пользователь уже взаимодействовал (читал, кликал, сохранял). Такой индекс можно обновлять инкрементально после каждой сессии. При поиске RAG выполняет слияние двух источников — глобального индекса (общие документы для всех) и пользовательского memory-индекса, где хранятся личные предпочтения. Fusion может быть реализован как объединение top-K списков с последующим reranking, либо через взвешенную сумму скорингов: $score(q, d) = \alpha\,score_{global}(q, d) + (1-\alpha)\,score_{user}(q, d)$. Это позволяет системе учитывать как общую релевантность документа, так и его ценность конкретно для данного пользователя.

---

## 5. Алгоритмы выбора контекста

### 5.1. Static Top-K

Простой подход: фиксированный $K$ документов, независимо от пользователя.

### 5.2. Personalized Top-K

В этом подходе количество документов, передаваемых в LLM, зависит от характеристик пользователя.

* **Адаптивный размер K(u):** если интересы пользователя очень специфичны (например, он всегда читает про один конкретный клуб), то достаточно меньшего K, чтобы не перегружать модель. Если интересы шире (например, пользователь интересуется целой областью науки или спорта), то K увеличивается, чтобы охватить разнообразие.
* **Diversity penalty:** после первичного выбора top-K документов применяется механизм штрафов за избыточное сходство. Примеры методов:
  * **MMR (Maximal Marginal Relevance):** каждый следующий выбранный документ должен быть не только релевантен запросу, но и максимально отличаться от уже выбранных.
  * **xQuAD (explicit Query Aspect Diversification):** документы оцениваются с учётом покрытия различных аспектов запроса и интересов пользователя.

Таким образом Personalized Top-K стремится сохранить баланс: учитывать индивидуальные интересы и одновременно обеспечивать разнообразие результатов, чтобы избежать ситуации, когда пользователь видит несколько почти идентичных документов.

### 5.3. Contextual re-clustering

Вместо простого выбора отдельных документов, система сначала выполняет кластеризацию кандидатов (например, с помощью k-means или иерархических методов). Каждому кластеру можно сопоставить определённый аспект темы запроса.

Алгоритм работает так:

1. Собираем top-N кандидатов из retriever.
2. Строим их векторные представления и группируем в K кластеров.
3. Для каждого кластера вычисляем релевантность с учётом профиля пользователя $u$ — например, через усреднение скорингов документов кластера или отдельную модель.
4. Выбираем те кластеры, которые лучше всего соответствуют интересам $u$.
5. Из выбранных кластеров берём документы для контекста, обеспечивая тем самым покрытие разных аспектов, релевантных именно этому пользователю.

**Преимущество:** система не ограничивается только ближайшими документами, а старается охватить смысловое разнообразие. Это особенно полезно, если запрос многозначен или пользователь интересуется разными аспектами одной темы.

### 5.4. Utility-based selection

Задача этого подхода — не просто выбрать наиболее релевантные документы, а учесть их дополнительный вклад (маржинальную полезность) в уже сформированный контекст.

Алгоритм можно описать так:
1. Стартуем с пустого множества выбранных документов.
2. Для каждого кандидата оцениваем его базовую релевантность запросу q и профильную релевантность пользователю u.
3. Добавляем фактор новизны: насколько данный документ содержит новую информацию по сравнению с уже выбранными (например, через минимальное расстояние в эмбеддинговом пространстве или снижение схожести с текущим контекстом).
4. Вычисляем итоговый скор как комбинацию: $utility(d \;|\; q, \;u, \;Context) = \alpha \cdot relevance(q,\; d) + \beta \cdot relevance(u,\; d) + \gamma \cdot novelty(d,\; Context)$
5. Итеративно выбираем документы с наибольшей маржинальной полезностью, пока не достигнут лимит K.

**Преимущество:** контекст получается не только релевантным, но и максимально информативным для конкретного пользователя, без избыточных повторов.

---

## 6. Метрики качества

- **Personalized Recall\@K** — сколько релевантных именно пользователю документов попало в top-K.
- **nDCG\@K (per user)** — ранговая метрика с учётом персонализированных релевантностей.
- **CTR, dwell-time** — онлайн сигналы.
- **Diversity, novelty** — избегаем однообразия.
- **Fairness\@K** — равномерность покрытия интересов.

---

## 7. Edge cases

- **Cold start**: новый пользователь без истории. Эта ситуация особенно сложна, так как у системы нет сигналов о предпочтениях. Возможные решения:
  - *Популярные fallback-документы*: показывать наиболее часто выбираемые материалы в данной категории как базовый вариант.
  - *Zero-shot эмбеддеры*: использовать универсальные модели (например, E5, BGE-M3), которые хорошо работают без обучения на конкретном пользователе.
  - *Meta-features*: учитывать язык интерфейса, геолокацию, тип устройства, время суток.
  - *User onboarding*: при первом использовании можно задать пользователю короткий опрос о предпочтениях или предложить выбор тем.
  - *Federated warm-up*: агрегировать обобщённые интересы схожих пользователей и применять их как стартовый профиль. Таким образом cold start смягчается комбинацией универсальных сигналов и минимального вовлечения пользователя.
- **Sparse history**: у пользователя есть лишь ограниченное количество взаимодействий (несколько кликов или запросов), поэтому сигналов для построения точного профиля мало. Возможные стратегии:
  - *Использование мета-фичей*: локация, язык, тип устройства, часовой пояс могут подсказать базовые предпочтения.
  - *Content-based transfer*: перенос знаний из похожих предметных областей, например, если пользователь читал статьи про Python, можно предложить материалы и по смежным темам (ML, data science).
  - *Cluster-based smoothing*: объединение пользователя с «похожими» пользователями по ограниченному набору признаков и использование их истории как дополнительного источника.
  - *Temporal weighting*: больший вес недавним действиям, так как они точнее отражают текущие интересы.
  - *Active learning*: система может предлагать несколько разнообразных документов, чтобы получить дополнительный отклик и быстрее уточнить профиль. Таким образом sparse history компенсируется комбинированием слабых сигналов и стратегий дообучения на ближайших кластерах пользователей.
- **Shifting interests**: интересы пользователя меняются со временем, и старые сигналы могут вводить систему в заблуждение. Чтобы адаптироваться, используют несколько стратегий:
  - *Временной decay*: более недавние взаимодействия получают больший вес при расчёте профиля.
  - *Сезонные и событийные факторы*: учитывается контекст времени (например, чемпионат мира или премьера фильма).
  - *Sliding window*: профиль формируется только на основе последних N действий или временного окна (например, последние 30 дней).
  - *Change detection*: использование метрик (KL-divergence, PSI) для фиксации сдвига в интересах и перезапуска профиля.
  - *Multi-profile*: хранение нескольких профилей для разных доменов интересов (работа, хобби, спорт) и динамическое переключение между ними. Таким образом система может быть чувствительной к изменению интересов и подстраиваться под текущий контекст пользователя.
- **Privacy constraints**: при персонализации важно не нарушать приватность пользователя и соответствовать требованиям законодательства (GDPR, CCPA и др.). Основные меры:
  - *Минимизация данных*: хранить только те признаки, которые реально нужны для персонализации, избегая избыточного сбора.
  - *Анонимизация*: удаление или замена PII (Personally Identifiable Information) на псевдонимы или хэши.
  - *Шифрование*: данные профиля шифруются при хранении (at-rest, например AES-GCM) и при передаче (in-transit, TLS).
  - *Access control*: разграничение доступа к данным, ролевая модель (RBAC), логирование обращений.
  - *Federated learning / on-device personalization*: обучение и хранение профиля на устройстве пользователя, чтобы исключить передачу данных на сервер.
  - *Differential privacy*: добавление шума в данные или эмбеддинги, чтобы скрыть индивидуальные особенности при агрегированном обучении.
  - *Право на забвение*: обеспечение возможности быстрого удаления данных по запросу пользователя. Эти меры позволяют строить персонализированные системы без компромиссов в области конфиденциальности.

---

## 8. Интеграция в RAG

1. Retriever: поиск кандидатов с учётом профиля.
2. Reranker: пересчёт релевантности с учётом $u$.
3. Context selector: отбор документов в окно LLM.
4. LLM: генерация ответа с учётом персонализированного контекста.