# Графовые методы в рекомендациях: распространение предпочтений и LightGCN

## 0) Зачем графы в рекомендациях
Коллаборативная фильтрация говорит: “пользователи похожи, если они взаимодействуют с похожими айтемами”.
Графовые методы формулируют это буквально:
- **пользователи и айтемы** — вершины,
- **взаимодействия** — рёбра,
- рекомендации — результат **распространения сигналов/предпочтений** по графу.

Плюсы графового взгляда:
- естественно моделирует “путь” от пользователя к новым айтемам через соседей,
- хорошо работает в implicit,
- даёт сильные кандидатные модели (retrieval) для top‑K.

---

## 1) База: двудольный граф и ключевые термины
### 1.1 Двудольный граф (user–item bipartite graph)
**Двудольный граф** — граф, у которого вершины разбиты на два непересекающихся множества `U` и `I`, и рёбра возможны только между долями.

В рекомендациях:
- `U` — пользователи,
- `I` — айтемы,
- `E ⊆ U×I` — взаимодействия.

Обозначения:
- `G=(V,E)`, где `V=U∪I`.
- соседство:
  - `N(u) = { i ∈ I : (u,i)∈E }`
  - `N(i) = { u ∈ U : (u,i)∈E }`

### 1.2 Что лежит в узлах и на рёбрах
**В узлах** обычно лежат обучаемые эмбеддинги:
- `e_u ∈ ℝ^d` для пользователя,
- `e_i ∈ ℝ^d` для айтема.

**На рёбрах** может быть:
- просто факт взаимодействия (1),
- вес `w_{ui}` (частота, рейтинг, duration),
- тип события (view/cart/buy) → разные веса.

В LightGCN базовая версия обычно использует **неориентированный граф** и чаще всего бинарные рёбра.

### 1.3 Adjacency / degree / нормализация
Пусть `A` — матрица смежности графа `|V|×|V|`:
- для user–item графа `A` имеет блочную структуру:

$$
A=\begin{pmatrix}
0 & R\\
R^\top & 0
\end{pmatrix}
$$

где `R` — матрица взаимодействий `|U|×|I|`.

Степени вершин:
$$
D_{vv} = \sum_{t} A_{vt}
$$

Ключевая нормализация (symmetric normalization):
$$
\tilde{A} = D^{-1/2} A D^{-1/2}
$$

Интуиция: если у узла огромная степень, он не должен доминировать просто потому что он “популярный”.

---

## 2) Preference propagation: распространение предпочтений
### 2.1 Интуитивная картинка
Если пользователь `u` взаимодействовал с айтемом `i`, то “предпочтение” можно передать:
- от `u` к `i` (user → item),
- затем от `i` к другим пользователям (item → user),
- затем к другим айтемам (user → item).

Это соответствует путям вида:

$$
u \to i \to u' \to i'
$$

То есть “похожие пользователи” возникают через общие айтемы, а “похожие айтемы” — через общих пользователей.

### 2.2 Спектральный взгляд (очень кратко)
Умножение на $\tilde{A}$ — это “сглаживание” сигналов по графу (graph smoothing):

$$
H^{(l+1)} = \tilde{A} H^{(l)}
$$

Каждый шаг смешивает представление узла с представлениями соседей.

---

## 3) LightGCN: ключевая идея
### 3.1 Чем LightGCN отличается от классических GCN
Классические GCN часто используют:
- weight matrices `W_l`,
- нелинейности `σ`,
- иногда self‑loop,
- сложные агрегации.

**LightGCN** упрощает:
- убирает нелинейности,
- убирает матричные преобразования на каждом слое,
- оставляет только **нормализованную агрегацию соседей**.

Причина: в CF‑графах основная польза — именно в **пропагации коллаборативного сигнала**, а не в сложной трансформации.

---

## 4) Математика LightGCN (полная)
### 4.1 Инициализация эмбеддингов (layer 0)
Задаём обучаемые параметры:

$$
E^{(0)} = \begin{bmatrix}E_U^{(0)}\\E_I^{(0)}\end{bmatrix} \in \mathbb{R}^{(|U|+|I|)\times d}
$$

где строки — эмбеддинги узлов:
- $e_u^{(0)}$ для `u∈U`,
- $e_i^{(0)}$ для `i∈I`.

### 4.2 Пропагация (графовая “свёртка”)
На каждом слое:

$$
E^{(l+1)} = \tilde{A}\,E^{(l)}
$$

То есть для конкретного пользователя:

$$
e_u^{(l+1)} = \sum_{i\in N(u)} \frac{1}{\sqrt{|N(u)|}\sqrt{|N(i)|}}\; e_i^{(l)}
$$

и для айтема:

$$
e_i^{(l+1)} = \sum_{u\in N(i)} \frac{1}{\sqrt{|N(i)|}\sqrt{|N(u)|}}\; e_u^{(l)}
$$

Здесь видно:
- каждый слой чередует “user ← items” и “item ← users”,
- нормализация делит вклад популярного узла.

Это и называют “graph convolution” в данном контексте: локальная агрегация соседей со стационарным kernel (весом), заданным $\tilde{A}$.

### 4.3 Финальные эмбеддинги как сумма по слоям
LightGCN агрегирует эмбеддинги с разных слоёв:

$$
 e_v = \sum_{l=0}^{L} \alpha_l\, e_v^{(l)}
$$

Часто берут равные веса:

$$
\alpha_l = \frac{1}{L+1}
$$

Интуиция:
- `l=0` — “чистый ID‑эмбеддинг” (без графа),
- `l=1` — 1‑hop (прямые соседи),
- `l=2` — 2‑hop (user→item→user, или item→user→item),
- большие `l` — более дальние связи, но риск “пересглаживания” (over‑smoothing).

### 4.4 Скоринг
Для пары user–item:

$$
\hat{x}_{ui} = e_u^\top e_i
$$

Это важно для прод‑retrieval: dot product → можно ANN.

---

## 5) Функции потерь для LightGCN
Графовые CF‑модели почти всегда учатся на implicit‑сигнале. Два самых типичных выбора:

### 5.1 BPR‑loss (pairwise)
Берём триплет `(u,i,j)`:
- `i` — позитив из `N(u)`,
- `j` — негатив/unknown.

$$
\mathcal{L}_{BPR} = -\sum_{(u,i,j)} \ln\sigma(\hat{x}_{ui}-\hat{x}_{uj}) + \lambda\|\Theta\|_2^2
$$

`Θ` включает все эмбеддинги $E^{(0)}$ (а через пропагацию — и финальные).

### 5.2 BCE / sampled softmax (pointwise)
Иногда используют pointwise:

$$
\mathcal{L}_{BCE} = -\sum_{(u,i)}\Big( y_{ui}\ln\sigma(\hat{x}_{ui}) + (1-y_{ui})\ln(1-\sigma(\hat{x}_{ui}))\Big)
$$

но нужен negative sampling и аккуратные веса.

На практике для LightGCN чаще обсуждают BPR как стандарт.

---

## 6) Почему negative sampling критичен
В implicit данных нет явных негативов.
Мы вынуждены выбирать `j` (негатив) как айтем, с которым `u` не взаимодействовал.

Проблемы:
1) **Ложные негативы**: пользователь мог бы любить `j`, просто не видел.
2) **Слишком лёгкие негативы** при uniform sampling:
   - случайный айтем часто очевидно нерелевантен,
   - градиент маленький,
   - обучение медленное.

### 6.1 Медленная сходимость при равномерном семплинге
Если `j` почти всегда далеко от `i` и не конкурирует в ранжировании, то для BPR:
- $\hat{x}_{ui}-\hat{x}_{uj}$ быстро становится положительным,
- $\sigma(\cdot)$ насыщается,
- градиенты малы.

### 6.2 Популярность и “harder negatives”
Популярные айтемы чаще оказываются конкурентными:
- они ближе к “экспозиции” (их реально видят),
- модель часто по умолчанию тянется к популярным.

Поэтому негативы часто семплируют не равномерно, а

$$
P(j) \propto \mathrm{pop}(j)^{\beta}
$$

где популярность — количество взаимодействий. Частый компромисс:

$$
\beta = 1/2 \quad \Rightarrow \quad P(j) \propto \sqrt{\mathrm{pop}(j)}
$$

Почему корень:
- `β=1` слишком сильно смещает в популярное,
- `β=0` слишком лёгкие негативы,
- `β=1/2` даёт “сложнее, но не совсем перекос”.

Это ускоряет обучение и повышает качество top‑K.

---

## 7) Почему LightGCN “любит” популярное (popularity bias)
Даже при нормализации $D^{-1/2}AD^{-1/2}$ популярные узлы остаются центральными:
- у популярного айтема много соседей → он находится на огромном числе путей,
- пропагация распространяет его сигнал шире,
- при негатив‑семплинге из популярных модель чаще видит их как конкурентов.

В результате:
- модель может переобучаться на “популярность”,
- особенно если training objective не учитывает exposure и позиционные эффекты.

Практические меры:
- дебайс‑семплинг,
- корректировка кандидатной выдачи по популярности,
- re‑ranking с дополнительными целями (diversity, novelty),
- добавление контентных/контекстных сигналов (hybrid).

---

## 8) Функции агрегации и “штрафы” при агрегации
### 8.1 Базовая агрегация в LightGCN
Фактически это weighted sum соседей:

$$
\mathrm{AGG}(v)=\sum_{t\in N(v)} w_{vt}\,e_t
$$

где веса

$$
w_{vt}=\frac{1}{\sqrt{deg(v)}\sqrt{deg(t)}}
$$

Этот вес — “штраф” за большие степени:
- если `deg(t)` большой, вклад каждого соседа уменьшается.

### 8.2 Почему нужны такие штрафы
Без нормализации популярные узлы доминировали бы просто по количеству рёбер.
С нормализацией мы приближаем вклад к “среднему по соседям”, снижая перекос.

---

## 9) Большая практическая проблема: user–item граф и масштабы
В крупных системах:
- пользователей может быть *на порядок* больше, чем айтемов,
- значительная часть пользователей вообще не участвует в online‑inference
  (например, рекомендации строятся по последним событиям, а userID может быть анонимным/нестабильным).

Тогда хранить и обучать эмбеддинги для всех пользователей:
- дорого по памяти,
- дорого по обновлению,
- часть параметров “мертвые” и редко обновляются.

### 9.1 Ключевая эвристика
Эмбеддинг пользователя можно выразить как **линейную комбинацию эмбеддингов айтемов** из его истории.

Например, простейшее:

$$
 e_u \approx \frac{1}{|N(u)|}\sum_{i\in N(u)} e_i
$$

Это уже похоже на 1‑hop агрегацию.

Следствие: можно уменьшить роль пользователей как параметров и перейти к item‑centric графам.

---

## 10) Вариант: item×item граф (когда user‑граф слишком большой)
### 10.1 Как строится item–item граф
Вершины: только айтемы `I`.

Рёбра: соединяем `i` и `j`, если существует пользователь, который взаимодействовал с обоими:

$$
(i,j) \in E_{II} \iff \exists u: (u,i)\in E \;\wedge\; (u,j)\in E
$$

Вес ребра можно задать по числу совместных пользователей:

$$
 w_{ij} = |\{u: i\in N(u) \wedge j\in N(u)\}|
$$

или по PMI/нормированным ко‑встречаемостям.

### 10.2 Зачем item–item граф
- параметров меньше (нет эмбеддингов юзеров),
- инференс можно делать из последних просмотренных айтемов:
  - пользователь = “корзина/сессия”,
  - быстро и удобно.

### 10.3 Проблема шума и как “резать ветки”
Если соединять всё со всем по любому совместному пользователю, граф будет шумным.
Практические фильтры:
- минимум совместных пользователей `w_{ij} ≥ c_min`,
- top‑K соседей по каждому айтему (kNN‑граф),
- временные окна (совместность в близкие даты),
- исключение слишком популярных айтемов как “хабов” (они создают спуровые связи).

---

## 11) Агрегация и обучение на item–item графе
### 11.1 Эмбеддинги айтемов
Инициализируем $e_i^{(0)}$ и делаем пропагацию по item–item графу:

$$
E^{(l+1)} = \tilde{A}_{II}\,E^{(l)}
$$

где $\tilde{A}_{II}=D^{-1/2}A_{II}D^{-1/2}$.

### 11.2 Эмбеддинг пользователя как агрегация истории
Если у пользователя есть последние айтемы `S_u` (сессия/история), то строим “онлайн‑эмбеддинг”:

$$
 e_u = \sum_{i\in S_u} a_{ui}\, e_i
$$

где веса `a_{ui}` могут учитывать:
- тип события (buy > cart > view),
- recency (последние важнее),
- нормировку.

После этого скоринг — dot product:

$$
\hat{x}_{ui} = e_u^\top e_i
$$

### 11.3 Как учить (пример: BPR)
Можно по‑прежнему оптимизировать BPR:
- позитивы — айтемы из истории,
- негативы — не в истории.

Но важно: `e_u` не параметр, а функция от айтемов → градиент течёт в item‑эмбеддинги.

---

## 12) Почему это хорошая кандидатная модель (retrieval) и как входит в ансамбль
Графовые эмбеддинги дают:
- быстрый скоринг (dot product),
- ANN‑индексацию,
- хорошие “семантические” соседства по коллаборативному сигналу.

В прод‑стеке обычно:
1) **Candidate generation**: LightGCN / item‑item граф / MF → быстро получить top‑N.
2) **Re‑ranking**: более тяжёлая модель с фичами/контекстом (GBDT/NN/LLM‑signals) → точная выдача.

Графовые методы ценны именно как **retrieval‑кандидатник**.

---

## 13) Построение графа и один шаг LightGCN

### 13.1 Построение нормализованной матрицы $\tilde{A}$
```python
import numpy as np
from scipy.sparse import coo_matrix, csr_matrix


def build_bipartite_norm_adj(n_users, n_items, interactions):
    """
    interactions: list of (u, i) positive edges
    returns: \tilde{A} in CSR, size (n_users+n_items, n_users+n_items)
    """
    # build R as sparse
    rows = [u for u, i in interactions]
    cols = [i for u, i in interactions]
    data = np.ones(len(interactions), dtype=np.float32)
    R = coo_matrix((data, (rows, cols)), shape=(n_users, n_items)).tocsr()

    # adjacency blocks
    # A = [[0, R], [R^T, 0]]
    upper = csr_matrix(np.hstack([np.zeros((n_users, n_users), dtype=np.float32), R.toarray()]))
    lower = csr_matrix(np.hstack([R.T.toarray(), np.zeros((n_items, n_items), dtype=np.float32)]))
    A = csr_matrix(np.vstack([upper.toarray(), lower.toarray()]))

    deg = np.array(A.sum(axis=1)).ravel()
    deg_inv_sqrt = 1.0 / np.sqrt(deg + 1e-12)
    D_inv_sqrt = csr_matrix(np.diag(deg_inv_sqrt))

    A_norm = D_inv_sqrt @ A @ D_inv_sqrt
    return A_norm
```

Примечание: тут ради наглядности использованы `.toarray()` — это НЕ для больших данных.
В проде всё делается полностью sparse.

### 13.2 Пропагация LightGCN и финальный эмбеддинг
```python
def lightgcn_forward(A_norm, E0, L=2):
    """A_norm: CSR (N,N), E0: (N,d)"""
    Es = [E0]
    E = E0
    for _ in range(L):
        E = A_norm @ E
        Es.append(E)
    # average over layers
    E_final = sum(Es) / len(Es)
    return E_final
```

### 13.3 BPR‑loss для батча триплетов
```python
def bpr_loss(E_user, E_item, triplets, reg=1e-4):
    # E_user: (n_users, d), E_item: (n_items, d)
    loss = 0.0
    for u, i, j in triplets:
        x_ui = E_user[u] @ E_item[i]
        x_uj = E_user[u] @ E_item[j]
        x_uij = x_ui - x_uj
        loss += -np.log(1.0 / (1.0 + np.exp(-x_uij)) + 1e-12)
    # simple L2
    loss += reg * (np.sum(E_user**2) + np.sum(E_item**2))
    return loss / len(triplets)
```

Для реального обучения нужен autograd (PyTorch) и батчи.

---

## 14) Что важно запомнить (TL;DR)
- Рекомендательный граф чаще всего **двудольный user–item**.
- LightGCN = нормализованная агрегация соседей без нелинейностей:
  - $E^{l+1}=\tilde{A}E^{l}$,
  - финальный эмбеддинг = сумма/среднее слоёв.
- Учим чаще всего через **BPR**; negative sampling критичен.
- Uniform negative sampling даёт медленную сходимость; помогает `P(j)∝pop(j)^{1/2}`.
- Популярность и хабы создают bias.
- Масштаб user‑эмбеддингов может быть проблемой → переход к **item×item графу** и “user = агрегация последних айтемов”.
- Графовые методы — сильные кандидатные модели для retrieval + ANN и хорошо входят в ансамбль.