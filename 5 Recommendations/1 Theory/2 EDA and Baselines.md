# Первичный EDA в рекомендательных системах и простые бейзлайны

## 1. Задача и типичные данные

В рекомендательных системах у нас почти всегда есть таблица взаимодействий вида:

* `user_id` — пользователь,
* `item_id` — объект (товар, фильм, трек, видео),
* `timestamp` — время события,
* сигнал интереса: `rating`, `watch_time`, `click`, `purchase`, `like` и т.п.,
* дополнительные признаки: пол, возраст, категория товара, жанр, платный/бесплатный тариф и т.д.

Первичный EDA здесь нужен не ради формальности, а чтобы ответить на несколько базовых вопросов:

1. Как устроены данные: насколько матрица user–item разреженная, насколько выражен long tail.
2. Насколько стабильны интересы во времени: есть ли дрейф, сезонность, устаревание контента.
3. Как разные сегменты пользователей ведут себя по-разному.
4. Какие самые простые, но при этом адекватные бейзлайны можно построить и с чем дальше сравнивать сложные модели.

---

## 2. Структура данных и разреженность

Первый блок EDA — понимать базовую геометрию данных:

* количество пользователей `U = |users|`,
* количество объектов `I = |items|`,
* количество взаимодействий `N`,
* плотность матрицы: `density = N / (U * I)`.

На этом же этапе стоит посмотреть:

* распределение сигнала интереса (распределение рейтингов, watch_time, лайков),
* количество взаимодействий на пользователя,
* количество взаимодействий на item.

Уже тут часто видно:

* много ли «одноразовых» пользователей с 1–2 событиями;
* много ли товаров с 1–2 взаимодействиями;
* есть ли явные аномалии (например, пользователи с несколькими тысячами событий, которых, возможно, надо выделить отдельно).

Это всё напрямую определяет сложность задачи: если у 70% item’ов ≤ 2 взаимодействия, никакая изящная модель не «выучит» про них много — придётся отдельно решать проблему с хвостом и cold start.

---

## 3. Long tail по пользователям и по item’ам

### 3.1. Что такое long tail

В рекомендательных системах почти всегда наблюдается «длинный хвост» (long tail):

* небольшое число популярных товаров даёт большую часть взаимодействий;
* небольшое число «плотных» пользователей создаёт львиную долю активности;
* огромная масса редких товаров и малoактивных пользователей имеет по 1–2 события.

Это важно и с точки зрения качества рекомендаций (хотим ли мы рекомендовать хвост или нас устраивает только голова каталога), и с точки зрения метрик (модель может быть очень хороша по hit-rate (в топ-K рекомендаций для пользователя часто попадает хотя бы один “правильный” объект), но рекомендовать только топ-100 популярных фильмов).

### 3.2. Как это анализировать

1. Для item’ов:

   * группировка по `item_id` и подсчёт `interactions_cnt` (количество событий: просмотры, клики и т.п.),
   * гистограмма/лог-гистограмма `interactions_cnt`,
   * сортировка item’ов по убыванию `interactions_cnt` и построение кумулятивной суммы (см. ниже).

2. Для user’ов:

   * группировка по `user_id` и подсчёт событий на пользователя,
   * аналогичные графики.

### 3.3. Кумулятивная сумма (cumsum) и зачем она нужна

Кумулятивная сумма (cumsum) по отсортированным item’ам отвечает на вопросы типа:

* «Какую долю всех взаимодействий дают топ-K популярных item’ов?»
* «Сколько процентов каталога (по количеству item’ов) нужно, чтобы покрыть X% всех исторических взаимодействий?»

Типичный график:

* по оси X — доля каталога, отсортированного по популярности (от 0 до 1),
* по оси Y — доля всех взаимодействий, накопленная cumsum (тоже 0–1).

Интерпретация:

* если 10% item’ов дают 90% всех взаимодействий — хвост очень длинный и тонкий;
* если распределение ближе к равномерному — long tail менее выражен.

Отдельно можно построить:

* cumsum по user’ам: сколько % пользователей генерируют 80–90% событий.

Практические выводы:

* если популярность сильно концентрирована, то простые бейзлайны на популярности будут очень сильными;
* одновременно это значит, что «дальняя часть хвоста» практически не видна в данных и её нельзя адекватно выучить без дополнительных источников информации (описания, контент, онтологии и т.п.).

---

## 4. Время: стационарность, дрейф, сезонность, устаревание

### 4.1. Что такое стационарность в контексте рекомендаций

Грубо: данные стационарны, если распределения:

* интересов пользователей (какие категории, жанры, типы товаров они выбирают),
* популярности item’ов,

во времени не меняются (или меняются слабо и предсказуемо).

На практике чаще наблюдаем нестационарность:

* дрейф интересов: аудитория постепенно уходит из одного жанра в другой;
* сезонность: регулярные пики по праздникам, выходным, рабочим дням;
* устаревание контента: старые товары и фильмы постепенно «умирают» по популярности.

Основной практический вопрос: можно ли обучиться на истории глубиной в несколько лет и рассчитывать, что эта модель будет нормально работать завтра.

### 4.2. Какие временные графики строить

1. **Активность по времени:**

   * количество событий по дням/неделям/месяцам;
   * средний рейтинг или средний «интерес» по времени;
   * доля событий в основных категориях по времени.

2. **Сезонность и режим дня:**

   * распределение событий по часам суток;
   * распределение по дням недели;
   * тепловая карта «день недели × час» — видно, когда платформа живёт активнее всего.

3. **Динамика категорий и жанров:**

   * для каждого крупного жанра/категории — доля событий по времени (line-plot);
   * можно смотреть отдельно в разных сегментах пользователей.

4. **Стабильность распределения во времени:**

   * для каждого временного окна (например, месяц) считаем распределение по категориям;
   * считаем похожесть соседних окон (cosine similarity / Jensen–Shannon и т.п.);
   * падение похожести между окнами = дрейф интересов.

### 4.3. Устаревание контента

Для анализа старения item’ов:

* для каждого item строим зависимость «количество событий / просмотров от времени с момента релиза или появления в системе»;
* можно усреднить по группам (по категориям, годам релиза, типам контента).

Обычно видно:

* всплеск интереса в первые дни/недели,
* затем затухание (часто близкое к экспоненциальному).

Практический вывод: модели и бейзлайны должны учитывать свежесть (time-aware рекомендации, фичи «сколько прошло дней с релиза»), а обучение следует делать с разумным ограничением по давности данных, если старый паттерн поведения уже не актуален.

---

## 5. Сегменты пользователей и гетерогенность

Помимо времени, часто важно смотреть на гетерогенность между сегментами:

* пол,
* возрастные группы,
* платные/бесплатные пользователи,
* география и т.п.

Типичные шаги:

1. Разбиваем пользователей на сегменты (например, male/female или возрастные когорты).
2. Для каждого сегмента считаем:

   * распределение по категориям/жанрам;
   * активность по времени (те же временные ряды и heatmaps, но отдельно);
   * базовую статистику (средний чек, среднее количество событий на пользователя, конверсию в покупку и т.д.).
3. Сравниваем сегменты между собой.

Зачем:

* понять, насколько вообще допустимо «одна модель для всех»;
* увидеть сегменты, по которым понадобятся специализированные бейзлайны или модели (например, детский контент, премиальные подписчики и т.п.).

---

## 6. Простые бейзлайны

После того как мы понимаем структуру данных, long tail и временные эффекты, имеет смысл собрать набор простых бейзлайнов, которые:

1. легко реализуются,
2. дают неожиданно сильные результаты,
3. служат точкой отсчёта для сложных моделей.

### 6.1. Бейзлайны на популярности

Самый базовый, но часто очень сильный вариант:

* считаем глобальный топ item’ов по количеству взаимодействий (или по суммарному watch_time, количеству покупок, лайков и т.п.);
* рекомендуем всем пользователям этот топ.

Вариации:

* топ популярных item’ов **за последние N дней** — рудиментарный учёт свежести;
* топ по **категории**: определяем любимые категории пользователя (по его истории) и рекомендуем популярное в них;
* топ по **сегменту** (мужчины/женщины, платные/бесплатные) — более тонкий вариант, если поведение сегментов сильно различается.

Плюс таких бейзлайнов — они отлично ложатся на аналитику long tail и cumsum: по cumsum-кривой можно заранее понять, какой максимум покрытия достижим для подобных моделей.

### 6.2. Рейтинговые бейзлайны и user/item bias

Если есть явный рейтинг (звёздочки, баллы), стандартный набор базовых моделей:

1. **Глобальное среднее**
   `μ = средний рейтинг по всем парам (u, i)`.

2. **Среднее по item**
   `r̄ᵢ = средний рейтинг конкретного item’а`.

3. **Среднее по user**
   `r̄ᵤ = средний рейтинг конкретного пользователя`.

Самый полезный и осмысленный baseline — модель с **user/item bias**:

$$
\hat r_{ui} = \mu + b_u + b_i,
$$

где:

* $\mu$ — глобальное среднее,
* $b_u$ — смещение пользователя (склонность ставить выше/ниже среднего),
* $b_i$ — смещение товара (насколько товар в среднем лучше/хуже других).

Обычно обучается с L2-регуляризацией (ridge), через:

* простую оптимизацию (градиентный спуск),
* или решение нормальных уравнений.

Зачем:

* это сильный sanity-check: если сложная модель не обгоняет $\mu + b_u + b_i$ по RMSE/MAE — что-то не так;
* показывает, как много вариации рейтинга объясняется банальными сдвигами;
* bias’ы можно позже использовать как фичи в более сложных моделях (факторизационные, нейросетевые и т.п.).

### 6.3. Простая персонализация без факторизации

Даже без матричной факторизации или нейросетей можно делать персональные рекомендации.

1. **Профиль пользователя по категориям:**

   * для каждого пользователя считаем долю его взаимодействий по категориям/жанрам;
   * выбираем топ-k категорий;
   * рекомендуем внутри этих категорий популярные item’ы (по взаимодействиям или по рейтингу).

   Это простейший вариант контентно-ориентированной персонализации.

2. **Пользователи-соседи на агрегированных признаках:**

   * собираем компактный вектор для пользователя: частоты категорий, средний чек, средний рейтинг, долю «длинных»/«коротких» фильмов/треков и т.д.;
   * ищем ближайших пользователей в этом пространстве (cosine / euclidean);
   * рекомендуем популярные item’ы среди соседей.

3. **Time-aware профиль:**

   * строим профиль пользователя, используя только последние N дней/недель,
   * этим грубо учитываем дрейф интересов: старые и давно не смотримые жанры/категории вываливаются.

Такие бейзлайны уже чувствительны к индивидуальным вкусам и времени, но всё ещё легко реализуемы.

---

## 7. Как EDA связывается с дальнейшим моделированием

1. **Long tail и разреженность** → понимание, сколько вообще смысла в сложных моделях и какие метрики разумно использовать.
   Если 90% взаимодействий сидит в 10% каталога, модель, которая «игнорирует хвост», уже покрывает большую часть истории.

2. **Стационарность и дрейф** → выбор стратегии разбиения на train/validation/test.
   В рекомендациях почти всегда стоит использовать временной сплит (train — прошлое, valid/test — будущее), а не случайный.

3. **Сезонность и старение контента** → решение, на какую глубину истории опираться и как часто дообучать модель.
   Если интересы сильно меняются, чем «свежее» обучение, тем лучше.

4. **Сегменты пользователей** → понимание, где одна модель в принципе не вытянет, и нужен либо сегментированный подход, либо дополнительные фичи.

5. **Бейзлайны** → базовый уровень, который обязана обогнать любая дальнейшая модель.
   Модель, которая не лучше топ-популярности или $\mu + b_u + b_i$, просто не имеет смысла.

---

## 8. Итог

Хороший первичный EDA в задачах рекомендательных систем — это:

* анализ структуры данных и разреженности (в т.ч. long tail по user’ам и item’ам),
* изучение временных эффектов: дрейф интересов, сезонность, устаревание контента,
* понимание гетерогенности по сегментам пользователей,
* построение простых, но сильных бейзлайнов: популярностных, рейтинговых ($\mu + b_u + b_i$) и простых персонализированных.

После этого уже имеет смысл переходить к матричной факторизации, нейронным моделям и сложным loss-функциям — но всегда сравнивая их с этими базовыми, понятными и интерпретируемыми опорными точками.
