# Матричная факторизация

## 0) Зачем это нужно и где применяется
Матричная факторизация — один из самых сильных **классических бейзлайнов** для рекомендаций:

- **Персональные top‑K рекомендации**: ранжируем айтемы для каждого пользователя.
- **Item‑to‑Item рекомендации** ("похожие", "часто смотрят вместе") — ищем ближайшие айтемы в латентном пространстве.
- **Быстрый инференс**: после обучения скор считается через простую формулу (скалярное произведение) и хорошо сочетается с **ANN (Approximate Nearest Neighbors)** индексами.

Основная идея: вместо работы с огромной разреженной матрицей взаимодействий мы учим **низкоразмерные эмбеддинги** пользователей и айтемов, и далее считаем их близость.

---

## 1) Model‑based коллаборативная фильтрация: интуиция
В коллаборативной фильтрации есть 2 больших семейства:

- **Memory‑based**: kNN по пользователям/айтемам в исходном пространстве (косинус по строкам матрицы, и т.п.).
- **Model‑based**: строим модель латентных факторов.

**Matrix Factorization** — классический представитель **model‑based**: мы отображаем пользователей и айтемы в пространство размерности `k` (обычно `k ∈ [16, 512]`), где близость векторов соответствует вероятности интереса.

---

## 2) Данные: матрица взаимодействий и проблема пропусков
### 2.1 Матрица взаимодействий
Пусть:

- `m` — число пользователей, `n` — число айтемов.
- `R ∈ ℝ^{m×n}` — матрица взаимодействий.

В зависимости от задачи `R` может означать:

- **Explicit feedback**: `r_{ui}` — рейтинг (например 1…5).
- **Implicit feedback**: `r_{ui}` — “сила” взаимодействия (просмотры, клики, покупки), часто неотрицательная.

`R` почти всегда **разреженная**: наблюдений `|Ω|` намного меньше `m·n`, где

- `Ω = {(u,i): r_{ui} наблюдаем}` — множество известных (наблюдаемых) ячеек.

### 2.2 Missing Not At Random (MNAR)
Ключевая сложность: пропуски **не случайны**.

- Пользователь взаимодействует только с тем, что увидел (exposure bias).
- Популярные айтемы получают больше взаимодействий.
- Нишевые айтемы видит узкий сегмент.

Это называется **MNAR** (missing not at random). Если бы пропуски были **случайны (MCAR)**, задача матричного восстановления была бы существенно проще. В MNAR легко получить смещения:

- **popularity bias** (модель предпочитает популярное),
- **exposure bias** (модель учит “что показали”, а не “что нравится”),
- смещение по сегментам/категориям.

Важно помнить: разные типы feedback требуют разных постановок (explicit vs implicit), и смена сигнала часто означает смену функции потерь/обучения.

---

## 3) Базовая MF‑модель: эмбеддинги и скор
### 3.1 Эмбеддинги
Хотим найти:

- `P ∈ ℝ^{m×k}` — матрица эмбеддингов пользователей (строка `p_u ∈ ℝ^k`).
- `Q ∈ ℝ^{n×k}` — матрица эмбеддингов айтемов (строка `q_i ∈ ℝ^k`).

### 3.2 Скор (предсказание)
Самая базовая формула:

$$
\hat{r}_{ui} = p_u^\top q_i
$$

Вариант с байесами (смещение среднего):

$$
\hat{r}_{ui} = \mu + b_u + b_i + p_u^\top q_i,
$$

где:
- `μ` — глобальное среднее,
- `b_u` — персональный сдвиг пользователя (кто-то ставит “всё на 5”),
- `b_i` — сдвиг айтема (в среднем “всем нравится/не нравится”).

### 3.3 Геометрическая интерпретация (латентное пространство)
Если мы используем **dot product**:

$$
 a \cdot b = \|a\|\,\|b\|\cos\theta
$$

- `θ` — угол между векторами.
- Норма `||q_i||` часто коррелирует с **популярностью/количеством сигнала** → dot product может усиливать popularity bias.

Если используем **cosine similarity**:

$$
\mathrm{cos}(a,b)=\frac{a\cdot b}{\|a\|\,\|b\|}
$$

то мы смотрим на **направление**, меньше учитывая длину. На практике:
- для retrieval иногда нормализуют эмбеддинги и используют cosine;
- для рейтинговых задач часто остаются на dot product + регуляризация/дебайс.

---

## 4) SVD и Truncated SVD как путь к MF
> Важно: “чистый” SVD — это разложение **плотной** матрицы. В рекомендациях матрица разреженная, поэтому прямое применение часто означает выбор того, **как трактовать пропуски**.

### 4.1 Что такое SVD
Для матрицы `M ∈ ℝ^{m×n}` (плотной) существует разложение:

$$
M = U\,\Sigma\,V^\top,
$$

где:
- `U ∈ ℝ^{m×m}` — ортонормальные столбцы ($U^\top U = I$),
- `V ∈ ℝ^{n×n}` — ортонормальные столбцы ($V^\top V = I$),
- `Σ ∈ ℝ^{m×n}` — диагональная (в прямоугольном смысле) матрица сингулярных чисел `σ_1 ≥ σ_2 ≥ … ≥ 0`.

**Смысл**:
- `σ_j` измеряет “силу” j‑го латентного направления.
- столбцы `U` и `V` — левые/правые сингулярные векторы (базисы в пространствах пользователей и айтемов).

### 4.2 Truncated SVD (rank‑k приближение)
Берём только первые `k` компонент:

$$
M \approx U_k\,\Sigma_k\,V_k^\top,
$$

где:
- `U_k ∈ ℝ^{m×k}`,
- `Σ_k ∈ ℝ^{k×k}`,
- `V_k ∈ ℝ^{n×k}`.

Ключевой факт (Экарта–Юнга–Мирского): это **лучшее** rank‑`k` приближение `M` по норме Фробениуса:

$$
\|M - U_k\Sigma_kV_k^\top\|_F = \min_{\mathrm{rank}(X)\le k}\|M-X\|_F.
$$

### 4.3 Как это “становится” рекомендациями
Чтобы применить Truncated SVD к рекомендациям “в лоб”, часто делают так:

1) строят матрицу `M`,
2) **заполняют пропуски нулями** (или средним/байесами),
3) делают Truncated SVD,
4) восстанавливают предсказания $\hat{M}=U_k\Sigma_kV_k^\top$.

**Почему “шум” может быть полезен** (интуиция про картинки → рекомендации):
- В изображениях low‑rank приближение “сглаживает” детали и на малом `k` даёт артефакты/шум.
- В рекомендациях мы как раз хотим **обобщение**: модель обязана выставлять **ненулевые скоры** и для тех пар `(u,i)`, где взаимодействий не было.

То есть:
- “пустая” ячейка в данных означает **unknown**, а не обязательно “плохой айтем”.
- low‑rank приближение создаёт **оценки** для неизвестных ячеек → это и есть predicted relevance.

Но тут важный риск:
- если ты заполнил пропуски нулями, то ты молча сказал модели “не взаимодействовал = 0” (как будто негатив), что усиливает bias при MNAR.

### 4.4 Folding‑in (получение эмбеддингов новых пользователей/айтемов без переобучения)
Для Truncated SVD есть удобные формулы проекции.

Если $M \approx U_k\Sigma_kV_k^\top$, то:

$$
U_k\Sigma_k \approx M V_k
$$

и, следовательно,

$$
U_k \approx M V_k\Sigma_k^{-1}.
$$

Практический смысл:
- если `V_k,Σ_k` зафиксированы, можно быстро получить **вектор нового пользователя** по его строке `m_u` (взаимодействия с айтемами):

$$
\tilde{u}_u = m_u V_k\Sigma_k^{-1} \in \mathbb{R}^k.
$$

Аналогично для нового айтема по его столбцу.

Важно:
- это **не полноценное инкрементальное SVD**: мы не обновляем `V_k` (айтемное пространство), а лишь проектируем новое наблюдение в уже выученный базис.
- в проде это часто называют “fold‑in” и используют как быстрый cold‑start для новых сущностей.

---

## 5) Градиентные MF: FunkSVD (и почему он “правильнее” для разреженности)
SVD на плотной матрице неудобен: в рекомендациях мы чаще хотим оптимизировать **только наблюдаемые** значения.

### 5.1 FunkSVD (матричная факторизация через SGD)
Модель:

$$
\hat{r}_{ui} = p_u^\top q_i
$$

Оптимизация по observed‑ячейкам `Ω`:

$$
\min_{P,Q}\; \sum_{(u,i)\in \Omega} (r_{ui} - p_u^\top q_i)^2
+ \lambda\left(\sum_u\|p_u\|^2 + \sum_i\|q_i\|^2\right).
$$

- Регуляризация (`λ`) борется с переобучением.
- Обучение обычно SGD/mini‑batch.

**Ключевое отличие от “SVD с нулями”**:
- FunkSVD **не трактует пропуски как нули**, он просто игнорирует отсутствующие значения в лоссе.

### 5.2 Негативный фидбек и implicit данные
В implicit‑задачах наблюдаем в основном позитивы (клик/покупка), а “негативов” мало.

Тогда варианты:
- **Negative sampling**: сэмплируем не-взаимодействовавшие пары как “0/негатив” с маленьким весом.
- **Pairwise loss** (например BPR): учим относительные предпочтения `i ≻ j`.

(В этом конспекте фокус дальше на квадратичных постановках (ALS/iALS), но важно помнить, что для implicit часто pairwise работает лучше.)

---

## 6) Retrieval, item2item и ANN
После обучения MF у нас есть эмбеддинги.

### 6.1 Персональные рекомендации
Для пользователя `u` считаем скоры всем айтемам:

$$
\hat{r}_{u^*} = Q p_u \quad (если\ Q\ хранится\ как\ матрица\ n×k)
$$

и берём top‑K.

### 6.2 Item‑to‑Item
Для айтема `i` ищем ближайшие `q_j` по близости (dot/cosine). Это классический “похожие товары”.

### 6.3 Почему нужен ANN
Если `n` огромно, полный перебор `O(nk)` на запрос дорог.

ANN‑подход:
- строим индекс по `{q_i}`,
- на вход подаём `p_u` (персонализация) или `q_i` (item2item),
- получаем приближённый top‑K.

---

## 7) Кастомизации: bias, SVD++, timeSVD
### 7.1 Добавление bias (baseline)
С байесами модель чаще стабильнее:

$$
\hat{r}_{ui} = \mu + b_u + b_i + p_u^\top q_i.
$$

`\mu, b_u, b_i` можно:
- учить вместе с эмбеддингами (SGD),
- или оценить отдельно как baseline.

### 7.2 SVD++ (implicit сигнал как “история интересов”)
Идея: пользователь описывается не только параметром `p_u`, но и суммой векторов айтемов, с которыми он взаимодействовал.

Формула:

$$
\hat{r}_{ui} = \mu + b_u + b_i + q_i^\top \left(p_u + |R(u)|^{-\frac12}\sum_{j\in R(u)} y_j\right),
$$

где:
- `R(u)` — множество айтемов, с которыми пользователь взаимодействовал,
- `y_j` — “implicit item vector” (дополнительные параметры),
- нормировка `|R(u)|^{-1/2}` стабилизирует вклад при разной длине истории.

Интуиция:
- даже если пользователь редко ставит рейтинги (explicit), его **поведенческая история** несёт сигнал.

### 7.3 timeSVD / timeSVD++
Время влияет на предпочтения. Простая версия:
- старые взаимодействия учитываем слабее (time decay),
- или добавляем временные bias/дрейф эмбеддингов.

---

## 8) ALS для explicit feedback (масштабирование MF)
Когда данных много (миллионы пользователей/айтемов), SGD может быть неудобен. Тогда часто используют **ALS (Alternating Least Squares)**.

### 8.1 Постановка
Та же квадратичная цель:

$$
\min_{P,Q}\; \sum_{(u,i)\in \Omega} (r_{ui}-p_u^\top q_i)^2
+ \lambda\left(\sum_u\|p_u\|^2 + \sum_i\|q_i\|^2\right).
$$

### 8.2 Идея ALS
Чередуем оптимизацию:
- фиксируем `Q`, оптимизируем все `p_u`,
- фиксируем `P`, оптимизируем все `q_i`.

При фиксированном `Q` задача по каждому `p_u` — это **ridge regression**.

Обозначим:
- $I_u = {i: (u,i)\in\Omega}$ — айтемы, которые оценил пользователь.
- $Q_{I_u} ∈ ℝ^{|I_u|×k}$ — матрица соответствующих айтем‑векторов.
- $r_u ∈ ℝ^{|I_u|}$ — вектор рейтингов пользователя по этим айтемам.

Тогда:

$$
 p_u = \left(Q_{I_u}^\top Q_{I_u} + \lambda I\right)^{-1} Q_{I_u}^\top r_u.
$$

Аналогично для каждого айтема `i`.

### 8.3 Почему это удобно
- Решения по пользователям независимы → легко параллелить.
- На практике хорошо ложится на distributed вычисления (включая Spark‑экосистему).

Минус:
- оптимизируем только квадратичный лосс (MSE), что не всегда идеально для ranking/implicit.

---

## 9) iALS для implicit feedback (Hu–Koren–Volinsky)
В implicit данных мы хотим учиться не “предсказывать рейтинг”, а “предсказывать наличие/вероятность интереса”.

### 9.1 Переменные предпочтения и уверенности
Обычно вводят:

$$
 p_{ui} = \begin{cases}
 1, & r_{ui} > 0 \\
 0, & r_{ui} = 0
 \end{cases}
$$

и confidence:

$$
 c_{ui} = 1 + \alpha r_{ui}
$$

(иногда берут лог‑форму $c_{ui}=1+\alpha\log(1+r_{ui})$, чтобы не раздувать веса тяжелых пользователей).

- `p_{ui}` — “есть интерес/нет” (булево предпочтение),
- `c_{ui}` — “насколько уверены” (вес в лоссе): чем больше взаимодействий, тем больше вес.

### 9.2 Оптимизация iALS
Пусть эмбеддинги:
- `x_u ∈ ℝ^k` — пользователь,
- `y_i ∈ ℝ^k` — айтем.

Лосс:

$$
\min_{x_u,y_i}\; \sum_{u=1}^m\sum_{i=1}^n c_{ui}\,(p_{ui}-x_u^\top y_i)^2
+ \lambda\left(\sum_u\|x_u\|^2 + \sum_i\|y_i\|^2\right).
$$

Важно: сумма идёт по **всем** парам `(u,i)` — это кажется невозможным, но ниже будет трюк.

### 9.3 Нормальные уравнения (решение для одного пользователя)
Зафиксируем `Y` и найдём `x_u`.

Обозначим:
- `Y ∈ ℝ^{n×k}` — матрица айтем‑векторов (строки `y_i`).
- `p_u ∈ ℝ^n` — вектор предпочтений пользователя по всем айтемам.
- `C_u ∈ ℝ^{n×n}` — диагональная матрица confidence для пользователя `u` (на диагонали `c_{ui}`).

Тогда оптимум задаётся:

$$
 x_u = (Y^\top C_u Y + \lambda I)^{-1} Y^\top C_u p_u.
$$

Аналогично для `y_i` при фиксированном `X`.

### 9.4 Главный вычислительный хак
Наивно считать $Y^\top C_u Y$ дорого, потому что `C_u` размера `n×n`.

Трюк: `C_u = I + (C_u - I)`.

Тогда:

$$
Y^\top C_u Y = Y^\top Y + Y^\top (C_u - I) Y.
$$

Но `(C_u - I)` **разрежена по ненулевым взаимодействиям**, потому что:
- для большинства айтемов $r_{ui}=0 → c_{ui}=1 → (c_{ui}-1)=0$.

Следовательно:

$$
Y^\top (C_u - I) Y = \sum_{i\in I_u} (c_{ui}-1)\, y_i y_i^\top,
$$

а правая часть:

$$
Y^\top C_u p_u = \sum_{i\in I_u} c_{ui}\, y_i
$$

(потому что `p_{ui}=1` только для `i∈I_u`, иначе 0).

Итого формула для пользователя:

$$
 x_u = \Big( Y^\top Y + \sum_{i\in I_u} (c_{ui}-1) y_i y_i^\top + \lambda I \Big)^{-1}
 \Big( \sum_{i\in I_u} c_{ui} y_i \Big).
$$

Что хорошо:
- $Y^\top Y$ — это маленькая матрица `k×k`, одинаковая для всех пользователей → можно **предподсчитать**.
- Суммы идут только по `|I_u|` наблюдаемым взаимодействиям.

### 9.5 Инкрементальные обновления
Если пришли новые взаимодействия (добавились события для части пользователей), можно:
- **обновить только соответствующие `x_u`**, фиксируя `Y`.
- периодически (реже) делать полный цикл и обновлять `Y`.

Это полезно для прод‑контуров (near‑real‑time персонализация) — но важно помнить, что фиксированный `Y` со временем устаревает.

---

## 10) Плюсы и минусы (SVD / FunkSVD / ALS / iALS)
### 10.1 Общие плюсы MF
- Сильный бейзлайн “из коробки” в стабильных доменах.
- Очень быстрый скоринг (dot product) и отличный матч с ANN.
- Простая интерпретация: latent space.
- Можно быстро делать item2item.

### 10.2 Общие минусы MF
- Использует в основном только user×item сигнал (без контекста), плохо с cold‑start без доп. фич.
- MNAR/Exposure bias → легко получить смещения.
- Popularity bias (особенно с dot product).

### 10.3 SVD / Truncated SVD
**Плюсы**
- Очень сильная математика: лучшее rank‑k приближение по Фробениусу.
- Folding‑in: можно быстро получать эмбеддинги новых пользователей/айтемов в фиксированном базисе.

**Минусы**
- Требует выбора трактовки пропусков (часто “нули”), что опасно при MNAR.
- Инкрементальность ограничена: fold‑in не обновляет item‑пространство.

### 10.4 FunkSVD (SGD‑MF)
**Плюсы**
- Оптимизирует только observed‑ячейки.
- Легко добавлять bias, дополнительные регуляризации, менять лосс.

**Минусы**
- Для implicit нужно аккуратно генерировать негативы/выбирать лосс.
- Инкрементальное дообучение может “уехать” в сторону последних событий без контроля.

### 10.5 ALS (explicit)
**Плюсы**
- Отлично параллелится (по пользователям/айтемам), подходит для больших данных.
- Есть аналитическое решение для шага обновления.

**Минусы**
- По умолчанию MSE, не ранговая оптимизация.

### 10.6 iALS (implicit)
**Плюсы**
- Стандартный сильный метод для implicit.
- Учитывает уверенность (веса) и масштабируется через трюк `Y^T Y`.
- Довольно удобно делать частичные обновления пользователей.

**Минусы**
- Всё ещё без контекста.
- Настройка `α`, формы `c_{ui}` и регуляризации критична.

---

## 11) Мини‑примеры на Python
Ниже — минимальные учебные реализации (для понимания математики, не для продакшна).

### 11.1 Cosine vs dot product
```python
import numpy as np

A = np.array([2.0, 0.0, 0.0])
B = np.array([1.0, 1.0, 0.0])

# dot product
print('dot:', A @ B)

# cosine similarity
cos = (A @ B) / (np.linalg.norm(A) * np.linalg.norm(B) + 1e-12)
print('cos:', cos)
```

### 11.2 FunkSVD (SGD) по observed‑ячейкам
```python
import numpy as np

def train_funksvd(interactions, n_users, n_items, k=32, lr=0.05, reg=0.02, epochs=10, seed=42):
    """interactions: list of (u, i, r) только по наблюдаемым."""
    rng = np.random.default_rng(seed)
    P = 0.01 * rng.standard_normal((n_users, k))
    Q = 0.01 * rng.standard_normal((n_items, k))

    for _ in range(epochs):
        rng.shuffle(interactions)
        for u, i, r in interactions:
            pred = P[u] @ Q[i]
            err = r - pred
            # SGD update
            Pu = P[u].copy()
            P[u] += lr * (err * Q[i] - reg * P[u])
            Q[i] += lr * (err * Pu   - reg * Q[i])
    return P, Q

# пример
inter = [(0, 1, 5.0), (0, 3, 1.0), (1, 1, 4.0), (2, 0, 2.0)]
P, Q = train_funksvd(inter, n_users=3, n_items=5, k=8)
print('score u0->i2:', P[0] @ Q[2])
```

### 11.3 Один ALS‑шаг для explicit (обновление пользователей при фиксированных айтемах)
```python
import numpy as np

def als_update_users(user_items_ratings, Q, lam=0.1):
    """user_items_ratings[u] = (item_ids, ratings)
    Q: (n_items, k)
    returns P: (n_users, k)
    """
    n_users = len(user_items_ratings)
    k = Q.shape[1]
    P = np.zeros((n_users, k))
    I = np.eye(k)

    for u in range(n_users):
        item_ids, r = user_items_ratings[u]
        Qi = Q[item_ids]                 # (|I_u|, k)
        A = Qi.T @ Qi + lam * I          # (k, k)
        b = Qi.T @ r                     # (k,)
        P[u] = np.linalg.solve(A, b)
    return P
```

### 11.4 Один iALS‑шаг для implicit (обновление пользователей при фиксированных айтемах)
```python
import numpy as np

def ials_update_users(implicit_user_items, Y, alpha=40.0, lam=0.1):
    """implicit_user_items[u] = list of (item_id, r_ui) where r_ui>0
    Y: (n_items, k)
    returns X: (n_users, k)

    Uses trick:
      YtY = Y^T Y
      A_u = YtY + sum_{i in I_u} (c_ui - 1) y_i y_i^T + lam I
      b_u = sum_{i in I_u} c_ui y_i
    where c_ui = 1 + alpha * r_ui
    """
    n_users = len(implicit_user_items)
    k = Y.shape[1]
    X = np.zeros((n_users, k))
    I = np.eye(k)
    YtY = Y.T @ Y

    for u in range(n_users):
        A = YtY + lam * I
        b = np.zeros(k)

        for i, r_ui in implicit_user_items[u]:
            c = 1.0 + alpha * r_ui
            y = Y[i]
            A += (c - 1.0) * np.outer(y, y)
            b += c * y

        X[u] = np.linalg.solve(A, b)
    return X
```

---

## 12) Чеклист “что помнить”
- MF = эмбеддинги пользователей/айтемов + скор через dot product.
- MNAR → пропуски нельзя наивно считать нулями.
- Truncated SVD даёт лучшее rank‑k приближение (по Фробениусу), но в recsys важно, как трактуются пропуски.
- Folding‑in: новые пользователи/айтемы можно быстро проектировать в фиксированный базис.
- FunkSVD оптимизирует только observed‑ячейки; для implicit нужны негативы или pairwise loss.
- ALS масштабируется: шаги — ridge regression, параллелится.
- iALS вводит `p_{ui}` и `c_{ui}`, использует трюк с `Y^T Y` и суммированием только по наблюдаемым.
- Dot product склонен к popularity bias; cosine/нормализация помогает в retrieval.
- ANN индекс делает top‑K retrieval быстрым.