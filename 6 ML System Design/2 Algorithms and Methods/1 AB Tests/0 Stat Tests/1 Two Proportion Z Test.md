# Two‑proportion Z‑test (Z‑тест для двух долей)

> Коротко: сравнивает **две пропорции** (доли успехов) в независимых выборках — классический выбор для CR/CTR и других бинарных метрик в A/B‑тестах.

---

## 1. Постановка и интуиция
Пусть в двух независимых группах наблюдаем числа успехов $X_1, X_2$ при размерах $n_1, n_2$ и истинные вероятности события $p_1, p_2$.

- Оценки долей: $\hat p_1 = X_1/n_1$, $\hat p_2 = X_2/n_2$.
- Нас интересует разница $\Delta = p_2 - p_1$.

**Нулевая гипотеза $H_0$:** $p_1 = p_2$  (разницы нет).  
**Альтернатива ($H_1$):** двусторонняя $p_1 \ne p_2$ или односторонняя $p_2 > p_1$ / $p_2 < p_1$.

По центральной предельной теореме при достаточно больших $n_1, n_2$ распределение разности оценок долей близко к нормальному, что позволяет использовать Z‑статистику.

---

## 2. Статистика теста
### 2.1. "Пулинг" дисперсии под $H_0$ (рекомендуемый для проверки гипотезы)
При $H_0$ считаем общую (pooled) оценку доли:
$$\hat p = \frac{X_1 + X_2}{n_1 + n_2}$$
Тогда Z‑статистика:
$$ Z_{\text{набл}} = \frac{\hat p_2 - \hat p_1}{\sqrt{\hat p(1-\hat p)\left(\tfrac{1}{n_1} + \tfrac{1}{n_2}\right)}} $$
Сравниваем $|Z|$ с стандартным нормальным распределением, получаем $p$‑value ($p-value=P(|Z|\ge |Z_\text{набл}|)$, значения берем из таблицы стандартного нормального распределения $N(0,1)$ и умножаются на 2 - двусторонний тест).

### 2.2. Непулинг (Wald для CI разности)
Для **доверительных интервалов (CI) разности** часто используют непуленную оценку стандартной ошибки:
$$ \operatorname{SE}_{\text{wald}} = \sqrt{\frac{\hat p_1(1-\hat p_1)}{n_1} + \frac{\hat p_2(1-\hat p_2)}{n_2}} $$
и CI: 
$$
\ (\hat p_2-\hat p_1) \pm z_{1-\alpha/2}\, \operatorname{SE}_{\text{wald}}
$$ 
или $\text{истинная разница} \in \text{наблюдаемая разница} \pm (z_{1-\alpha/2} \times \text{SE}_\text{wald})$, где $z_{1-\alpha/2}$ — это "граница" нормального распределения для 95%.  

На практике вместо Wald‑CI лучше применять **Newcombe (Wilson)** — он стабильнее при крайних `долях/малых $n$.

#### **Wilson score interval (для одной доли)**
Wilson-интервал пытается исправить смещение простого Wald-интервала, который часто даёт нереалистичные границы (ниже 0, выше 1, или слишком узкие при малых n). Он делает это, не центрируясь на $\hat p$, а немного сдвигая центр и ширину интервала, в зависимости от $n$, $p$ и $z_{1−α/2}$.

$$
\hat p_W = \frac{\hat p + \frac{z^2}{2n}}{1 + \frac{z^2}{n}}
$$

$$
\text{SE}_W = \frac{z}{1 + \frac{z^2}{n}} \sqrt{\frac{\hat p(1 - \hat p)}{n} + \frac{z^2}{4n^2}}
$$

Тогда доверительный интервал:
$$
\text{CI}_{Wilson} = \hat p_W \pm \text{SE}_W
$$

где $z = z_{1−α/2}$ (например, 1.96 для 95%).

#### **Newcombe interval (для разности двух долей)**
Теперь у нас есть две независимые доли:
$$
\hat p_1 = X_1/n_1, \quad \hat p_2 = X_2/n_2
$$

Строим **отдельные Wilson-интервалы** для каждой:
$$
[L_1, U_1], \quad [L_2, U_2]
$$

Комбинируем их в **интервал для разности** $(p_2 - p_1)$:

$$
\text{CI}_{Newcombe} = [L_2 - U_1; U_2 - L_1]
$$

То есть берём все возможные комбинации крайних границ,
которые гарантированно "накрывают" истинную разницу между долями.

---

## 3. Предпосылки и когда использовать
**Когда подходит:**
- Бинарные метрики на единицу анализа: **CR** (конверсия), **CTR** (кликнул/нет), **активация**, **оплата** и т.п.
- Единица анализа совпадает с единицей рандомизации (обычно пользователь).
- Независимые наблюдения между группами.
- Достаточно большие выборки, чтобы аппроксимация нормальностью была уместна (часто проверяют, чтобы в каждой группе ожидаемые числа успехов/неуспехов были ≥ 5; практические правила варьируют).

**Когда НЕ подходит без оговорок:**
- Очень малые выборки/редкие события → **точный тест Фишера** или точный биномиальный.
- Нарушение независимости (кластеризация): нужен учёт дизайна (кластер‑робастные ошибки, дизайн‑эффект и т.п.).
- Единица анализа не равна единице рандомизации (псевдорепликация): поправьте агрегацию/дизайн.

---

## 4. Что именно тестируем и как интерпретировать
- Гипотеза $H_0$ про **равенство истинных долей** $p_1$ и $p_2$.
- Малый $p$‑value (меньше $\alpha$, например 0.05) ⇒ данные **плохо согласуются** с $H_0$ ⇒ отвергаем $H_0$.
- Всегда необходмо:
  - сообщать **размер эффекта**:
    - абсолютная разница в п.п.: $\hat p_2-\hat p_1$;
    - относительный эффект: $\frac{\hat p_2-\hat p_1}{\hat p_1}$;
    - стандартизованный эффект **Cohen’s h**: $\;h = 2\,\big(\arcsin \sqrt{\hat p_2} - \arcsin \sqrt{\hat p_1}\big)$
  - давать  **доверительные интервалы** (лучше Newcombe/Wilson) — они устойчивее, чем Wald‑CI.

---

## 5. Почему это стандарт для A/B
- Прост и интерпретируем;
- Работает для ключевых бинарных метрик (CR/CTR), наиболее распространённых в продакт‑экспериментах;
- Совместим с планированием мощности и MDE (через Cohen’s $h$ и нормальную аппроксимацию);
- Легко расширяется на A/B/n (попарные сравнения + корректировка множественности) и A/A (валидация пайплайна).

---

## 6. Выбор одно‑ или двустороннего теста
- **Двусторонний** по умолчанию, если важны любые отличия (лучше/хуже).  
- **Односторонний** — только если **заранее** допустим интерес «только на улучшение» и решение при ухудшении не меняется (фиксируйте до запуска).

---

## 7. Доверительные интервалы для долей и разности
- На уровне **каждой доли**: Wilson/Agresti–Coull лучше классического Wald.  
- Для **разности долей**: Newcombe (на основе двух Wilson CI) — один из лучших практических вариантов.

---

## 8. Планирование мощности (power) и MDE
Для долей используют стандартизованный эффект **Cohen’s $h$**:
$$ h = 2\,\big(\arcsin \sqrt{p_2} - \arcsin \sqrt{p_1}\big). $$
Далее применяют нормальный анализ мощности (например, `statsmodels.NormalIndPower`) для расчёта требуемого $n$ при заданных $\alpha$, мощности и MDE.

---

## 9. Пример
```python
import numpy as np
import statsmodels.api as sm

# Данные A/B: успехи (конверсии) и размеры групп
x1, n1 = 120, 2000  # A: 120 конверсий из 2000
x2, n2 = 150, 2000  # B: 150 конверсий из 2000

p1_hat = x1 / n1
p2_hat = x2 / n2

# 1) Z-тест (двусторонний), pooled под H0
stat, pval = sm.stats.proportions_ztest(count=[x2, x1], nobs=[n2, n1], alternative='two-sided')
print(f"Z = {stat:.3f}, p-value = {pval:.4f}")

# 2) CI для каждой доли (Wilson)
ci1 = sm.stats.proportion_confint(count=x1, nobs=n1, alpha=0.05, method='wilson')
ci2 = sm.stats.proportion_confint(count=x2, nobs=n2, alpha=0.05, method='wilson')
print(f"p1_hat = {p1_hat:.4f}, Wilson CI: [{ci1[0]:.4f}, {ci1[1]:.4f}]")
print(f"p2_hat = {p2_hat:.4f}, Wilson CI: [{ci2[0]:.4f}, {ci2[1]:.4f}]")

# 3) Разница и относительный эффект
diff_abs = p2_hat - p1_hat
rel = diff_abs / p1_hat
print(f"Absolute diff = {diff_abs:.4f} (pp), Relative lift = {rel*100:.2f}%")

# 4) Эффект-сайз Cohen's h и расчёт требуемого n на группу при заданном MDE
h = sm.stats.proportion_effectsize(p1_hat, p2_hat)  # оценка h по наблюдаемым
print(f"Cohen's h = {h:.4f}")

power_analysis = sm.stats.NormalIndPower()
# Пример: хотим power=0.8, alpha=0.05, симметричные группы (ratio=1)
# Пусть целевой MDE: p2 = p1 * (1 + 0.05)
from math import ceil
p1_baseline = p1_hat
p2_target = p1_baseline * 1.05
h_target = sm.stats.proportion_effectsize(p1_baseline, p2_target)

n_per_group = power_analysis.solve_power(effect_size=h_target, alpha=0.05, power=0.80, ratio=1.0, alternative='two-sided')
print(f"Required n per group for +5% relative lift: ~{ceil(n_per_group)}")
```

Возможный output:
```
Z = 1.891, p-value = 0.0587
p1_hat = 0.0600, Wilson CI: [0.0504, 0.0713]
p2_hat = 0.0750, Wilson CI: [0.0643, 0.0874]
Absolute diff = 0.0150 (pp), Relative lift = 25.00%
Cohen's h = -0.0599
Required n per group for +5% relative lift: ~100657
```