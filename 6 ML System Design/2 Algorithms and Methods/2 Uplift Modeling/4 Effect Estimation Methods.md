# Методы оценки эффекта

## 1. Постановка задачи

### 1.1. Исходная проблема

В наблюдаемых данных воздействие $W\in{0,1}$ **не назначается случайно**:

* маркетинг показывает оффер более «перспективным» клиентам;
* банк предлагает продукт только низкорисковым;
* таргетинг рекламы выбирает тех, кто с большей вероятностью кликнет.

В результате:

* распределения ковариат $X$ в группах $W=1$ и $W=0$ **разные**;
* простое сравнение средних $\mathbb E[Y\mid W=1] - \mathbb E[Y\mid W=0]$ **смещено** (confounding).

Наша цель:

* оценить причинный эффект:

  * **ATE** (Average Treatment Effect): средний эффект по всей популяции;
  * **ATT** (Average Treatment effect on the Treated): эффект для реально обработанных;
  * при uplift‑моделировании – ещё и **CATE/uplift** на уровне единицы.

---

### 1.2. Ключевые допущения

Все стандартные методы на основе propensity/matching/IPTW опираются на:

1. **Ignorability / Unconfoundedness**
   Условно на X нет скрытого конфоундера:

   $$
   (Y(0), Y(1)) \perp W \mid X.
   $$

2. **Positivity (overlap)**
   У любого объекта с признаками $X=x$ есть ненулевая вероятность попасть и в treatment, и в control:

   $$
   0 < P(W=1\mid X=x) < 1.
   $$

3. **SUTVA** (отсутствие интерференции и единичность варианта воздействия):

   * эффект на единицу не зависит от назначений другим;
   * нет «разных версий» одного и того же W.

**Задача propensity/matching/IPTW:** сконструировать «псевдо‑RCT»:

* сбалансировать распределения $X$ в группах $W=0$ и $W=1$;
* после балансировки любое различие в $Y$ можно интерпретировать как причинный эффект.

---

## 2. Propensity Score

### 2.1. Определение

**Propensity score** $e(X)$ – это условная вероятность попадения объекта в treatment при заданных ковариатах:

$$
e(X) = P(W=1 \mid X).
$$

Классическое свойство (Теорема Розенбаума–Рубина):

* если выполняется ignorability относительно полного набора X,
  $$
  (Y(0), Y(1)) \perp W \mid X.
  $$
* то она выполняется и относительно propensity score:
  $$
  (Y(0), Y(1)) \perp W \mid e(X).
  $$

Иначе говоря, **при условии одинакового propensity score treatment и control «как бы» рандомизированы**.

> **Смысл**: чтобы устранить смещение из-за разных распределений признаков между treatment и control, **не нужно уравнивать все признаки $X$** — достаточно уравнять (сбалансировать) их **по одной скалярной функции**.

**Почему это важно**  
В реальных данных treatment и control группы часто различаются по $X$. Например, более активные пользователи чаще получают рекламу. Чтобы корректно сравнить группы, нужно, чтобы их распределения по признакам были одинаковыми.  

Но $X$ может быть многомерным — уравнять всё напрямую сложно. Теорема говорит: можно "сжать" всю информацию о вероятности попасть в treatment в одно число $e(X)$, и если treatment и control **имеют одинаковое распределение propensity score**, то они сбалансированы и по исходным признакам $X$.

Это позволяет:

* делать **matching** по e$X$;
* строить **страты** по e$X$ и сравнивать внутри них исходы;
* строить **веса IPTW**, зависящие от e$X$.

---

### 2.2. Интуиция

* Если у клиента $e(X) \approx 0.9$, бизнес почти всегда дал бы ему treatment. Клиенты с такими X в контроле – редкий и ценный «контрафактический» материал.
* Если $e(X) \approx 0.5$, то клиенты почти случайно попадают в обе группы → это наиболее информативная зона для оценки эффекта.
* Если $e(X) \approx 0.01$ или $0.99$, то у нас **почти нет информации** о контрафактическом исходе → оценки эффекта там будут с огромной дисперсией и чувствительны к спецификации моделей.

---

### 2.3. Методы оценки propensity score

### 2.3.0. Общее описание

Propensity score $e(X) = \Pr(W=1 \mid X)$ — это просто **модель вероятности попасть в treatment-группу**. Её можно обучить с помощью любого классификатора, где:
- признаки = ковариаты $X$,
- таргет = $W$ (1 — получил воздействие, 0 — нет).

Задача модели — **не предсказывать точно, кто получит воздействие**, а **обеспечить одинаковое распределение признаков** между treatment и control при стратификации по $e(X)$.

Поэтому высокая точность (ROC-AUC → 0.9+) может быть даже вредна: модель слишком "уверена", группы почти не пересекаются → нарушается условие перекрытия (для некоторых типов людей нет аналогов в другой группе).  

Лучше, если $e(X)$ распределён **плавно**, и treatment/control пересекаются.

После обучения модель часто **калибруют**, чтобы прогнозы отражали реальные вероятности.

Калибровка важна, потому что даже небольшие искажения в вероятностях дают сильные ошибки при вычислении весов (например, в IPW).

#### 2.3.1. Логистическая регрессия

Базовый подход: модель

$$
e(X) = \beta_0 + \beta^T X,
$$

с оценкой через максимальное правдоподобие.

Плюсы:

* интерпретируемая; можно явно задать нелинейности/интеракции;
* легко диагностировать калибровку и экстремальные значения;
* часто достаточно для хорошего баланса.

Минусы:

* требует явного задания взаимодействий и нелинейностей;
* в сложных задачах может плохо описывать true $e(X)$.

#### 2.3.2. ML‑модели

Можно использовать любой бинарный классификатор:

* градиентный бустинг;
* random forest;
* нейросеть;
* ансамбли.

Важно:

* **не** гнаться за ROC‑AUC как самоцель;
* следить за **калибровкой** вероятностей и **overlap**;
* избегать перегиба, когда модель «зажимает» $e(X)$ близко к 0/1 и создаёт экстремальные веса.

**Практика:**

* часто логит с разумным набором фич + интеракции/сплайны даёт хороший баланс;
* ML имеет смысл, если высокая размерность и сильная нелинейность, но тогда критична диагностика баланса.

---

### 2.4. Диагностика propensity модели

После оценки $\hat e(X)$ важно проверить:

1. **Overlap:** распределения $\hat e(X)$ в группах $W=0$ и $W=1$ должны перекрываться. Если есть хвосты, где почти только одна группа → в этой зоне надежно оценить эффект нельзя.

2. **Баланс ковариат после применения метода** (matching/страты/веса):

   * **Standardized Mean Difference (SMD)** по каждой фиче до/после корректировки;
   * графики (Love‑plot);
   * сравнение гистограмм/ECDF для ключевых признаков.

**Главное:** качественная propensity‑модель – это не та, у которой AUC=0.9, а та, которая приводит к **хорошему балансу ковариат** после применённого метода.

---

### 2.5. Численный пример

Пусть есть 4 клиента, один ковариат X – риск‑скор (чем выше, тем выше шанс treatment):

| id | X (риск) | W (treat) | Y |
| -- | -------- | --------- | - |
| 1  | 0.1      | 0         | 0 |
| 2  | 0.2      | 0         | 0 |
| 3  | 0.8      | 1         | 1 |
| 4  | 0.9      | 1         | 1 |

Наивная оценка эффекта:

$$
\hat{ATE}_{naive} = (1+1)/2 - (0+0)/2 = 1.
$$

Но очевидно, что group W=1 состоит из более «жирных» клиентов по X, у которых и без treatment конверсия выше.

Если мы оценим $e(X)$ логитом (условно):

* $\hat e(X=0.1) \approx 0.1$
* $\hat e(X=0.2) \approx 0.2$
* $\hat e(X=0.8) \approx 0.8$
* $\hat e(X=0.9) \approx 0.9$

То можем делать matching/стратификацию/IPTW таким образом, чтобы сравнивать «похожих» по X клиентов.

---

### 2.6. Пример

```python
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score

# игрушечные данные
np.random.seed(0)
n = 5000
X = np.random.normal(size=(n, 2))
# истинная propensitу (логит):
# logit e(x) = 0.5 * x1 - 0.8 * x2
logit_e = 0.5 * X[:, 0] - 0.8 * X[:, 1]
true_e = 1 / (1 + np.exp(-logit_e))
W = np.random.binomial(1, true_e)

# оцениваем логистической регрессией
logit = LogisticRegression()
logit.fit(X, W)
ps_hat = logit.predict_proba(X)[:, 1]

print("ROC-AUC по W:", roc_auc_score(W, ps_hat))

# кладем в DataFrame
df = pd.DataFrame({"x1": X[:, 0], "x2": X[:, 1], "W": W, "ps_hat": ps_hat})

# смотрим overlap по propensity
print(df.groupby("W")["ps_hat"].describe())
```

Дальше `ps_hat` используются для matching, стратификации или построения весов.

---

## 3. Matching (сопоставление)

### 3.1. Идея

Найти и сравнить **похожие наблюдения** из treatment $(W=1)$ и control $(W=0)$ групп.

* Для каждого объекта из одной группы подбираются «близкие» по признакам аналоги из другой группы.
* Считаем разницу исходов внутри пар/кластеров и усредняем.
* Так получаем оценку ATE/ATT на сбалансированной подвыборке.

Для корректной работы матчинга нужно выбрать метрику похожести.

---

### 3.2. Метрики «похожести»

1. **Euclidean / по выбранным признакам**
   Используем обычное расстояние по ключевым ковариатам (возраст, доход, риск и т.п.). Работает, если:

   * признаков немного;
   * они приведены к сопоставимому масштабу.

2. **Mahalanobis distance**
   Учитывает ковариационную структуру признаков, т.е. корреляции и масштабы. Для вектора $x$:

   $$
   d_M(x_i, x_j) = \sqrt{(x_i - x_j)^T \Sigma^{-1} (x_i - x_j)},
   $$

   где $\Sigma$ – ковариационная матрица X.

3. **Propensity score matching**
   Считаем расстояние по $\hat e(X)$:

   $$
   d(i,j) = |\hat e(X_i) - \hat e(X_j)|.
   $$

   Плюсы:

   * резко снижает размерность задачи (из $\dim X$ в 1);
   * при хорошо построенном $e(X)$ автоматически учитывает не только линейные, но и сложные зависимости.

На практике часто делают **propensity score matching** как первый шаг, потом докручивают баланс регрессией/стратификацией.

---

### 3.3. Caliper (радиус подбора)

Чтобы избежать «плохих» пар (слишком разные объекты), задают максимум дистанции (caliper) между treatment и control:

* при matching по $e(X)$ часто берут $\text{caliper} = 0.1–0.2 * SD(e(X))$;
* если для объекта нет подходящего соседа внутри caliper, его исключают.

Эффект:

* повышается качество сопоставления и баланс;
* снижается размер эффективной выборки.

---

### 3.4. Соотношение пар и replacement

* **1:1 matching** – каждому объекту из treatment подбирается ровно один из control.
* **1:k matching** – одному объекту из treatment подбирают k из control (повышает стабильность оценки за счёт большего числа наблюдений).

**Replacement:**

* **с возвратом** – один и тот же контроль может использоваться для нескольких treated;
* **без возврата** – каждый контроль используется максимум один раз.

С возвратом увеличивает эффективный размер контрольной группы, но может «перегрузить» отдельные наблюдения.

---

### 3.5. Типы оценок: ATE vs ATT

После matching можно построить:

* **ATT (Average Treatment effect on the Treated):** сопоставляем каждый treated с похожими контролями и усредняем:

  $$
  \widehat{ATT} = \frac{1}{n_T} \sum_{i:W_i=1} \left( Y_i - \sum_{j\in\mathcal{M}(i)} w_{ij} Y_j \right),
  $$

  где $\mathcal{M}(i)$ – множество matched контролей, $w_{ij}$ – веса.

* **ATE:** существует несколько схем, например:

  * делать matching и для treated, и для control симметрично;
  * использовать взвешенные комбинации ATT и ATC.

На практике matching чаще используют для оценки **ATT**, т.к. нас обычно интересует эффект для реально таргетируемых.

---

### 3.6. Диагностика matching

После построения пар/кластеров нужно:

* проверить **SMD** по всем ковариатам до и после matching;
* убедиться в сохранении overlap (нет полного отсечения целых сегментов);
* посчитать **effective sample size** (с учётом повторного использования контролей).

Если баланс плохой → нужно менять:

* спецификацию $e(X)$;
* метод distance;
* caliper;
* стратегию 1:1 vs 1:k, with/without replacement.

---

### 3.7. Matching по propensity (идея)

1. Оценили $\hat e(X)$ логитом.
2. Для каждого treated нашли ближайший control по |ps_treated − ps_control| с caliper=0.1.
3. Считали ATT как среднюю разность исходов в парах.

Кодовый скелет:

```python
from sklearn.neighbors import NearestNeighbors

# df: колонки X1, X2, W, Y, ps_hat

# берём только контрольных
control = df[df["W"] == 0].copy()
treated = df[df["W"] == 1].copy()

nn = NearestNeighbors(n_neighbors=1)
nn.fit(control[["ps_hat"]])

# находим соседа для каждого treated
distances, indices = nn.kneighbors(treated[["ps_hat"]])

caliper = 0.1
mask = distances.flatten() <= caliper

matched_treated = treated[mask].copy()
matched_control = control.iloc[indices.flatten()[mask]].copy()

att = (matched_treated["Y"].values - matched_control["Y"].values).mean()
print("ATT (matching):", att)
```

В реальных задачах используют более развитые пакеты (MatchIt, etc.), но идея та же.

---

## 4. Stratification / Subclassification по propensity

### 4.1. Идея

Вместо подбора индивидуальных пар можно:

1. Отсортировать наблюдения по $\hat e(X)$.
2. Разбить на несколько **подклассов (страты)**, например, квинтилями propensity.
3. Внутри каждой страты сравнить средний исход между $W=1$ и $W=0$.
4. Усреднить эффект по стратам с весами по размеру.

Это «грубая» версия matching, которая проще и устойчивее, но менее точна по отдельным объектам.

---

### 4.2. Формулы

Пусть всего K страт, в каждой страте k:

* $n_k$ – размер страты,
* $n_{1k}$, $n_{0k}$ – размеры treatment/control внутри страты,
* $\bar Y_{1k}$, $\bar Y_{0k}$ – средние исходы.

Тогда оценка ATE через стратификацию:

$$
\widehat{ATE}*{strat} = \sum*{k=1}^K \frac{n_k}{n} \big( \bar Y_{1k} - \bar Y_{0k} \big).
$$

Для ATT можно использовать веса только по treated внутри страт.

---

### 4.3. Практика

* K = 5 (квинтили) – обычно достаточно;
* в каждой страте должен быть **и treatment, и control**;
* по каждой страте можно отдельно проверять баланс ковариат;
* стратификация часто используется как диагностика и baseline к более сложным методам.

---

## 5. IPTW (взвешивание обратными вероятностями)

### 5.1. Идея

Сделать так, чтобы treatment $(W=1)$ и control $(W=0)$ группы имели **одинаковое распределение признаков X**, как будто воздействие назначалось случайно.

Каждому наблюдению назначается вес, обратный вероятности попасть в свою группу:

* если $W_i = 1$, вес $w_i = 1 / \hat e(X_i)$;
* если $W_i = 0$, вес $w_i = 1 / (1 - \hat e(X_i))$.

Интуиция:

* чуть «преувеличиваем» редких в своей группе клиентов;
* и «уменьшаем» тех, для кого такая группа вполне ожидаема.

После взвешивания получаем «виртуальную популяцию», где X распределены одинаково при W=0 и W=1.

---

### 5.2. Оценка ATE через IPTW

Стандартная оценка:

$$
\widehat{ATE}*{IPTW}  = \frac{1}{n} \sum*{i=1}^n \left( \frac{W_i Y_i}{\hat e(X_i)} - \frac{(1-W_i) Y_i}{1-\hat e(X_i)} \right).
$$

Это разность средних исходов в двух «взвешенных» популяциях:

* $Y$ среди $W=1$ с весами $1/\hat e(X)$;
* $Y$ среди $W=0$ с весами $1/(1-\hat e(X))$.

---

### 5.3. Варианты весов: ATE, ATT, ATC, overlap

1. **ATE‑веса**:

   $$
   w_i^{ATE} = \frac{W_i}{\hat e(X_i)} + \frac{1-W_i}{1-\hat e(X_i)}.
   $$

2. **ATT‑веса (фокус на treated)**:

   * для treated: $w_i = 1$;
   * для control: $w_i = \hat e(X_i)/(1-\hat e(X_i))$.

   Тогда мы строим популяцию, которая по X похожа на treated.

3. **ATC‑веса (фокус на control)** – симметрично, но ориентируемся на контрольную популяцию.

4. **Overlap‑веса**:

   $$
   w_i^{overlap} = W_i (1-\hat e(X_i)) + (1-W_i) \hat e(X_i).
   $$

   Такие веса подчёркивают область $\hat e(X)\approx 0.5$, где есть наибольший overlap и наименьшая модельная зависимость.

---

### 5.4. Проблема больших весов и решения

Если $\hat e(X_i)$ близко к 0 или 1, веса $1/\hat e(X_i)$ или $1/(1-\hat e(X_i))$ становятся огромными → оценка очень шумная.

Стандартные приёмы:

1. **Стабилизация весов**
   Домножаем на маргинальную вероятность treatment:

   $$
   w_i^{stab} = \frac{W_i P(W=1)}{\hat e(X_i)} + \frac{(1-W_i) P(W=0)}{1-\hat e(X_i)}.
   $$

2. **Trimming / обрезка**
   Ограничиваем propensity в диапазоне $[a, 1-a]$, например, $a = 0.05$:

   $$
   \tilde e(X_i) = \min(\max(\hat e(X_i), a), 1-a).
   $$

3. **Исключение наблюдений с экстремальным $e(X)$**
   Отрезаем хвосты, где $\hat e(X) < a$ или $> 1-a$. Это меняет целевую популяцию («trimming estimand»), но делает оценку стабильнее.

Практический компромисс: небольшой trimming + стабилизированные веса.

---

### 5.5. Пример: IPTW

```python
import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression

np.random.seed(1)

n = 5000
X = np.random.normal(size=(n, 2))
logit_e = 0.5 * X[:, 0] - 0.5 * X[:, 1]
true_e = 1 / (1 + np.exp(-logit_e))
W = np.random.binomial(1, true_e)

# задаём истинный эффект tau(x) = 0.5 (для примера)
# базовый исход
mu0 = 0.2 + 0.1 * X[:, 0]
Y0 = np.random.binomial(1, 1 / (1 + np.exp(-mu0)))
Y1 = np.random.binomial(1, 1 / (1 + np.exp(-(mu0 + 0.5))))
Y = np.where(W == 1, Y1, Y0)

# наивная оценка ATE
ate_naive = Y[W == 1].mean() - Y[W == 0].mean()
print("Naive ATE:", ate_naive)

# оцениваем propensity логитом
logit = LogisticRegression()
logit.fit(X, W)
ps_hat = logit.predict_proba(X)[:, 1]

# IPTW-оценка ATE
w_treat = W / ps_hat
w_control = (1 - W) / (1 - ps_hat)

ate_iptw = (w_treat * Y).sum() / w_treat.sum() - (w_control * Y).sum() / w_control.sum()
print("IPTW ATE:", ate_iptw)
```

В симуляции можно проверить, что $\widehat{ATE}_{IPTW}$ ближе к истинному эффекту, чем наивная разность средних.

---

## 6. Doubly Robust / AIPW

### 6.1. Идея

Соединить:

1. **модель исхода** $m_w(x) = \mathbb{E}[Y \mid X=x, W=w]$;
2. **пропенсити‑модель** $e(x) = P(W=1\mid X=x)$,

так, чтобы при корректности **хотя бы одной** из них оценка ATE была состоятельной.

Это и есть **двойная робастность**.

---

### 6.2. AIPW / DR‑оценка ATE

Одна из стандартных формул:

$$
\widehat{ATE}*{DR} = \frac{1}{n} \sum*{i=1}^n \Bigg[ \big(\hat m_1(X_i) - \hat m_0(X_i)\big)

* \frac{W_i}{\hat e(X_i)} (Y_i - \hat m_1(X_i))

- \frac{1-W_i}{1-\hat e(X_i)} (Y_i - \hat m_0(X_i)) \Bigg].
$$

Интерпретация:

* первая часть $\hat m_1(X_i) - \hat m_0(X_i)$ – «регрессионная» оценка эффекта (outcome regression);
* вторая и третья – **IPTW‑коррекция остатков**, которая устраняет смещение, если верен $e(X)$.

Свойства:

* если хотя бы одна из моделей (исхода или пропенсити) корректно специфицирована, DR‑оценка ATE состоятельна;
* при корректности обеих моделей – достигается асимптотическая эффективность.

---

### 6.3. Связка с CATE/uplift и Double ML

AIPW – базовый кирпич:

* **R‑, DR‑, X‑learners** используют AIPW‑подобные псевдо‑таргеты для обучения CATE-моделей;
* **Double Machine Learning** строит ортогональные условия момента, в которых:

  * сначала ML‑моделями оцениваются $m_w(x), e(x)$ на cross‑fitting;
  * затем параметр интереса (ATE, эффект тарифа и т.п.) оценивается регрессией по псевдо‑таргету с хорошими статистическими свойствами.

Здесь важно понимать AIPW как «универсальный корректор смещения», на котором строится весь современный арсенал Causal ML.

---

## 7. Практический пайплайн для наблюдательных данных

1. **Определить W, Y, X и целевой estimand** (ATE или ATT).
2. **Построить propensity‑модель**:

   * выбрать ковариаты, влияющие и на W, и на Y;
   * оценить $\hat e(X)$ логитом или ML;
   * проверить overlap.
3. **Выбрать метод корректировки**:

   * Matching (по $e(X)$ или Mahalanobis): хороший baseline для ATT;
   * IPTW (ATE/ATT/overlap): удобен при последующей регрессии/uplift‑моделировании;
   * Stratification: простой и понятный способ сверки результата.
4. **Проверить баланс ковариат** после корректировки:

   * SMD по ключевым признакам;
   * визулизации распределений.
5. **При необходимости – использовать DR‑подход**:

   * строим $\hat m_w(X)$ и $\hat e(X)$;
   * считаем AIPW‑оценку ATE;
   * на базе псевдо‑таргетов обучаем CATE/uplift‑модель.
6. **Сделать чувствительный анализ**:

   * разные спецификации $e(X)$;
   * разные caliper/стратификации/параметры trimming;
   * оценка устойчивости эффекта.
