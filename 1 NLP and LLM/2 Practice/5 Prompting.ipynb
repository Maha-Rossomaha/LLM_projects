{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30148449",
   "metadata": {},
   "source": [
    "### Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cd9457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6119d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from together import Together\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373aa291",
   "metadata": {},
   "source": [
    "### Prompting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196ca4b4",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77edb236",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b0571",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "test_dataset = []\n",
    "for i in range(1, 31):\n",
    "    train_dataset.append(imdb[\"train\"][i])\n",
    "    train_dataset.append(imdb[\"train\"][-i])\n",
    "    test_dataset.append(imdb[\"test\"][i])\n",
    "    test_dataset.append(imdb[\"test\"][-i])\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(train_dataset)\n",
    "random.shuffle(test_dataset)\n",
    "\n",
    "print(sum(sample[\"label\"] for sample in train_dataset), \"положительных примеров в train датасете\")\n",
    "print(sum(sample[\"label\"] for sample in test_dataset), \"положительных примеров в test датасете\")\n",
    "\n",
    "true_labels = [sample[\"label\"] for sample in test_dataset]\n",
    "pred_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31159984",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv(\"TOGETHER_API_KEY\")\n",
    "client = Together(api_key=API_KEY)\n",
    "model_8b = \"databricks/dbrx-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c9c37e",
   "metadata": {},
   "source": [
    "#### Zero-Shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fec031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "true_labels = [sample[\"label\"] for sample in test_dataset]\n",
    "accuracy = []\n",
    "\n",
    "for sample in tqdm(test_dataset):\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies movies reviews. Please, read the review and answer with symbol - 1, if user liked the movie, or with symbol 0, if he did not. Do not answer in text, answer in one of the following two options: 1, 0\"}]\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Do not answer in text and classify this review in one word with one of following options - 0 or 1: {sample['text'].replace('<br />', '')}\"})\n",
    "    response = client.chat.completions.create(messages=messages, model=model_8b, timeout=10, max_tokens=20, temperature=0.4)\n",
    "    if '1' in response.choices[0].message.content.lower():\n",
    "        pred_label = 1\n",
    "    elif '0' in response.choices[0].message.content.lower():\n",
    "        pred_label = 0\n",
    "    else:\n",
    "        raise Exception(f'Нет решения по отзыву:\\n\\t{sample[\"text\"]}\\nМодель сказала:\\n\\t{response.choices[0].message.content.lower()}')\n",
    "    accuracy.append(int(pred_label == sample['label']))\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d03c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(accuracy) / len(accuracy))\n",
    "# Грамотная пост-обработка позволила бы значительно повысить метрику"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc39905",
   "metadata": {},
   "source": [
    "#### ReAsking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aac9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [sample[\"label\"] for sample in test_dataset]\n",
    "accuracy = []\n",
    "\n",
    "for sample in tqdm(test_dataset):\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies movies reviews. Please, read the review and answer with symbol - 1, if user liked the movie, or with symbol 0, if he did not. Do not answer in text, answer in one of the following two options: 1, 0\"}]\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Do not answer in text and classify this review in one word with one of following options - 0 or 1: {sample['text'].replace('<br />', '')}\"})\n",
    "    response = client.chat.completions.create(messages=messages, model=model_8b, timeout=10, max_tokens=20, temperature=0.2)\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response.choices[0].message.content.strip().lower()})\n",
    "    messages.append({\"role\": \"user\", \"content\": \"Are you sure that your answer is fully correct? Please think and classify the review again with one of following options - 0 or 1.\"})\n",
    "    response_new = client.chat.completions.create(messages=messages, model=model_8b, timeout=10, max_tokens=512)\n",
    "    if '1' in response_new.choices[0].message.content.lower():\n",
    "        pred_label = 1\n",
    "    elif '0' in response_new.choices[0].message.content.lower():\n",
    "        pred_label = 0\n",
    "    else:\n",
    "        print(f'No answer in new generation: \\n\\t{response_new.choices[0].message.content.lower()}')\n",
    "        if '1' in response.choices[0].message.content.lower():\n",
    "            pred_label = 1\n",
    "        elif '0' in response.choices[0].message.content.lower():\n",
    "            pred_label = 0\n",
    "        else:\n",
    "            raise Exception(f'Нет решения по отзыву:\\n\\t{sample[\"text\"]}\\nМодель сказала:\\n\\t{response.choices[0].message.content.lower()}')\n",
    "    # print(response.choices[0].message.content.lower())\n",
    "    accuracy.append(int(pred_label == sample['label']))\n",
    "print(sum(accuracy) / len(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b52fa7",
   "metadata": {},
   "source": [
    "#### Few-Shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb48fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_few_shot_prompt(review_text, examples=train_dataset[:4]):\n",
    "    messages = []\n",
    "    system_prompt = \"You are a helpful assistant that classifies movies reviews. Please, read the review and answer with symbol - 1, if user's review is positive, or with symbol 0, if review is negative. Do not answer in text, answer in one of the following two options: 1, 0\"\n",
    "    messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "\n",
    "    for example in examples:\n",
    "        messages.append({\"role\": \"user\", \"content\": f\"Do not answer in text and classify this review in one word with one of following options - 0 or 1: {example['text'].replace('<br />', '')}\"})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": f\"assistant: {example['label']}\"})\n",
    "\n",
    "    user_content = f\"Do not answer in text and classify this review in one word with one of following options - 0 or 1: {review_text.replace('<br />', '')}\"\n",
    "    messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a90de15",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [sample[\"label\"] for sample in test_dataset]\n",
    "responses = []\n",
    "accuracy = []\n",
    "\n",
    "for sample in tqdm(test_dataset):\n",
    "    messages = build_few_shot_prompt(sample['text'])\n",
    "    response = client.chat.completions.create(messages=messages, model=model_8b, timeout=10, max_tokens=20, temperature=0.2)\n",
    "    response = response.choices[0].message.content.lower()\n",
    "    responses.append(response)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d07ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [int('assistant: 1' in elem) for elem in responses]\n",
    "sum([preds[i] == true_labels[i] for i in range(len(preds))]) / len(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582ec971",
   "metadata": {},
   "source": [
    "#### Chain-of-Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cad3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
    "gsm8k = load_dataset(\"openai/gsm8k\", \"main\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ccbb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "\n",
    "for i in range(20):\n",
    "    sample = gsm8k[\"test\"][i]\n",
    "    question = sample[\"question\"]\n",
    "    answer = sample[\"answer\"].split(\"####\")[1].strip()\n",
    "    samples.append({\"question\": question, \"answer\": int(answer)})\n",
    "\n",
    "\n",
    "print(\"Task:\", samples[0][\"question\"])\n",
    "print(\"Answer:\", samples[0][\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaff5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(task):\n",
    "    system_prompt = 'You are a helpful assistant that helps to solve math tasks. Now you are on a math exam.'\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"Here is a math task. Solve it step by step and give answer in the end: {task}\"})\n",
    "    response = client.chat.completions.create(messages=messages, model=model, max_tokens=300)\n",
    "    assistant_prompt = response.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": f\"Solution: {assistant_prompt}\"})\n",
    "    messages.append({\"role\": \"user\", \"content\": \"Now give me only the answer in JSON-format, key is word 'answer', and value is number - final answer for this task\"})\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890fa079",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "answers = []\n",
    "for sample in tqdm(samples):\n",
    "    messages = create_prompt(sample['question'])\n",
    "    response = client.chat.completions.create(messages=messages, model=model, max_tokens=20)\n",
    "    responses.append(response.choices[0].message.content)\n",
    "    answers.append(sample['answer'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506eeb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [int(re.sub(r'[{}\\n\"]', '', response).strip().split(': ')[1]) for response in responses]\n",
    "sum([predictions[i] == answers[i] for i in range(len(answers))]) / len(answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
