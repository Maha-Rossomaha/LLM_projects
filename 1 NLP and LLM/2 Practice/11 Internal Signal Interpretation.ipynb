{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b902bf",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e5130",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"transformers[torch]\" accelerate datasets captum shap bertviz matplotlib pandas fsspec \"huggingface_hub>=0.24.0\" -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a92a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "from datasets import load_dataset\n",
    "from bertviz import head_view, model_view\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b8cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2924408a",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cf5d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert/distilbert-base-uncased', num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert/distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef822a1b",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c7dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a31ea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = load_dataset(\"imdb\", ignore_verifications=True)\n",
    "ds = load_dataset(\"imdb\")  \n",
    "ds = ds.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406e0ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c0191f",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f5199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.from_numpy(logits).softmax(dim=-1).numpy()\n",
    "    preds = probs.argmax(axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1  = f1_score(labels, preds)\n",
    "    prec = precision_score(labels, preds)\n",
    "    rec = recall_score(labels, preds)\n",
    "    try:\n",
    "        auc = roc_auc_score(labels, probs[:, 1])\n",
    "    except Exception:\n",
    "        auc = np.nan\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": prec, \"recall\": rec, \"roc_auc\": auc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"./data/signal_explanation/ckpt\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_ratio=0.1,\n",
    "    fp16=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=30,\n",
    "    dataloader_num_workers=0,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=args,\n",
    "    train_dataset=ds[\"train\"].shuffle(seed=42).select(range(7000)),\n",
    "    eval_dataset=ds[\"test\"].shuffle(seed=42).select(range(700)),\n",
    "    data_collator=collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada24c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f98421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe40548a",
   "metadata": {},
   "source": [
    "### BertViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36195fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The movie was surprisingly good!\"\n",
    "inputs = tokenizer.encode(text, return_tensors='pt').to(device)\n",
    "\n",
    "outputs = model(inputs, output_attentions=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])\n",
    "\n",
    "head_view(outputs.attentions, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa4d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_view(outputs.attentions, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d92612",
   "metadata": {},
   "source": [
    "### Attention Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8b5acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_heatmap(attn_4d, tokens, layer_idx=0, savepath=\"data/signal_explanation/attention_heatmap.png\"):\n",
    "    A = attn_4d[layer_idx].mean(axis=0)  # (H,L,L) -> (L,L), среднее по H\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    im = ax.imshow(A, aspect=\"auto\")\n",
    "    ax.set_xticks(range(len(tokens))); ax.set_yticks(range(len(tokens)))\n",
    "    ax.set_xticklabels(tokens, rotation=90)\n",
    "    ax.set_yticklabels(tokens)\n",
    "    ax.set_title(f\"Attention heatmap (layer {layer_idx}, mean heads)\")\n",
    "    fig.colorbar(im, ax=ax, fraction=0.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(savepath, dpi=200)\n",
    "    plt.close()\n",
    "    return savepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e103ffa",
   "metadata": {},
   "source": [
    "### Integrated Gradients (token-importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29346a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_for_class(input_ids, attention_mask, target_class):\n",
    "    embeds = model.get_input_embeddings()(input_ids)\n",
    "    logits = model(inputs_embeds=embeds, attention_mask=attention_mask, return_dict=True).logits\n",
    "    return logits[:, target_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e42ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_importance_ig(text, target_class=None, max_len=128, n_steps=32):\n",
    "    model.eval()\n",
    "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_len).to(device)\n",
    "    input_ids = enc[\"input_ids\"]\n",
    "    attention_mask = enc[\"attention_mask\"]\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probs = model(**enc).logits.softmax(-1)\n",
    "        if target_class is None:\n",
    "            target_class = int(probs.argmax(-1).item())\n",
    "\n",
    "    lig = LayerIntegratedGradients(\n",
    "        lambda inp: forward_for_class(inp, attention_mask, target_class), \n",
    "        layer=model.get_input_embeddings()\n",
    "    )\n",
    "    \n",
    "    attributions, _ = lig.attribute(\n",
    "        inputs=input_ids,\n",
    "        baselines=torch.zeros_like(input_ids),\n",
    "        additional_forward_args=None,\n",
    "        n_steps=n_steps, \n",
    "        return_convergence_delta=True\n",
    "    )\n",
    "\n",
    "    token_scores = attributions.sum(dim=-1).detach().cpu().numpy()[0]  # (L,)\n",
    "\n",
    "    s = token_scores\n",
    "    s_norm = (s - s.min()) / (s.max() - s.min() + 1e-9)\n",
    "    return tokens, s_norm, target_class, probs[0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_token_importance(tokens, scores, title=\"Token attribution (IG)\", savepath=\"data/signal_explanation/ig_importance.png\"):\n",
    "    idx = np.arange(len(tokens))\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.bar(idx, scores)\n",
    "    plt.xticks(idx, tokens, rotation=90)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(savepath, dpi=200)\n",
    "    plt.close()\n",
    "    return savepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce06f7b1",
   "metadata": {},
   "source": [
    "#### Attention vs Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_content_token(tok):\n",
    "    return tok not in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_attentions(model, tokenizer, text, max_len=128):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_len).to(device)\n",
    "    outputs = model(**inputs, output_attentions=True, return_dict=True)\n",
    "\n",
    "    attentions = [a[0].detach().cpu().numpy() for a in outputs.attentions]\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0].tolist())\n",
    "    return attentions, tokens, outputs.logits.softmax(-1)[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be69234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_cls_importance(attn_4d, layer_idx=-1):\n",
    "    \"\"\"Берём среднее по головам внимание из позиции [CLS] к остальным токенам на выбранном слое.\"\"\"\n",
    "    A = attn_4d[layer_idx].mean(axis=0)  # (L,L)\n",
    "    cls_idx = 0\n",
    "    imp = A[cls_idx]  # (L,)\n",
    "    imp = (imp - imp.min()) / (imp.max() - imp.min() + 1e-9)\n",
    "    return imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2900be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_attention_vs_ig(text, layer_idx=-1, max_len=128):\n",
    "    attn, toks, probs = get_attentions(model, tokenizer, text, max_len=max_len)\n",
    "    toks_ig, ig_scores, target_class, probs_full = token_importance_ig(text, max_len=max_len)\n",
    "\n",
    "    attn_imp = attention_cls_importance(attn, layer_idx=layer_idx)\n",
    "\n",
    "    # Фильтруем служебные токены\n",
    "    mask = np.array([is_content_token(t) for t in toks])\n",
    "    ig_c = ig_scores[mask]\n",
    "    at_c = attn_imp[mask]\n",
    "    \n",
    "    rho, pval = spearmanr(ig_c, at_c)\n",
    "\n",
    "    def top_k(tokens, scores, k=10):\n",
    "        idx = np.argsort(scores)[::-1][:k]\n",
    "        return [(tokens[i], float(scores[i])) for i in idx]\n",
    "\n",
    "    top_ig = top_k(toks, ig_scores)\n",
    "    top_attn = top_k(toks, attn_imp)\n",
    "    \n",
    "    heatmap_path = plot_attention_heatmap(attn, toks, layer_idx if layer_idx>=0 else len(attn)-1)\n",
    "    ig_plot_path = plot_token_importance(toks, ig_scores)\n",
    "    \n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"tokens\": toks,\n",
    "        \"probs\": probs.tolist(),\n",
    "        \"pred_class\": int(np.argmax(probs)),\n",
    "        \"attention_importance\": list(zip(toks, attn_imp)),\n",
    "        \"ig_importance\": list(zip(toks, ig_scores)),\n",
    "        \"spearman_rho\": float(rho),\n",
    "        \"spearman_pval\": float(pval),\n",
    "        \"top_tokens_ig\": top_ig,\n",
    "        \"top_tokens_attention\": top_attn,\n",
    "        \"plots\": {\n",
    "            \"attention_heatmap\": heatmap_path, \n",
    "            \"ig_importance\": ig_plot_path\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6b8695",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = compare_attention_vs_ig(\"The movie was surprisingly good, not boring at all!\")\n",
    "for k, v in res.items():\n",
    "    print(k)\n",
    "    print(v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d25696a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
