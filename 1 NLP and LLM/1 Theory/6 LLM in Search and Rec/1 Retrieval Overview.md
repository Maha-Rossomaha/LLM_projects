# Обзорный конспект: Retrieval

## 1. Мотивация

Retrieval (поиск) — ключевой этап в информационных системах, где задача состоит в том, чтобы по входному запросу найти релевантные документы или объекты. В контексте LLM и современных рекомендательных систем, retrieval необходим для:

* **RAG (Retrieval-Augmented Generation)**: подбор релевантного контекста для генеративной модели.
* **Semantic Search**: поиск по смыслу, а не по точному совпадению слов.
* **Рекомендации**: нахождение похожих объектов (товаров, фильмов, новостей).
* **Дедупликация и кластеризация**: поиск схожих элементов для удаления или группировки.

Основная цель retrieval — быстро и качественно найти ограниченный набор кандидатов (top-K), которые будут дальше обработаны более сложными моделями (reranker, генератор).

---

## 2. Виды Retrieval

### 2.1 Sparse Retrieval

Использует разреженные представления (мешок слов, tf-idf, BM25 и др.).

* Преимущества: простота, прозрачность, устойчивость к редким словам.
* Недостатки: плохо улавливает синонимы и контекст.

### 2.2 Dense Retrieval

Использует плотные векторные представления (эмбеддинги) из нейросетевых моделей (например, E5, BGE, SBERT).

* Преимущества: семантический поиск, способность находить результаты без точного совпадения слов.
* Недостатки: требует обучения моделей и поддержки ANN-индексации.

### 2.3 Hybrid Retrieval

Комбинирует sparse и dense подходы, например, взвешивая их результаты или используя ранговые фузии (RRF, weighted sum).

* Преимущества: устойчивость к OOV, редким термам и морфологическим вариациям.
* Недостатки: усложнение инфраструктуры и слияния результатов.

---

## 3. Sparse Retrieval

Sparse retrieval основан на лексическом совпадении токенов из запроса и документа. Классический стек включает:

* **TF-IDF** — базовый метод с весами термов по их частоте.
* **BM25** — улучшение TF-IDF с нормализацией по длине документа и функцией насыщения термов.
* **BM25F** — расширение BM25 для учёта весов разных полей (заголовок, тело, аннотация).

**Параметры BM25:**

* `k1` — степень насыщения терма (обычно 1.2–2.0).
* `b` — коэффициент нормализации по длине документа (0 — нет нормализации, 1 — полная нормализация).

**Оптимизация Sparse Retrieval:**

* Удаление стоп-слов и малозначимых термов.
* Лексический fallback при сбое dense поиска.
* Индексация с учётом морфологии (стемминг, лемматизация).

**Инфраструктурная поддержка:**

* Elasticsearch / OpenSearch (`BM25`, `BM25F`).
* Lucene core.
* Поддержка в гибридных пайплайнах (BM25 + dense fusion).

---

## 4. Dense Retrieval

Dense retrieval использует нейросетевые модели для преобразования текста в плотные векторные представления фиксированной размерности. Эти векторы сравниваются по косинусному сходству или другим метрикам расстояния.

**Ключевые элементы:**

* **Эмбеддинговые модели**: Sentence-BERT, E5, BGE, GTE.
* **Нормализация**: L2-нормализация для стабильности сравнения.
* **Pooling**: mean, max, CLS-token pooling.

**Процесс:**

1. Кодирование запросов и документов в векторы.
2. Поиск ближайших соседей через ANN (Approximate Nearest Neighbor) индекс.
3. Возврат top-K кандидатов.

**Алгоритмы ANN:**

* IVF-PQ (инвертированные списки + product quantization).
* HNSW (графовая навигация).
* ScaNN, DiskANN.

**Преимущества:**

* Семантическое понимание запросов.
* Хорошо работает для мультиязычного поиска.

**Недостатки:**

* Требует больших вычислительных ресурсов для обучения.
* Необходима поддержка векторных баз данных.

**Инфраструктурная поддержка:**

* FAISS, Qdrant, Milvus, Weaviate, Vespa.
* OpenSearch / Elasticsearch с `dense_vector` полями.

---

## 5. Hybrid Retrieval

Hybrid retrieval объединяет сильные стороны sparse и dense подходов.

**Методы объединения:**

* **Score Fusion**: взвешенное сложение нормализованных скорингов (BM25 и cosine similarity).
* **Rank Fusion**: методы слияния списков кандидатов, например Reciprocal Rank Fusion (RRF) или Borda count.
* **Lexical Fallback**: переход на sparse-поиск при отсутствии качественных dense-результатов.

**Преимущества:**

* Устойчивость к редким словам и OOV.
* Улучшение качества для сложных и неоднозначных запросов.

**Недостатки:**

* Более сложная настройка.
* Повышенные требования к инфраструктуре.

**Инфраструктурная поддержка:**

* OpenSearch / Elasticsearch с гибридными плагинами.
* Weaviate, Vespa, Pinecone с нативной поддержкой гибридного поиска.
