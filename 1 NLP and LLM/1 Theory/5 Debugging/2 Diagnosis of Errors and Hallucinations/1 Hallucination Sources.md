# Выявление источников галлюцинаций в LLM 

## 1. Что такое галлюцинации в LLM

**Галлюцинации** — это случаи, когда модель генерирует текст, содержащий фактически неверную или несуществующую информацию, при этом подавая её как достоверную.

---

## 2. Основные источники галлюцинаций

### 2.1 Недостаточный контекст

* **Описание:** модель не имеет всей необходимой информации в prompt’е или переданном контексте.
* **Причины:**

  * Короткий или неправильно выбранный контекст.
  * Потеря ключевых фактов при сжатии/фильтрации документа.
  * Ограничение длины окна контекста (context window).
* **Пример:** Вопрос «Кто был премьер-министром Великобритании в 2016?» без уточнения месяца → модель может выбрать неверного человека.

### 2.2 Ошибка retrieval

* **Описание:** в RAG или поисковых системах модель получает нерелевантные, устаревшие или ошибочные документы.
* **Причины:**

  * Низкое качество retriever’а (неудачные эмбеддинги, плохая сегментация).
  * Слабая фильтрация шума в результатах.
  * Попадание устаревшей информации.
* **Пример:** Запрос «Столица Франции» возвращает документ с заведомо неверным утверждением («Марсель»), и модель, не проверив факт, включает его в ответ.

---

## 3. Методы диагностики

### 3.1 Логирование и трассировка

* Сохранять top-K retrieved документов для каждого ответа.
* Логировать версию эмбеддингов и параметры поиска.
* Привязывать к каждому ответу `doc_id`, source URL, timestamp.

### 3.2 Анализ retrieved контента

* Проверка релевантности (manual review или автоматическая классификация).
* Метрики: Recall\@K, MRR, nDCG для retrieval.
* Сравнение retrieved текста с вопросом по semantic similarity.

### 3.3 Проверка контекстного окна

* Подсчёт, был ли нужный факт внутри context window.
* Анализ обрезанных частей при длинных документах.
* Визуализация chunk’ов и их позиций.

### 3.4 Сравнение с эталонной базой знаний

* Использование валидационных датасетов с проверенной информацией.
* Сравнение фактов ответа с ground truth.

### 3.5 Атрибуция (LRP, IG, SHAP)

* Определить, на какие части контекста модель опиралась.
* Если модель ссылается на нерелевантные куски, вероятно, это источник ошибки.

---

## 4. Применимость в пайплайнах

* **RAG:** диагностика качества retriever’а и relevance ranking.
* **LLM без retrieval:** анализ полноты и качества prompt’а.
* **Multi-hop reasoning:** проверка, что промежуточные шаги содержат верные факты.

---

## 5. Плюсы и минусы подходов

**Плюсы:**

* Позволяет локализовать проблему: retrieval vs context formulation.
* Улучшает explainability.
* Можно автоматизировать для мониторинга качества.

**Минусы:**

* Требует хранения и анализа больших объёмов данных.
* Автоматические проверки могут пропускать скрытые ошибки (требуется human-in-the-loop).

---

## 6. Лучшие практики снижения галлюцинаций

* Улучшение retrieval (качественные эмбеддинги, fine-tune).
* Фильтрация и reranking документов по релевантности.
* Расширение или оптимизация контекста.
* Валидация retrieved фактов через вторичную модель.
* Использование self-checking LLM (модель проверяет свой ответ).
