# Multi-hop Reasoning в LLM

## Что это такое

**Multi-hop reasoning** — это стратегия, при которой LLM решает задачу, требующую **нескольких последовательных логических шагов**, каждый из которых использует **разные фрагменты знаний**.

Иными словами, чтобы ответить на вопрос, нужно "перепрыгнуть" через несколько опорных фактов ("hop'ов"), связывая их в цепочку.

> Пример: “В какой стране родился актёр, сыгравший Гэндальфа в «Властелине колец»?”
>
> 1. Кто сыграл Гэндальфа → Иэн Маккеллен
> 2. Где он родился → Великобритания  → Ответ: Великобритания

---

## Мотивация

Большинство реальных вопросов не содержат всю информацию явно. Ответ скрыт за **несколькими промежуточными связями**, которые необходимо извлечь, связать и интерпретировать.

**Multi-hop reasoning** позволяет:

- выходить за пределы surface-level matching,
- повышать точность в retrieval-augmented задачах (RAG),
- строить более интерпретируемые reasoning-пути.

---

## Формальные признаки multi-hop задач

- Необходимость сделать **2 и более логических перехода**
- Использование **нескольких источников или предложений**
- Промежуточные вопросы/ответы можно явно выписать

Примеры датасетов: **HotpotQA, MuSiQue, StrategyQA**

---

## Алгоритмические подходы

### 1. **Chain-of-Thought (CoT)**

- Простая реализация: LLM генерирует шаги рассуждения в виде текста
- Хорошо работает, если модель знает знания из всех hop'ов

### 2. **RAG + Step-by-step**

- На каждом шаге retrieval используется предыдущий результат
- Пример: query → retrieve → partial answer → next query → …

### 3. **Graph-based Reasoning**

- Представление фактов как графа (узлы — сущности, ребра — связи)
- Поиск путей между сущностями через knowledge base (например, Wikidata)

### 4. **Self-ask with search**

- Модель задаёт себе под-вопросы и ищет на них ответы
- Пример: “Кто…?” → “Кто сыграл X?” → “Где родился Y?”

---

## Пример (CoT style)

**Вопрос:** Какая река протекает через столицу страны, в которой родился Чарльз Дарвин?

1. Чарльз Дарвин родился в Англии.
2. Столица Англии — Лондон.
3. Через Лондон протекает Темза. **Ответ:** Темза

---

## Пример реализации (итеративный hop-by-hop retrieval)

```python
from rag_toolkit import retrieve_documents, llm_answer

query = "Какая река протекает через столицу страны, где родился Дарвин?"
step1 = llm_answer(query)

docs1 = retrieve_documents(step1)
step2 = llm_answer("Столица страны, где родился Дарвин", context=docs1)

docs2 = retrieve_documents(step2)
step3 = llm_answer("Река в столице " + step2, context=docs2)

print("Финальный ответ:", step3)
```

---

## Плюсы

- Позволяет решать сложные и нетривиальные вопросы
- Высокая интерпретируемость (видны шаги reasoning-а)
- Подходит для RAG, агентных и search-heavy систем
- Стимулирует структурированные reasoning-паттерны

---

## Минусы

- Ошибка на раннем шаге → ошибка на всём пути
- Требует хороших retriever'ов и chunk-стратегий
- Медленнее и дороже, чем single-hop
- Часто возникают галлюцинации промежуточных фактов

---

## Где используется

- **QA-системы:** HotpotQA, Natural Questions
- **RAG-фреймворки:** LangChain, LlamaIndex с пошаговым retrieval
- **Агентные системы:** LLM, задающий себе под-вопросы
- **Обучение reasoning-способностей** (например, в fine-tuning задачах)
