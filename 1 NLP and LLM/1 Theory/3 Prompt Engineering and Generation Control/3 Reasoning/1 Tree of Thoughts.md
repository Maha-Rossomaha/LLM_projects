# Tree of Thoughts (ToT) в LLM

## Что это такое

**Tree of Thoughts (ToT)** — это техника reasoning-а, при которой LLM рассматривает **несколько вариантов мышления (thoughts)** на каждом шаге, формируя **древовидную структуру** поиска решений.

В отличие от Chain of Thought (CoT), где создаётся линейная цепочка рассуждений, **ToT строит дерево возможных рассуждений**, выбирает и продолжает наиболее перспективные ветки.

> Вдохновлён алгоритмами поиска в классическом ИИ (DFS, BFS, A\*), но использует LLM как генератор и оценщик мыслей.

---

## Мотивация

Chain of Thought хорош для линейных задач, но:

- не может вернуться и попробовать другой путь,
- не оценивает альтернативы,
- легко заходит в тупик или делает ошибку в early step.

**ToT** помогает:

- исследовать множество вариантов рассуждений,
- выбирать лучшие мысли по метрике (оценка модели или эвристика),
- формировать более надёжные, обоснованные и точные ответы.

---

## Описание алгоритма

Алгоритм можно описать как **итеративное расширение дерева мыслей** с выбором и фильтрацией.

### 1. Инициализация

- Получаем задачу или вопрос
- Задаём функцию генерации мыслей `generate_thoughts(state)`
- Начальное состояние: `root` (например, пустое рассуждение)

### 2. Расширение узлов

- Для текущего узла генерируется `k` возможных мыслей (веток)
- Каждая мысль — потенциальный шаг решения

### 3. Оценка узлов

- Применяется **оценочная функция** (LLM, эвристика, value function)
- Узлы сортируются по score (надежность, правдоподобие, достижимость цели и т.п.)

### 4. Отбор

- Выбираются top-N мыслей (веток) для продолжения
- Применяется ограничение глубины / ширины дерева

### 5. Поиск

- Повторяется до достижения глубины или получения финального ответа
- Возможны стратегии: BFS, DFS, beam search

---

## Пример (задача на арифметику)

**Вопрос:** У Анны 3 яблока, у Бориса в 2 раза больше. Сколько всего яблок?

1. Root:

   - Thought 1: У Бориса 3 × 2 = 6
   - Thought 2: У Бориса на 3 больше → 3 + 3 = 6

2. Expansion:

   - From Thought 1 → Thought: 3 + 6 = 9 → ✅
   - From Thought 2 → Thought: 3 + 6 = 9 → ✅

3. Evaluation: обе ветки дают правильный ответ 9, но первая логически точнее.

---

## Реализация (псевдокод)

```python
from typing import List

def generate_thoughts(state: str) -> List[str]:
    prompt = f"Continue reasoning from: {state}\nThought:"
    return LLM_generate_k_completions(prompt, k=3)

def evaluate_thoughts(thoughts: List[str]) -> List[float]:
    return [LLM_score(t) for t in thoughts]

def tree_of_thoughts(root_state, max_depth=3, beam_width=2):
    frontier = [(root_state, [])]  # (current_state, path)

    for depth in range(max_depth):
        candidates = []
        for state, path in frontier:
            thoughts = generate_thoughts(state)
            scores = evaluate_thoughts(thoughts)
            for t, s in zip(thoughts, scores):
                candidates.append((s, t, path + [t]))

        candidates.sort(reverse=True)
        frontier = [(t, p) for _, t, p in candidates[:beam_width]]

    return frontier[0][1]  # best path of thoughts
```

---

## Плюсы

- Более полный охват пространства решений
- Меньше ошибок на ранних шагах (можно вернуться)
- Гибкость стратегий поиска (DFS, BFS, beam)
- Возможность оценки промежуточных шагов

---

## Минусы

- Высокая стоимость: много вызовов LLM
- Требует стратегии оценки промежуточных мыслей
- Не всегда легко определить метрику «качества мысли»
- Сложнее реализовать и дебажить, чем CoT

---

## Где используется

- **Математика и логика:** multi-step reasoning
- **Игра в 20 вопросов**, шахматы, задачи планирования
- **RAG-процессы:** выбор лучшего пути поиска / ответа
- **LLM-агенты:** выбор действия среди стратегий
