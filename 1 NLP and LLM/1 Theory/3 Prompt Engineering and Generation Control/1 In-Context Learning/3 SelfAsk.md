# Self-Ask Prompting

## Мотивация

Некоторые вопросы требуют **внешних знаний** или **многоступенчатого мышления**, которое сложно выразить в одной цепочке рассуждений. Модель может не обладать всей информацией, нужной для ответа, особенно если вопрос предполагает подзадачи.

**Self-Ask** (Self-Ask With Search) — это prompting-подход, в котором модель:

1. Разбивает вопрос на подзадачи.
2. Явно задаёт себе вопросы, на которые нужно ответить, чтобы решить основную задачу.
3. Ищет ответы (внутренне или с помощью внешнего поиска).
4. На их основе строит финальное рассуждение и ответ.

## Пример

> Вопрос: Какая столица страны, в которой родился Барак Обама?

**Self-Ask поведение:**

1. Где родился Барак Обама? → Гавайи (США)
2. Какая столица США? → Вашингтон
3. Ответ: Вашингтон

## Формулировка

Модель задаёт промежуточные вопросы $q_1, ..., q_T$ и получает ответы $a_1, ..., a_T$:

$$
\text{SelfAsk}(x) = \{(q_1, a_1), ..., (q_T, a_T)\} \rightarrow y
$$

Где:

- $x$ — исходный вопрос,
- $y$ — финальный ответ,
- каждый $q_i$ — подвопрос,
- $a_i$ — ответ на него (может быть из внешнего источника).

## Отличия от Chain-of-Thought

| CoT                          | Self-Ask                          |
| ---------------------------- | --------------------------------- |
| Генерирует рассуждение сразу | Делит на подвопросы               |
| Без внешнего поиска          | Может обращаться к поиску         |
| Линейная цепочка             | Последовательность QA             |
| Полезен для арифметики       | Полезен для знаний и lookup-задач |

## Компоненты Self-Ask

1. **Разбиение на подвопросы**: модель формирует естественные уточняющие вопросы.
2. **Поиск/Lookup** (опционально): можно подключать Web Search API, Google, Википедию, базу знаний.
3. **Answer aggregation**: ответы используются для составления финального объяснения.

## Пример prompt-а

```text
Вопрос: Кто был президентом Франции, когда родился Илон Маск?
Давайте разберём вопрос.
Подвопрос: Когда родился Илон Маск?
Ответ: 28 июня 1971 года.
Подвопрос: Кто был президентом Франции в 1971 году?
Ответ: Жорж Помпиду.
Ответ: Жорж Помпиду
```

## Использование с внешним поиском

Self-Ask может использовать внешний **retriever** (например, Wikipedia API или Google Search) для получения ответов на подвопросы. В этом случае pipeline выглядит так:

1. Модель генерирует подвопрос.
2. Поиск по вебу / базе.
3. Извлечение краткого ответа.
4. Возврат в LLM для следующего шага рассуждения.

## Примеры задач

- Вопросы с несколькими шагами reasoning (QA over knowledge)
- Commonsense + factual
- Temporal and historical QA
- Web-assisted QA
- Answer-lookup in retrieval-augmented generation (RAG)

## Почему работает

- Модель **явно декомпозирует** задачу — это снижает когнитивную нагрузку.
- Каждый подвопрос проще, чем изначальный.
- Возможность уточнять — снижает галлюцинации.
- Поддерживает подключение внешних источников.

## Связанные методы и расширения

- **Ask-Confirm**: после ответа на подвопрос — проверка уверенности.
- **ReAct prompting**: чередование reasoning и действий (поиск, API).
- **ToT (Tree-of-Thought)**: можно представить Self-Ask как частный случай ToT с ветвлением по вопросам.
- **Toolformer**: автономное обучение модели выбирать подходящий инструмент (поиск, калькулятор и т.п.).

## Плюсы

- Повышает точность в задачах с внешними фактами.
- Структурирует reasoning и делает его интерпретируемым.
- Позволяет подключать внешние источники знаний.

## Минусы

- Дольше, чем обычный CoT.
- Требует поддержки внешнего поиска, если знаний в модели недостаточно.
- Неэффективен на простых задачах.
