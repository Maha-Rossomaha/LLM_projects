# Zero-shot, One-shot и Few-shot обучение

## Мотивация

Классическое обучение требует большого размеченного корпуса. Однако для многих задач:

- **разметка слишком дорогая**,
- **задача может быть уникальной**, без большого количества примеров,
- **нужна быстрая адаптация** к новой задаче без переобучения модели.

Zero-/One-/Few-shot позволяют использовать уже **предобученные модели** (особенно LLM) без или почти без дополнительного обучения.

## Формулировка задачи

Пусть у нас есть распределение задач $\mathcal{T} \sim p(\mathcal{T})$. Каждая задача $\mathcal{T}_i$ включает входы $x \in \mathcal{X}$ и выходы $y \in \mathcal{Y}$, а также распределение $\mathcal{D}_i(x, y)$.

Цель: обучить модель $f_\theta(x, \mathcal{T}_i)$ так, чтобы она:

- минимизировала ошибку на новых задачах $\mathcal{T}_{test}$,
- при этом **имела минимум примеров** для адаптации (0, 1 или несколько).

## Подходы

### Zero-shot learning

**Модель**: используется напрямую без адаптации к конкретной задаче.\
**Контекст**: промпт содержит только формулировку задачи.

> Пример: "Переведи на французский: 'I am happy'."

- Нет обучающих примеров.
- Опирается на знания, полученные во время pretraining.

**Формально:** $y = f(x)$, где $f$ не зависит от конкретной задачи.

**Плюсы:**

- Моментальное применение на новых задачах.
- Не требует дополнительной разметки или fine-tuning.

**Минусы:**

- Качество ограничено способностью модели обобщать.
- Зависит от правильной формулировки задачи (prompt sensitivity).

### One-shot learning

**Модель**: получает **один пример** решения задачи.

> Пример:
> "Переведи на французский: 'I am happy'. Ответ: 'Je suis heureux'.\
> Переведи на французский: 'I am sad'."

- Один пример до запроса.
- Часто используется для создания шаблона решения.

**Формально:** $y = f(x; (x_1, y_1))$

**Плюсы:**

- Дает модели пример структуры ответа.
- Улучшает результат по сравнению с zero-shot.

**Минусы:**

- Уязвимость к выбору единственного примера.
- Может не обобщаться на разные стили/тематики.

### Few-shot learning

**Модель**: получает **несколько примеров** (обычно 2–32) в контексте.

> Пример:
> "Переведи на французский:
>
> - 'I am happy' → 'Je suis heureux'
> - 'I am sad' → 'Je suis triste'
> - 'I am tired' → "

**Формально:** $y = f(x; {(x_i, y_i)}_{i=1}^k)$

**Плюсы:**

- Значительно повышает качество, особенно на сложных задачах.
- Позволяет использовать примеры из нужной доменной области.

**Минусы:**

- Ограничено контекстным окном модели.
- Требует тщательного подбора примеров (relevance, diversity).

## Реализация в LLM

Все три метода реализуются **промпт-инжинирингом**. Для few-shot часто используется **in-context learning**, где примеры подаются как часть входа, а веса модели не изменяются.

Дополнительно:

- Для задач классификации можно использовать шаблоны: "Текст: ... Класс: ..."
- Для reasoning – CoT (Chain-of-Thought) помогает модели проходить промежуточные шаги рассуждений.

## Вариации и расширения

- **Instruction tuning**: обучение на множестве задач вида (инструкция, ответ) улучшает zero/few-shot способность.
- **Prompt tuning / Prefix tuning**: автоматическое обучение параметров, добавляемых к prompt'у.
- **Meta-learning (например, MAML)**: обучает модель быстро адаптироваться к новым задачам, формально оптимизируя задание с минимальным количеством шагов.

## Применения

- Многоязычный перевод.
- Классификация без размеченных данных.
- Ответы на вопросы по новым тематикам.
- Диалоговые агенты (чатботы).
- Reasoning / логические задачи.
- Генерация кода (например, Codex).
