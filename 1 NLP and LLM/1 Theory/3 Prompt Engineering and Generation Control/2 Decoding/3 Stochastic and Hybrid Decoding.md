# Стохастические и гибридные алгоритмы декодирования в LLM

---

## 1. Nucleus Sampling (top-p)

**Суть:**

- Модель сортирует токены по вероятности и отбирает минимальное множество, чья суммарная вероятность ≥ *p* (например, 0.9). Затем выбор происходит случайно внутри этого множества.

**Используется:**

- В большинстве production-моделей (OpenAI, Anthropic, Cohere)
- Хороший баланс между качеством и разнообразием

**Плюсы:**

- Избегает редких токенов с низкой вероятностью
- Управляемый стохастический выбор

**Минусы:**

- Может терять важные токены за пределами p, если p слишком маленький

---

## 2. Top-k Sampling

**Суть:**

- Модель ограничивает выбор k наиболее вероятными токенами на каждом шаге. Выбор случайный из них.

**Используется:**

- Чуть реже, чем top-p, но применяется в задачах с более агрессивным контролем за разнообразием

**Плюсы:**

- Простая реализация, высокая эффективность
- Явно ограничивает хвост распределения

**Минусы:**

- Режет хвост «грубо», в отличие от top-p
- Без адаптации — чувствителен к падению вероятностей

---

## 3. Temperature + Sampling (в комбинации с top-p/top-k)

**Суть:**

- Temperature модифицирует распределение вероятностей: $p_i \propto \exp(\text{logit}_i / T)$
- Часто применяется совместно с top-p или top-k, чтобы управлять формой распределения

**Используется:**

- Почти всегда в реальных настройках (например, temperature=0.7 + top-p=0.9)

**Плюсы:**

- Контроль над степенью креативности модели
- Гибко настраивается под задачу

**Минусы:**

- Без других фильтров (top-p/k) может порождать нежелательные токены

---

## 4. Typical Decoding (энергетический порог типичности)

**Суть:**

- Идея: исключить как слишком «предсказуемые», так и слишком «редкие» токены — оставить только те, чья информация близка к средней энтропии распределения

**Используется:**

- Всё чаще в современных LLM-фреймворках (например, TGI, vLLM)

**Плюсы:**

- Улучшает правдоподобие без излишней креативности
- Часто работает лучше, чем top-p при тех же настройках

**Минусы:**

- Не всегда доступен в API (например, OpenAI его не поддерживает явно)

---

## 5. Contrastive Decoding (Contrastive Search)

**Суть:**

- На каждом шаге выбирается токен, который одновременно:

  1. имеет высокую вероятность
  2. минимально похож на предыдущие токены

- Баланс между relevance и diversity управляется параметром α

**Используется:**

- В научных и прототипных системах (от Microsoft, Baidu), иногда в задачах генерации описаний

**Плюсы:**

- Выдаёт текст, сочетающий правдоподобие и разнообразие
- Эффективен в summarization, description generation

**Минусы:**

- Не все библиотеки поддерживают
- Нужно держать embedding-представления прошлых токенов

---

## 6. Speculative Decoding (спекулятивная генерация)

**Суть:**

- Модель-кандидат генерирует много токенов «вперёд», а большая модель валидирует и выбирает, какие из них принять

**Используется:**

- На проде у OpenAI (до 2$\times$ ускорение), TGI, Mistral Inference

**Плюсы:**

- Значительно ускоряет генерацию без ухудшения качества
- Сохраняет ту же выборку, что и основная модель

**Минусы:**

- Реализуется только на уровне inference-сервера
- Требует второй «быстрой» модели

---

## Выводы

| Метод                | Тип            | Где используется            | Применение                      |
| -------------------- | -------------- | --------------------------- | ------------------------------- |
| top-p sampling       | Стохастический | Практически везде           | Диалоги, генерация, код         |
| top-k sampling       | Стохастический | Меньше, но тоже часто       | Креативные тексты               |
| typical decoding     | Адаптивный     | vLLM, TGI, новые фреймворки | Краткие правдоподобные тексты   |
| contrastive decoding | Гибридный      | Summarization, описания     | Высокое качество + разнообразие |
| speculative decoding | Адаптивный     | OpenAI, Mistral, TGI        | Ускорение генерации             |

---

## Рекомендации

- **top-p + temperature** — универсальное решение для большинства задач
- **contrastive decoding** — если нужно максимизировать читабельность и разнообразие
- **speculative decoding** — если важна скорость (но нужен server-side support)

