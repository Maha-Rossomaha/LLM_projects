## Вопросы

### Чем эмбеддить (в зависимости от цели)

1. **Для анализа данных**  
   Используется любой качественный эмбеддер, желательно адаптированный под домен (например, BERT с тюнингом, generative LLM).

2. **Для анализа ошибок классификатора**  
   Эмбеддинги должны совпадать с теми, которые использует сам классификатор. Это позволяет выявить, где он систематически ошибается.

3. **Практический вывод**  
   Кластеризация по обучающим эмбеддингам помогает найти группы данных, где классификатор ошибается чаще всего.  
   Эти кластеры можно отдельно дообучить, переосмыслить или исключить из трейна.

---

### Что такое кластер (и как определить его смысл)

- Кластеризация — это группировка, но **по какому признаку?**
- У одной и той же выборки могут быть **разные валидные разбиения**, в зависимости от бизнес-цели.
- Например, в отзывах на стиральные машины:
  - «Очень шумная во время отжима»
  - «Не работает отжим вообще»
  Эти тексты относятся к одной проблемной теме — "отжим", и могут быть объединены в один кластер.

---

### Как формировать кластеры вручную и автоматически

1. **Ручная разметка**  
   Просматриваем 100–200+ текстов и размечаем: что именно мы считаем единым кластером?

2. **Автоматическое распространение**  
   Используем методы:
   - anchor-based,
   - weak supervision,
   - label propagation.

3. **Продвинутый вариант**  
   Дообучаем эмбеддер на этих примерах через contrastive learning, чтобы автоматически формировать нужное пространство сходства.

4. **Оценка**  
   Не только по silhouette score, а по более прикладным метрикам — например, % покрытия жалоб.

---
### Непредсказуемое распределение плотностей

**Кейс:** кластеризация поисковых запросов или отзывов, где плотность точек нерегулярна.

- Часто встречаются:
  - Аномально плотные группы.
  - Сильно разреженные зоны данных.

- Проблемы:
  - Алгоритмы типа KMeans и DBSCAN "ломаются":
    - Либо сливают всё в один кластер.
    - Либо создают много фрагментированных кластеров.

- Пример:
  - «наушники для тренировок», «беспроводные спортивные наушники»
  - «одеяло зимнее», «тёплое пуховое одеяло»


### Что делать в такой ситуации:

1. **UMAP** позволяет визуализировать плотность и увидеть проблему.

2. BERT и другие универсальные эмбеддеры могут быть неадаптированы к конкретному домену → **требуется адаптация**.

3. **Contrastive learning** помогает дообучить эмбеддер под задачу и выровнять расстояния.

4. **HDBSCAN** умеет адаптироваться к различной плотности — в таких задачах работает надёжнее.

5. Можно **выделить топ-N частых запросов** как якоря и разметить всё через anchor-based clustering.

6. **Итеративный подход**: кластеризация → фильтрация шумов → переэмбеддинг → кластеризация.

7. **Разделение по подсрезам**: сначала сегментируем данные по темам, регионам и т.п., а затем кластеризуем внутри подсрезов.

---
### Число кластеров неизвестно и нестабильно

**Кейс: кластеризация отзывов о товарах с помощью HDBSCAN**

Как понять, что параметры HDBSCAN подобраны хорошо:

- Кластеры покрывают **большую часть данных**, но не 100% — выбросы допустимы.
- Кластеры **интерпретируемы** и тематически устойчивы.
- Общее число кластеров не выглядит аномально:
  - для 10k текстов 50–200 кластеров — нормальный диапазон.
- Кластеры при ручной проверке **осмысленны**, а не выглядят случайными.
- Модель не делает **один гигантский кластер** на 70% данных — это сигнал плохой дифференциации эмбеддингов.

---

### Часть данных не кластеризуется

**Кейс: обращения клиентов в поддержку**

- Всегда будут **единичные, редкие или странные обращения** — выбросы, частные случаи или noise.
- Пример: "на старой версии загрузка ведет себя неадекватно" — частный баг.

**Важно:**
- Насильно приклеивать их к какому-либо кластеру — **плохая идея**: они искажают центр масс и тему.
- HDBSCAN позволяет пометить такие точки как **шум** (`label = -1`), и не включать их в кластеры.

**Продуктовое решение:**
- Создать отдельную категорию **"Прочее"** или "Одиночные жалобы", куда они будут складироваться.
- Такие случаи можно анализировать отдельно или использовать в качестве источника новых гипотез для продуктовой аналитики.

**Комментарий:**  
Это редкий, но важный кейс. В нём часто не ясно, что делать, и команды пытаются "протянуть" такие точки в ближайшие кластеры — но это вредит всей системе. Поддержка выбросов и явное игнорирование — честный и стратегически правильный путь.

---

### Неравномерные кластеры

**Кейс: кластеризация отзывов в маркетплейсе**

- На практике часто возникают **2–3 очень больших кластера**, внутри которых оказываются и массовые жалобы, и важные редкие сигналы.
  - Например:
    - «Проблемы с доставкой» — 10k текстов.
    - «Шум при отжиме» — 800 текстов.
- Проблема: **редкие жалобы теряются** внутри огромного объёма.

### Что делать

1. **Оценивать однородность** кластеров:
   - вручную интерпретировать темы;
   - измерять внутрикластерную смысловую близость (TF-IDF, embeddings spread).

2. **Многоступенчатая кластеризация**:
   - сначала кластеризуем крупные сегменты,
   - затем внутри них — уточнение по темам,
   - далее ищем редкие (label = –1) кластеры, снижая `min_cluster_size`.

3. Если известны редкие примеры (аутлайеры), можно найти похожие через **anchor-based** кластеризацию.

4. Обогатить эмбеддинги **дополнительными фичами**:
   - длина текста,
   - наличие ключевых слов,
   - признаки тональности или продукта.