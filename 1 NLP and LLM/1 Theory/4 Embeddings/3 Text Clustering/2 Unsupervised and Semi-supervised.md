## Unsupervised и Semi-supervised подходы

### Label propagation & spreading

- Подходит для semi-supervised задач, когда имеется ограниченное количество размеченных текстов (например, 1k) и большое количество неразмеченных (например, 10k).
- В пространстве эмбеддингов строится граф, где узлы — тексты, а веса рёбер — расстояния (сходства) между ними.
- Затем метки от размеченных примеров распространяются по графу к ближайшим неразмеченным (процесс "распространения меток").
- Метод эффективно использует локальную структуру данных и может улучшить качество при малой разметке.


### Label Propagation vs Label Spreading

Оба метода относятся к semi-supervised обучению и работают по графу, где:
- Вершины — это объекты (например, тексты),
- Рёбра — похожесть (обычно основана на расстоянии между эмбеддингами),
- Идея — распространить метки от размеченных объектов к неразмеченным.

#### Label Propagation

- Простейший алгоритм: на каждой итерации каждый узел принимает метку, которую чаще всего видит у соседей.
- Размеченные узлы **могут менять метки**, что может привести к переобучению или потере исходной информации.
- Быстрее, но менее устойчив.

#### Label Spreading

- Улучшенный вариант: учитывает **сглаживание весов**, а размеченные узлы закреплены — их метки не изменяются.
- Используется гауссовый или двудольный граф с нормализацией.
- Более устойчив к шуму и переобучению.

### Когда применять:
- Если нужно быстрое распространение и не страшно, что размеченные метки изменятся — Label Propagation.
- Если важна устойчивость и сохранение исходной разметки — Label Spreading.

### Anchor-based Clustering

- Метод полуавтоматической кластеризации, основанный на задании якорей (anchor points).
- Для каждого кластера вручную выбираются 1 или несколько эталонных текстов (якорей).
- Вычисляются расстояния от всех текстов до каждого якоря.
- Каждый текст назначается в тот кластер, чей якорь ближе всего (если расстояние не превышает порог).
- Подходит, когда есть экспертное знание и нужно контролируемо формировать кластеры.
- Можно применять как постобработку после снижения размерности (например, UMAP + anchors).

---

### Weak Supervision: эвристическая псевдоразметка

- Используется, когда нет полной разметки, но можно задать **набор слабых сигналов** (эвристик), например:
  - регулярные выражения,
  - ключевые слова,
  - тональность,
  - внешние модели,
  - шаблоны или ручные правила.

- Эти эвристики реализуются как **Labeling Functions (LFs)** — каждая функция выдаёт слабую метку или `None`.

- Затем:
  1. Оценивается точность и коррелированность LFs.
  2. Комбинируются их предсказания (например, через EM или простое голосование).
  3. Получаем **псевдометки** для неразмеченных данных.

---

#### Популярные инструменты:
| Инструмент     | Назначение                                 | Особенности                        |
|----------------|---------------------------------------------|------------------------------------|
| Snorkel        | Фреймворк для weak supervision              | Гибкий, мощный, использует EM      |
| FlyingSquid    | Упрощённый аналог Snorkel                   | Быстрый, без EM                    |
| Snuba          | Генерация LFs на основе размеченной подвыборки | Стартует с label seed              |
