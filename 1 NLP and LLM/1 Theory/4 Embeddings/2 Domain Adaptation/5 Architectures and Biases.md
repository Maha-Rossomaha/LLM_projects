# Architectures and Biases

Адаптация модели к специфике задач — это не только предобучение и fine-tune, но и архитектурные решения, которые внедряют **индуктивные байасы**: структурные ограничения и подсказки, помогающие модели обучаться осмысленно.

---

## 1. Индуктивные байасы: зачем они нужны?

**Индуктивный байас** — это предположение, встроенное в архитектуру или данные, которое направляет модель в сторону более обобщающего решения.

Модель без байаса может «угадывать» на шуме, переобучаться или игнорировать важные паттерны. Байасы сокращают пространство гипотез и **ускоряют сходимость**, **снижают переобучение**, **улучшают генерализацию**.

### Примеры:

- **Симметричный bi-encoder:** enforce $\text{sim}(a, b) = \text{sim}(b, a)$ для задач сопоставления (например, product matching, paraphrase)
- **Аугментации:** равнозначные формы ("1 TB" = "1024 GB", "SSD" = "Solid State Drive") вводятся в данные, чтобы сохранить инвариантность
- **Позитивная разметка через корзину или бренд:** «клавиатура Logitech» и «мышь Logitech» → позитивная пара по корзине
- **Entity-aware encoding:** добавление специальных токенов или embedding-масок для категорий (цена, бренд, дата)
- **Сегментация по шаблонам:** указание структуры входа (заголовок, тело, категории и т.д.) в input-последовательности

---

## 2. Attention over pages (для длинных документов)

### Проблема:

Многостраничные документы (например, PDF на 10–20 страниц) превышают лимит токенов и не могут быть закодированы целиком.

### Решение:

1. Каждая страница передаётся в encoder (например, BERT или LayoutLM) → получается page embedding
2. Все embeddings объединяются через:
   - self-attention (cross-page)
   - mean-pooling с learnable weights
   - recurrent layer (например, LSTM over pages)
3. Получается **вектор всего документа**, учитывающий межстраничные зависимости

### Проблемы и уточнения:

- Если страница — скан, а OCR не сработал → пустой текст → мусорный embedding
- Можно использовать Layout-aware модели (например, LayoutLMv3), которые учитывают bounding boxes
- Можно отдельно обрабатывать OCR confidence и заменять пустые страницы на learnable `[EMPTY]` embedding

### Пример применения:

Классификация сканов судебных решений, где важна не только последняя страница, но весь контекст (истцы, нормы, подписи).

---

## 3. Multi-modal fusion (ResNet + OCR + BERT)

В задачах на сканы, формы, документы с таблицами приходится объединять визуальный и текстовый сигналы.

### Архитектура:

- **ResNet или CNN** извлекает признаки из изображения страницы
- **OCR-модуль** (например, Tesseract или TrOCR) извлекает текст
- **BERT** (или LayoutLM) обрабатывает текст и spatial layout
- **Fusion**: объединение векторов (concatenation, cross-attention, MLP)

### Варианты fusion:

- Early fusion: объединение признаков до encoder'а
- Late fusion: объединение на уровне финальных embeddings
- Cross-modal attention: BERT-контролируемая интеграция визуальных фичей

**Пример:** классификация форм с печатями, подписями, логотипами и таблицами, где важен как текст, так и визуальный стиль.

---

## 4. Entity-aware encoding

Для текстов с таблицами, метаданными, JSON-структурами или шаблонной формой часто полезно явно кодировать **роли и типы сущностей**.

### Способы:

- Дополнительный embedding по типу (price, date, quantity, id)
- Разметка специальных токенов: `<BRAND>`, `<SKU>`, `<DATE>`
- Использование Feature-aware Transformer (интеграция структурных признаков)
- Использование отдельных attention head'ов под разные поля (если известно заранее)

### Применение:

- Табличные данные в e-commerce
- Документы с шаблонной структурой (например, отчёты, карточки товаров, резюме)
- Распознавание и сравнение структурированных текстов
