# MiniLM как Embedder

## Общее описание

**MiniLM** — это компактная encoder-only модель, разработанная Microsoft, которая достигает качества крупных трансформеров при значительно меньшем числе параметров. MiniLM часто используется как embedder для retrieval, кластеризации и других задач, требующих плотных представлений текста.

Главная идея MiniLM — максимально сохранить знания большой teacher-модели (например, BERT-large, RoBERTa-large) при существенном сокращении числа параметров с помощью **knowledge distillation**.

---

## Архитектура и особенности

* **Encoder-only Transformer** с архитектурой, упрощённой по сравнению с BERT: уменьшенное число attention-голов, более компактный скрытый размер, но сохранение глубины и базовых механизмов внимания.
* **Knowledge Distillation**: обучение от крупной teacher-модели (например, BERT-large), при котором MiniLM копирует не только распределения attention, но и внутренние представления скрытых слоёв, чтобы максимально перенять смысловые и синтаксические знания.
* Поддержка как **mean pooling** (усреднение скрытых состояний токенов), так и использования \[CLS]-токена для получения финальных эмбеддингов — выбор зависит от downstream-задачи.
* **Низкие требования к ресурсам**: оптимизирована под работу на CPU и GPU с ограниченной памятью, поддерживает ускорение на мобильных и edge-устройствах.
* Хорошо сочетается с **L2-нормализацией** и **cosine similarity** при поиске и сравнении эмбеддингов, что упрощает интеграцию в retrieval-пайплайны.

---

## Преимущества

* **Компактность**: модели от 22M до 33M параметров, легко разворачиваются на CPU и мобильных устройствах.
* **Скорость**: в 2–3 раза быстрее BERT-base при сопоставимом качестве в ряде задач.
* **Качество**: близкое к teacher-модели благодаря переносу attention-паттернов и внутренних представлений.
* **Универсальность**: применима для retrieval, semantic similarity, классификации, reranking.

---

## Применение

* **Dense retrieval** — в паре с FAISS или Annoy для быстрого поиска.
* **Semantic textual similarity** — вычисление близости предложений и абзацев.
* **Clustering** — тематическая группировка документов.
* **Reranking** — быстрый отбор кандидатов перед подачей в более тяжёлые модели.
* **Edge/On-device NLP** — внедрение в приложения с ограниченными ресурсами.

---

## Варианты моделей

* `MiniLM-L12-H384` — 12 слоёв, скрытый размер 384.
* `MiniLM-L6-H384` — 6 слоёв, скрытый размер 384.
* Версии, дообученные на специальных задачах (например, paraphrase-mpnet-minilm).
