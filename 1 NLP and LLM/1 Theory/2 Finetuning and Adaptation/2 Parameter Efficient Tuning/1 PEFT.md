# Parameter-Efficient Fine-Tuning (PEFT)

## Зачем нужен PEFT?

Файнтюнинг больших языковых моделей (LLM) с миллиардами параметров требует:
- огромных вычислительных ресурсов (GPU-память, время обучения);
- большого объема размеченных данных;
- постоянного переобучения при каждой задаче или домене.

Полный fine-tuning (обновление всех весов модели) становится экономически неэффективным и трудно масштабируемым.

PEFT предлагает альтернативу: адаптировать модель к новой задаче, модальности или домену, **обновляя только небольшую часть параметров**.

## Основная идея
PEFT-методы добавляют или модифицируют небольшие компоненты в модели и обучают **только их**, оставляя основную массу весов неизменной. Это:
- снижает потребление памяти и ускоряет обучение;
- уменьшает риск переобучения;
- позволяет хранить множество адаптаций ("адаптеров") без дублирования всей модели.

## Преимущества
- **Эффективность**: обучаются ≈0.1–2% параметров вместо 100%.
- **Модулярность**: можно легко переключаться между адаптациями.
- **Композиционность**: адаптации можно комбинировать (например, задача + стиль).
- **Легкое внедрение**: достаточно подгрузить адаптер и применить его поверх предобученной модели.

## Области применения
- Кастомизация под конкретного пользователя или заказчика
- Доменная адаптация (например, медицина, право)
- Мультиязычные адаптации
- Мультизадачные пайплайны

## Архитектурная схема (в общем виде)

Модель = (Frozen Backbone) + (PEFT-модуль)  
Обучение: → только параметры PEFT-модуля  
Инференс: → совмещение базовой модели с адаптацией

## Что обычно НЕ входит в PEFT
- Полный fine-tuning
- Quantization (это оптимизация инференса, не адаптации)
- Distillation (сжатие модели, не адаптация)

## Типы PEFT-подходов (обобщенно)
- **Добавление новых обучаемых слоев** (адаптеры, слойные вставки)
- **Модификация существующих весов через low-rank разложения**
- **Mask-based обучение**: выборка подмножества весов для обновления

## Поддержка в инструментах
- [HuggingFace PEFT](https://github.com/huggingface/peft): стандартная библиотека для адаптаций
- Совместим с `transformers`, `accelerate`, `bitsandbytes`, `deepspeed`

## Заключение
PEFT стал индустриальным стандартом для обучения LLM на ограниченных ресурсах. Он позволяет:
- быстро адаптировать большие модели;
- эффективно масштабировать кастомизации;
- снизить стоимость и упростить деплой адаптированных моделей.

Это делает PEFT незаменимым инструментом в современных NLP-проектах, особенно при множестве задач, языков и доменов.

