# Когда выбирать Prefix / P-Tuning, а когда LoRA / QLoRA?

Выбор метода параметро-эффективной адаптации зависит от ограничений инфраструктуры, типа задачи и целей (качество vs ресурсы). Ниже — краткий конспект, в каких случаях что лучше использовать.

---

## Когда выбирать **Prefix Tuning / P-Tuning v2**

### Если:
- Есть **доступ к архитектуре модели** (можно внедряться в attention-слои)
- Модель **используется локально** (не через API)
- Задача — **few-shot обучение** или **крайне мало данных**
- Требуется **предельно дешёвый адаптер** (низкий объём параметров)
- Модель **не может быть перепакована** (например, работает на edge-устройстве)
- Нельзя или неудобно использовать PEFT-инструменты типа `LoRA`, особенно на старых фреймворках или ограниченных средах
- Требуется сохранить **оригинальные веса** полностью неизменными

### Отличия:
- `P-Tuning v2` — более выразителен, влияет и на input, и на attention
- `Prefix Tuning` — проще, чуть экономичнее, но менее гибкий

### Не подходит, если:
- Модель доступна только как API (например, OpenAI или Claude)
- Нельзя внедряться в архитектуру
- Нужна масштабируемая адаптация на десятки задач

---

## Когда выбирать **LoRA / QLoRA**

### Если:
- Нужно адаптировать **среднюю или большую модель** (7B+)
- **Важно качество**, приближенное к full fine-tuning
- Нужно адаптировать **всю модель**, а не только input/attention
- Хочется **гибко настраивать, какие модули адаптировать** (например, только attention или только FFN)
- Планируется **масштабироваться по задачам**: хранить множество адаптеров и подгружать нужный (своп адаптеров)
- Используется **инфраструктура с поддержкой LoRA (например, PEFT)**
- Возможна **перепаковка модели** (перезапись весов, добавление LoRA слоёв)
- Важно **долговременное качество и стабильность адаптации**

### Отличия:
- `LoRA` — добавляет обучаемые low-rank матрицы к слоям модели
- `QLoRA` — то же, но работает с **4-bit квантованной моделью**, ещё сильнее экономит VRAM

### Не подходит, если:
- Модель предоставляется как API
- Нельзя модифицировать структуру модели
- Рабочая среда не позволяет применять LoRA-слои (например, inference-only edge устройства)

---

## Таблица выбора

| Сценарий                                     | Рекомендуемый метод       |
|----------------------------------------------|----------------------------|
| Few-shot обучение / мало данных              | Prefix / P-Tuning v2       |
| Задачи на edge / без модификации модели      | Prefix / P-Tuning v2       |
| Поддержка десятков задач с hot-swapping      | LoRA / QLoRA               |
| Максимальное качество с минимумом затрат     | QLoRA                      |
| Гибкая настройка по слоям                    | LoRA                       |
| Только API-доступ                            | Prompt Engineering         |

---

## Вывод
- **Prefix / P-Tuning v2** — идеальны для ограниченных условий: минимум данных, невозможность модификации модели, работа на edge.
- **LoRA / QLoRA** — лучше, если нужна масштабируемость, гибкость и высокое качество при ограниченных ресурсах, особенно в продакшене.

Если модель «чёрный ящик» — используем prompt tuning. Если модель локальная — P-Tuning v2 или QLoRA дадут почти всё, что даёт full fine-tuning, но за меньшие ресурсы и с возможностью переключения адаптеров.

