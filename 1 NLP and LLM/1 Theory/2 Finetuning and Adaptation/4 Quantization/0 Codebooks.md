# Codebook — построение и хранение (deep dive)

> Подробный конспект о том, **как составляются codebook’и** (таблицы прототипов) при квантизации и **что именно они хранят**. Фокус на LLM/векторной квантизации (VQ, PQ/OPQ, RQ) и практику продакшна.

---

## 0) Термины и нотация

- **Векторная квантизация (VQ)**: заменяем исходный d-мерный вектор \(x\in\mathbb{R}^d\) индексом \(i\in\{1..K\}\), где \(C\in\mathbb{R}^{K\times d}\) — codebook, а \(\hat{x}=C[i]\).
- **Индексные тензоры**: массив целых чисел (обычно `uint8/uint16`) с индексами кодов.
- **PQ (Product Quantization)**: разбиваем \(x\) на \(m\) подвекторов \(x=(x^{(1)},...,x^{(m)})\), у каждого свой codebook \(C^{(j)}\) и индекс \(i_j\).
- **OPQ (Optimized PQ)**: перед PQ применяем обучаемое ортогональное преобразование \(R\) (ротация/whitening) для лучшего разбиения энергии по подпространствам.
- **RQ (Residual Quantization)**: последовательное кодирование остатка: \(r_1=x-C_1[i_1]\), \(r_2=r_1-C_2[i_2]\), и т.д.

---

## 1) Как составляются codebook’и (общая схема)

### 1.1. Сбор данных для обучения квантайзера

Выборка должна репрезентировать **распределение тех векторов**, которые вы будете квантовать в проде.

- **Для весов**: снимки весов целевых слоёв (можно все, можно стратифицированную подвыборку по слоям/каналам).
- **Для активаций**: калибрационная прогонка репрезентативных запросов/батчей.
- **Anti-bias**: не забывайте редкие, но важные паттерны (outliers, длинные контексты, спецязыки).

### 1.2. Предобработка векторов

- **Нормализация**: per-channel или global (z-score, layer norm-like, L2-норма). Часто полезно центрирование \(x\leftarrow x-\mu\).
- **Whitening/Rotation**: для OPQ — обучаем матрицу \(R\) (ортогональную), чтобы разнести коррелированные компоненты по подпространствам.
- **Клиппинг хвостов**: перцентильное (например, 0.1–99.9) для снижения влияния экстремальных выбросов.

### 1.3. Разбиение на блоки (для VQ над весами)

- **Block size / d**: выбираем длину вектора (например, 8/16/32). Для PQ: длина подвектора \(d_{sub}=d_{full}/m\).
- **Группировка**: per-channel, per-row, per-head или fixed-size блоки.

### 1.4. Инициализация codebook

- **k-means++**: устойчивая инициализация центроидов.
- **Random from data**: случайный сэмпл из обучающих векторов.
- **OPQ init**: сначала обучаем \(R\), затем запускаем k-means в повернутом пространстве.

### 1.5. Обучение codebook (классическая VQ)

Основная цель — минимизировать среднеквадратичную ошибку (MSE):

$$
\min_C \; \mathbb{E}_x \; \big\|x - C[\arg\min_i \|x-C[i]\|]\big\|^2
$$

Практически — **k-means / mini-batch k-means**:

1. **Assignment**: каждому вектору присваиваем ближайший код по L2 или косинусу.
2. **Update**: обновляем центроиды как среднее по кластерам.
3. **Repeat**: до сходимости или лимита итераций.

Вариации:

- **Spherical k-means** (косинусная близость, нормировка на L2).
- **k-medians/k-medoids** (устойчивее к выбросам).
- **Hessian-/layer-aware** взвешивание (важные компоненты штрафуются сильнее).

### 1.6. Обучение codebook (VQ-VAE‑семейство)

Используем **обучаемые** codebook’и через градиенты.

- Потери: `recon_loss + β * commitment_loss + codebook_loss`.
- Обновление codebook — через **EMA** счётчиков/сумм (Van den Oord et al.) или straight‑through estimator (STE).
- Плюс: codebook подстраивается под downstream‑задачу (например, под сжатие активаций).

### 1.7. PQ/OPQ

- **PQ**: обучаем \(m\) независимых codebook’ов на подпространствах (обычно mini-batch k-means). Индексы объединяются в «кодовую строку» длиной \(m\).
- **OPQ**: предварительно обучаем ортогональную матрицу \(R\), минимизируя квант. ошибку после ротации: \(\min_{R,\{C^{(j)}\}} \|X - R^T \hat{X}\|^2\).

### 1.8. RQ (Residual Quantization)

- Поэтапно кодируем остаток: первый codebook описывает большую часть энергии, последующие — уточняют. Полезно при сложных распределениях.

### 1.9. Регуляризация и устойчивость

- **Norm constraints**: ограничиваем норму кодов для стабильности.
- **Pruning кодов**: удаляем редко используемые/слившиеся коды.
- **Re-split кластеров**: при коллапсе пересэмплируем проблемные центроиды.

### 1.10. Оценка качества codebook

- **Distortion**: MSE / cosine error на валидации.
- **Task-level**: падение метрик модели (perplexity, accuracy, BLEU, MRR, ROUGE и т.д.).
- **Latency/Throughput**: проверяем выигрыш на целевой железке.

---

## 2) Что именно хранят codebook’и

### 2.1. Основное содержимое

- **Матрица кодов** `C` формы `K×d` (обычно в `float16`/`float32`; для tiny‑девайсов — `int8`/`bfloat16`).
- **(В PQ) Набор из m матриц**: `C^(1) ... C^(m)` с размерами `K×d_sub`.
- **(В RQ) Каскад матриц**: `C_1 ... C_L` для L ступеней резидуального кодирования.

### 2.2. Метаданные квантайзера

- Тип квантизации: VQ/PQ/OPQ/RQ, расстояние (L2/cosine), d, K, m, L.
- Схема разбиения: per-layer/per-channel/per-head/блочная (размер блока, stride, порядок обхода).
- Точность хранения кодов (`fp16/fp32`) и индексов (`uint8/uint16`).
- Для **OPQ**: матрица \(R\) (ортогональная), иногда в `fp16`.
- Для **RQ**: число ступеней L, коэффициенты/веса, если используются.

### 2.3. Статистика и служебные поля (опционально)

- **Гистограмма использования кодов** (для диагностики/энтропийного кодирования).
- **Сид/версия** обучения, контрольные суммы, дата, автор.
- **Сжатие индексов**: RLE/Хаффман/ANS при offline‑хранении.
- **Clip/scale** параметры, если смешиваются с uniform‑квантизацией.

### 2.4. Где физически хранятся

- **On‑disk**: отдельные файлы (например, `layer_X.codebook.bin`) плюс индексы (`layer_X.idx.bin`) или объединённо в контейнер (`safetensors`, `npz`, свой бинарный формат).
- **In‑memory**: загружаются в CPU/GPU RAM; для ускорения — **stage** в on‑chip SRAM/Shared Memory (CUDA) тайлами.
- **Sharding**: при распределённых весах — шардируются по девайсам/ранкам, метаданные содержат mapping.

---

## 3) Индексы и макет памяти

### 3.1. Типы индексов

- **`uint8`** при `K≤256` (частый выбор: K=256 → 8 бит/вектор).
- **`uint16`** при `256<K≤65535`.
- Для **PQ**: вектор индексов длиной \(m\) на каждый исходный блок.

### 3.2. Организация тензоров индексов

- **Row‑major / Column‑major** в зависимости от ядра матмул. Важно, чтобы итерация по индексам соответствовала шаблону доступа к codebook в ядре.
- **Tiling**: индексы упакованы по тайлам (например, `T×B`), чтобы блоки кодов подгружались коалесцированно.
- **Prefetch**: индексы текущего тайла → `__shared__` память, затем lookup кодов в регистры.

### 3.3. Совместное хранение с uniform‑квантизацией

- Могут храниться **scale/zero‑point** (per‑tensor/per‑channel) для смешанных схем (например, VQ на «трудных» каналах, uniform на «простых»).

---

## 4) Сколько codebook’ов и как выбирать конфиг

### 4.1. Типовые паттерны

- **Per‑layer VQ**: один codebook на слой, блоки фикс. длины `d=16/32`, `K=256`.
- **Per‑channel VQ**: отдельный codebook на канал (дороже по памяти метаданных, но выше точность).
- **PQ/OPQ**: `m=4..16`, `K=256` на подпространство, хорошее соотношение «качество/вес индекса». OPQ чаще даёт +0.1–0.5% качества при той же памяти.
- **RQ**: 2–4 ступени дают сильное снижение ошибки без взрыва индексов.

### 4.2. Практические рекомендации для LLM

- Начните с **K=256** (8‑битный индекс) и **d=16/32** для блоков MLP/Attn весов.
- Для KV‑кэша/активаций — используйте **PQ (m=8)**, часто это лучший компромисс.
- Если падает косинусная близость скрытых состояний — попробуйте **OPQ**.
- Outliers: либо отдельный «hi‑precision» путь (int16/FP16), либо гибрид с uniform‑квантованием на «тяжёлых» каналах.

---

## 5) Инференс: путь данных и производительность

1. **Чтение индекса** → 2. **Lookup кода** в `C` (или в `C^(j)` для PQ) → 3. **Реконструкция** вектора (конкатенация/сумма с остатком для RQ) → 4. **Участие в матмул**.

Оптимизации:

- **Hot‑tile staging**: перенос подтаблицы кодов текущего тайла в shared memory.
- **Vectorized loads** (e.g., `ldmatrix`/`ld.global.v4`), выравнивание по 16/32 байтам.
- **Kernel fusion**: объединение lookup + GEMM на тайле.
- **Caching**: L2/Texture cache для повторно используемых кодов.

Бутылочные горлышки — **память/байтовая пропускная**, а не FLOPs. Хорошая укладка и тайлинг дают львиную долю ускорения.

---

## 6) Проверка качества после квантования

- **Layerwise cosine**: cos‑sim до/после на выходах слоёв.
- **E2E‑метрики**: perplexity, exact match, ROUGE/MRR/NDCG — на валидации.
- **Stress‑тесты**: длинные контексты, редкие токены, доменные запросы.
- **Canary‑промпты**: маленький чек‑лист, который гоняется при каждой сборке.

---

## 7) Подводные камни и как их обходить

- **Коллапс кодов**: половина кодов пустует → добавьте re‑init редких центроидов, увеличьте mini‑batch, примените spherical k‑means.
- **Сильные outliers**: выделите отдельный путь/микшируйте с uniform‑квантованием.
- **Неверная выборка калибрации**: берите реальные прод‑распределения (включая длинные запросы и мультиязычность).
- **Переобучение codebook под датасет**: держите hold‑out на прод‑трафике.

---

## 8) Быстрые формулы и оценки

- **Размер codebook (VQ)**: `K × d × bytes_per_code`.
- **Стоимость индексов (VQ)**: `N_blocks × bytes_per_index` (обычно 1 байт при K=256).
- **PQ общий размер кодов**: `m × K × d_sub × bytes`. Индексы: `N_blocks × m × bytes_per_index`.
- **RQ индексы**: `N_blocks × L × bytes_per_index`.

Пример при `K=256, d=16, bytes=2 (fp16)`: один codebook ≈ `256×16×2 = 8 КБ`. Для `m=8` (PQ) — 8 таких таблиц → \~64 КБ.

---

### Итог

**Как составляются**: выбираем репрезентативные данные → предобработка/разбиение → инициализация → k‑means (или VQ‑VAE/OPQ/RQ) → регуляризация → валидация.

**Что хранят**: матрицы кодов (и/или их каскады), метаданные квантайзера, опционально статистику/матрицу OPQ, а также индексы, которые указывают, какой код использован для каждого блока исходных весов/активаций.

