# Pipeline Parallelism

Когда модель слишком большая и **не помещается на одну GPU даже в минимальной конфигурации**, на помощь приходит **pipeline parallelism** — способ разнести модель по устройствам по слоям, а не по данным.

---

## Что такое Pipeline Parallelism

В отличие от **data parallelism** (как в DDP), где каждая GPU получает копию всей модели и свой набор данных, в **pipeline parallelism** модель **разбивается по слоям** между несколькими устройствами. Каждое устройство отвечает за свою часть forward и backward.

> Это как “конвейер”: первый GPU обрабатывает первый блок, передаёт результат второму и т.д. В каждый момент времени разные стадии могут обрабатывать разные микробатчи, что позволяет загружать все GPU одновременно.

Каждый такой блок, закреплённый за одной GPU, называется **stage**. Чем больше стадий — тем сложнее сбалансировать время их исполнения.

---

## Зачем нужен pipeline-parallelism

- **Когда модель не помещается целиком в память одной GPU.**
- **Если у вас несколько GPU с ограниченным объёмом памяти, но вы хотите собрать большую модель.**
- **Когда DDP+checkpointing уже не спасают.**

---

## Плюсы:

- Имея 2 GPU по $N$ GB, можно «собрать» модель, требующую почти $2N$ памяти.
- Позволяет вместить модель, которая **не помещалась целиком** на одну карту — особенно полезно для моделей типа GPT‑3.
- Совместим с gradient checkpointing, mixed precision.

> Однако **если один слой не помещается даже на одну GPU — pipeline тоже не спасёт**.

---

## Минусы:

- Между устройствами нужно пересылать тензоры — это **снижает производительность**.
- Требуется **microbatching**: т.к. каждый GPU работает последовательно, нужен набор микробатчей для заполнения pipeline.
- Поведение похоже на gradient accumulation — без правильного подбора microbatch размер и балансировки может быть **хуже, чем без pipeline**.
- Проблемы с реализацией:
  - **Tied weights** (например, shared embedding/decoder) требуют синхронизации.
  - Тяжело комбинировать с другими типами параллелизма (DDP, tensor/model).
  - **Нужен кастомный код**, особенно если хочется использовать HuggingFace, gradient checkpointing и т.п.
  - **Нагрузку между стадиями нужно балансировать вручную**, иначе узкие места тормозят весь pipeline.

---

## Сравнение с DDP

|                       | DDP                         | Pipeline Parallelism                     |
| --------------------- | --------------------------- | ---------------------------------------- |
| Параллелизм по        | Данных (batch'и)            | Слоям модели                             |
| Память на GPU         | Одинаковая модель на каждой | У каждой GPU — часть модели              |
| Требует microbatching | Нет                         | Да                                       |
| Ускоряет              | Время обучения              | Возможность обучить очень большую модель |
| Типичные проблемы     | Синхронизация градиентов    | Балансировка стейджей, tied weights      |

---

## Как реализуется (PyTorch + пример)

PyTorch предлагает `torch.distributed.pipeline.sync.Pipe`, но он имеет ограничения (например, плохо поддерживает tied weights).

Более гибкий способ — использовать **DeepSpeed** или **FairScale**:

```python
from deepspeed.runtime.pipe import PipelineModule

# Определим слои
layers = [Block1(), Block2(), Block3(), Block4()]

model = PipelineModule(layers=layers, num_stages=2, partition_method="parameters")
```

В этом примере модель разбивается на 2 стадии (например, по 2 блока на каждую GPU). Также потребуется задать `train_micro_batch_size_per_gpu` и `gradient_accumulation_steps` в конфиге DeepSpeed.

---

## Когда использовать

- Когда модель не помещается даже при gradient checkpointing и low precision.
- Когда хочется максимизировать использование нескольких карт с ограниченной памятью.
- Если готовы на компромиссы по коду и производительности ради запуска гигантской модели.

---

## Советы и инструменты

- Используй `pipeline_depth == microbatch_count` — это позволяет достичь полной загрузки всех стадий.
- Балансируй количество слоёв и их вычислительную сложность по стадиям вручную (или по профилю времени).
- Учитывай, что разные слои (например, attention vs feedforward) могут требовать разное время и память.
- У DeepSpeed есть [официальная документация](https://www.deepspeed.ai/tutorials/pipeline/) по pipeline parallelism.

---

## Вывод

**Pipeline parallelism** позволяет **разнести слои модели** между устройствами и обучать модели, которые иначе бы не влезли никуда. Но требует аккуратной настройки микробатчей, баланса слоёв и нередко — собственного кода. В большинстве случаев стоит попробовать сначала DDP + gradient checkpointing + quantization, и только потом переходить к pipeline.

