# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤: Encoder‚Äëonly, Decoder‚Äëonly –∏ Encoder‚ÄëDecoder

URL:  
üîó [HF Encoder-Decoder](https://huggingface.co/learn/llm-course/en/chapter1/6)  

## 1. Encoder‚Äëonly

**–û–ø–∏—Å–∞–Ω–∏–µ:**  
–°–æ—Å—Ç–æ–∏—Ç —Ç–æ–ª—å–∫–æ –∏–∑ —ç–Ω–∫–æ–¥–µ—Ä–Ω—ã—Ö —Å–ª–æ—ë–≤ ‚Äî –º–Ω–æ–≥–æ–≥–æ–ª–æ–≤–æ–µ self-attention bidirectional, –±–µ–∑ –º–∞—Å–∫–∏. –ü—Ä–∏–º–µ—Ä: BERT.

**–û–±—É—á–µ–Ω–∏–µ:**  
- –ú–∞—Å–∫–∏—Ä–æ–≤–∫–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ (Masked LM):  
$$
\mathcal{L}_{MLM} = -\sum_{t \in M} \log P(x_t | x_{\setminus M})
$$  
- –í–æ–∑–º–æ–∂–Ω–∞—è Next Sentence Prediction.

**–ü–ª—é—Å—ã:**  
- –ì–ª—É–±–æ–∫–æ–µ –¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ.  
- –í—ã—Å–æ–∫–∞—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –Ω–∞ GLUE/SuperGLUE: –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–æ–π NLU-–∫–∞—á–µ—Å—Ç–≤–µ.

**–ú–∏–Ω—É—Å—ã:**  
- –ù–µ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–æ –¥–ª—è –∞–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞.  
- –°—Ç–µ–∫ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π ‚Üí —Ç—Ä–µ–±—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π –¥–µ–∫–æ–¥–µ—Ä –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á.

---

## 2. Decoder‚Äëonly

**–û–ø–∏—Å–∞–Ω–∏–µ:**  
–¢–æ–ª—å–∫–æ causal self‚Äëattention: –∫–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–∏—Ö. –ü—Ä–∏–º–µ—Ä—ã: GPT‚Äë—Å–µ—Ä–∏—è, LLaMA.

**–û–±—É—á–µ–Ω–∏–µ:**  
- Causal LM:  
$$
\mathcal{L}_{CLM} = -\sum_{t} \log P(x_t \mid x_{<t})
$$

**–ü–ª—é—Å—ã:**  
- –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞, –ø—Ä–æ—Å—Ç–æ—Ç–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞.  
- –û—Ç–ª–∏—á–Ω–∞—è zero‚Äë/few‚Äëshot –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ generalization.

**–ú–∏–Ω—É—Å—ã:**  
- –û–±—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ ‚Üí –º–µ–Ω–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ.  
- –î–ª—è NLU- –∏ —Ç—Ä–∞–Ω—Å—Ñ–µ—Ä–Ω—ã—Ö –∑–∞–¥–∞—á —Ç—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.

---

## 3. Encoder‚ÄëDecoder (Seq2Seq)

**–û–ø–∏—Å–∞–Ω–∏–µ:**  
–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è seq2seq: —ç–Ω–∫–æ–¥–µ—Ä + –¥–µ–∫–æ–¥–µ—Ä —Å cross-attention. –ü—Ä–∏–º–µ—Ä—ã: T5, BART.

**–û–±—É—á–µ–Ω–∏–µ:**  
- –ú–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ö–æ–¥–∞ –∏ —Ü–µ–ª—å –Ω–∞ output; –º–æ–∂–µ—Ç –±—ã—Ç—å span-masked.  
$$
\mathcal{L}_{Seq2Seq} = -\sum_t \log P(y_t \mid y_{<t}, EncoderOutput(x))
$$

**–ü–ª—é—Å—ã:**  
- –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ—Å—Ç—å: –ø–µ—Ä–µ–≤–æ–¥, —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è, Q&A.  
- –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ causal‚ÄëLM –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –∏ –∏–Ω–æ–≥–¥–∞ –±—ã—Å—Ç—Ä–µ–µ –Ω–∞ edge (–º–µ–Ω—å—à–µ latency / throughput).

**–ú–∏–Ω—É—Å—ã:**  
- –°–ª–æ–∂–Ω–µ–µ –∏ —Ä–µ—Å—É—Ä—Å–æ–∑–∞—Ç—Ä–∞—Ç–Ω–µ–µ.  
- –¢—Ä–µ–±—É–µ—Ç —Ä–∞–∑–º–µ—Ç–∫–∏ –ø–∞—Ä ¬´–≤—Ö–æ–¥‚Üí–≤—ã—Ö–æ–¥¬ª.

---

## 4. –§–æ—Ä–º—É–ª—ã –≤ —Ä–µ–∑—é–º–µ

- **Encoder‚Äëonly (MLM):**  
  $\mathcal{L}_{MLM} = -\sum_{t \in M} \log P(x_t \mid x_{\setminus M})$
- **Decoder‚Äëonly (CLM):**  
  $\mathcal{L}_{CLM} = -\sum_{t} \log P(x_t \mid x_{<t})$
- **Encoder‚ÄëDecoder (seq2seq):**  
  $\mathcal{L}_{Seq2Seq} = -\sum_{t} \log P(y_t \mid y_{<t}, Encoder(x))$

---

## 5. –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞

| –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞         | –ö–æ–Ω—Ç–µ–∫—Å—Ç            | –ì–µ–Ω–µ—Ä–∞—Ü–∏—è | –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ                                 | –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å/–°–ª–æ–∂–Ω–æ—Å—Ç—å              |
|---------------------|---------------------|-----------|--------------------------------------------|--------------------------------------|
| **Encoder‚Äëonly**    | –¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π     | –Ω–µ—Ç         | –ü–æ–Ω–∏–º–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞, –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, NLU       | –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ, NLU‚Äë—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ |
| **Decoder‚Äëonly**    | —Ç–æ–ª—å–∫–æ –ø—Ä–æ—à–ª–æ–µ      | –¥–∞        | –ì–µ–Ω–µ—Ä–∞—Ü–∏—è, zero-/few-shot, —á–∞—Ç—ã, –∫–æ–¥       | –ü—Ä–æ—Å—Ç–æ–µ, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤       |
| **Encoder‚ÄëDecoder** | –ø–æ–ª–Ω—ã–π –≤—Ö–æ–¥ + –ø—Ä–æ—à–ª–æ–µ | –¥–∞       | –ü–µ—Ä–µ–≤–æ–¥, —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è, Q&A, seq2seq‚Äë–∑–∞–¥–∞—á–∏ | –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ, –Ω–æ —Ä–µ—Å—É—Ä—Å–æ–µ–º–∫–æ        |

---

### 6. –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º –∏ latency
–ü–∞—Ä–∞ ¬´–ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º ‚áÑ latency¬ª ‚Äî —ç—Ç–æ —Å–≤–æ–µ–≥–æ —Ä–æ–¥–∞ —Ä—ã—á–∞–≥, –∫–æ—Ç–æ—Ä—ã–º –º—ã —É–ø—Ä–∞–≤–ª—è–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å—é –æ–±—É—á–µ–Ω–∏—è –∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤. –ù–∏–∂–µ —Ä–∞–∑–±–µ—Ä—ë–º, –∫–∞–∫–∏–µ –≤–∏–¥—ã –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞ —Å—É—â–µ—Å—Ç–≤—É—é—Ç, –∫–∞–∫ –æ–Ω–∏ –±—å—é—Ç –ø–æ –∑–∞–¥–µ—Ä–∂–∫–µ (–∏–ª–∏ —ç–∫–æ–Ω–æ–º—è—Ç –µ—ë), –∏ –ø–æ—á–µ–º—É —Ä–∞–∑–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (encoder-only, decoder-only, encoder-decoder) –≤–µ–¥—É—Ç —Å–µ–±—è –ø–æ-—Ä–∞–∑–Ω–æ–º—É

#### 6.1 –ß—Ç–æ —Ç–∞–∫–æ–µ ¬´latency¬ª –∏ –ø–æ—á–µ–º—É –æ–Ω–∞ —Ä–∞–∑–Ω–∞—è
| –≠—Ç–∞–ø                           | Encoder-only                       | Decoder-only                                                          | Encoder-decoder                               |
| ------------------------------ | ---------------------------------- | --------------------------------------------------------------------- | --------------------------------------------- |
| **Training** (teacher forcing) | –≤—Å–µ –ø–æ–∑–∏—Ü–∏–∏ —Å—á–∏—Ç–∞—é—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ  | —Ç–æ–∂–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ, —Ç.–∫. —Ä–µ–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –∏–∑–≤–µ—Å—Ç–Ω—ã                       | —ç–Ω–∫–æ–¥–µ—Ä ‚Äî –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ, –¥–µ–∫–æ–¥–µ—Ä ‚Äî –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ  |
| **Inference**                  | –æ–¥–Ω–∞ ¬´–ø–ª–æ—Å–∫–∞—è¬ª –ø—Ä–æ–≥–æ–Ω–∫–∞ ‚Üí $O(L)$ | –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏—è: —Ç–æ–∫–µ–Ω ‚Üí KV-–∫—ç—à ‚Üí —Å–ª–µ–¥—É—é—â–∏–π ‚Äî $O(L\cdot N_{layers})$ | —ç–Ω–∫–æ–¥–µ—Ä (1 –ø—Ä–æ—Ö–æ–¥) + –∞–≤—Ç–æ—Ä–µ–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –¥–µ–∫–æ–¥–µ—Ä |
| **First-token latency**        | ‚âà encoder-pass                     | –≤—ã—Å–æ–∫–∞ –∏–∑-–∑–∞ –ø–µ—Ä–≤–æ–≥–æ –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–æ—Ö–æ–¥–∞                                  | —Å—Ä–µ–¥–Ω—è—è: —ç–Ω–∫–æ–¥–µ—Ä + –æ–¥–∏–Ω —Ç–æ–∫–µ–Ω                 |

Encoder-only –º–æ–¥–µ–ª–∏ —Å—á–∏—Ç—ã–≤–∞—é—Ç –≤—Å—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å—Ä–∞–∑—É, –ø–æ—ç—Ç–æ–º—É –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –∑–∞–¥–µ—Ä–∂–∫–∞ –ª–∏–Ω–µ–π–Ω–æ —Ä–∞—Å—Ç—ë—Ç —Ç–æ–ª—å–∫–æ —Å –¥–ª–∏–Ω–æ–π –≤—Ö–æ–¥–∞. Decoder-only –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–æ–∫–µ–Ω—ã –ø–æ –æ–¥–Ω–æ–º—É; –∏—Ç–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ü–∏–∫–ª —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è ¬´–≥–æ—Ä–ª—ã—à–∫–æ–º¬ª –¥–ª—è latency. Encoder-decoder –∫–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç –æ–±–∞ –º–∏—Ä–∞: –±—ã—Å—Ç—Ä—ã–π —ç–Ω–∫–æ–¥–µ—Ä –∏ –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω—ã–π –¥–µ–∫–æ–¥–µ—Ä.



---

### 7. –ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å?

- **NLU —Ç–æ–ª—å–∫–æ:** –±–µ—Ä—ë–º encoder-only (BERT‚Äë–ø–æ–¥–æ–±–Ω—ã–µ).
- **–¢–æ–ª—å–∫–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è:** decoder‚Äëonly (GPT‚Äë–ø–æ–¥–æ–±–Ω—ã–µ).
- **–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞:** encoder-decoder (T5/BART).
