# LLama3_1 Architecture  
URL: https://ai.meta.com/blog/meta-llama-3-1/

---

## 1. Модельный ряд  
| Модель | Параметров | Контекст | Предназначение | Аппаратные требования (инф.) |  
|-------|------------|----------|----------------|------------------------------|  
| Llama 3.1 8B / 8B‑Instruct | 8 B | 128 K | Встраивание на CPU/GPU, локальный inference | 1× A100 80GB (FP16) или ≈24 GB GPU при 4‑бит Quant |  
| Llama 3.1 70B / 70B‑Instruct | 70 B | 128 K | Продакш‑RAG, кодовая генерация | 4× H100 80GB (FP16) или 64 GB GPU (8‑bit) |  
| **Llama 3.1 405B / 405B‑Instruct** | 405 B | 128 K | Frontier‑исследования, генерация синт. данных | *Квантизация FP8* позволяет запускать на 1 узле с 8×H100 80GB |  

## 1.1 Базовая vs Instruct — в чём разница?  

| Характеристика | **Base (pretrained)** | **Instruct (SFT + DPO)** |
|----------------|-----------------------|--------------------------|
| Цель | Универсальное языковое моделирование | Следование инструкциям пользователя |
| Фаза пост‑тюна | Нет (только pretrain) | ① Supervised Fine‑Tuning (SFT) на 1.8 М задач ② Alignment DPO/RL | 
| Формат ввода | Сырые токены | Chat‑формат с ролями *system/user/assistant* |
| Безопасность | Минимальная | Llama Guard 3 + Refusals |

> *Инструкт‑версии показывают рост +3–5 pp против эквивалентных Llama 3 моделей при тех же 8 B/70 B.*  

## 2. Архитектура и обучение — детально  

### 2.1 Архитектура ядра  
- **Decoder‑only Transformer** без Mixture‑of‑Experts; плотная матрица = простой инференс‑стек.  
  >**Проще говоря**:
  Модель целиком построена на стандартных, одинаковых слоях-«кирпичиках». В каждом слой — только одна обычная («плотная») матрица параметров, поэтому при инференсе (генерации ответа) данные просто проходят через одинаковую цепочку блоков без каких-либо переключателей или «распределителей» нагрузки. Это делает запуск модели предсказуемо-линейным и избавляет от дополнительной логики маршрутизации, которая бывает в более сложных архитектурах.
- **Стек на 126 слоёв (405B)**:  
  - $d_{model} = 16\,384$, $n_{heads} = 128$, FFN ratio ≈ 4 (используется SwiGLU).  
  - **RMSNorm** перед каждым блоком Self‑Attention и MLP.  
  - **Grouped‑Query Attention (GQA)** для стабильной памяти при 128 K контексте.  
  - **Rotary Positional Embeddings (RoPE) + NTK scaling** → линейный рост окна до 128 K без дообучения.  
  - **FlashAttention‑v2** и FP8 матмнож → 1.9× throughput vs Llama 3.  

### 2.2 Процесс обучения  
1. **Pre‑train**: autoregressive присказка на 15 T токенов, batch ≈ 65 M токенов, AdamW β=(0.9,0.95), lr 3e‑4 с cosine‑decay.  
2. **Long‑context stage**: 6 градаций (4 K→128 K) с mix‑context sampling.  
3. **SFT** *(Instruct only)*: 1.8 M человеческих и синтетических задач.  
4. **Alignment**: Direct Preference Optimization (DPO) c β = 0.1 и выборками $(x,y^+,y^-)$ из 180 K пар.  

### 2.3 Функции потерь  
- **Предобучение**: стандартная кроссэнтропия  

  $$L_{CE} = -\sum_{t=1}^{T} \log p_\theta(x_t \mid x_{<t})$$  

- **DPO‑выравнивание**: оптимизация вероятностного преимущества «хорошего» ответа $y^+$ над «плохим» $y^-$  

  $$L_{DPO} = -\log \sigma\Bigl( \beta \bigl[ \log p_\theta(y^{+}\mid x) - \log p_\theta(y^{-}\mid x) \bigr] \Bigr)$$  

  где $\sigma$ — сигмоида, $\beta$ — температурный гиперпараметр.  


## 3. Обучение и данные  
- **Общий объём данных: ≈15 трлн токенов** публичного текста.  
- **Баланс датасета** (после фильтрации и микса):  
  - 50 % — general knowledge  
  - 25 % — math & reasoning  
  - 17 % — code  
  - 8 % — multilingual  
- Многошаговый пайплайн: начальный претрейн → long‑context pretrain (6 градаций контекста) → annealing на «лучших» 40 М токенов.  
- **Пост‑тренинг**: 6 раундов SFT + RL‑поиск (DPO), активное использование синтетики и rejection sampling c reward‑моделью.  

## 4. Технические улучшения  
| Область | Что изменилось | Польза |  
|---------|----------------|--------|  
| Tokenizer | Новая живая BPE с 32 к токенов, оптимизирована под 8 языков | +точность, +скорость |  
| Контекст | Rotary + NTK scaling; long‑context pre‑train | 128 K без «провала» качества |  
| Числовые форматы | FP8 quant для 405B | 2× меньше памяти vs BF16 |  
| Безопасность | Llama Guard 3, Prompt Guard, Safety‑RL | Снижение токсичности/PII |  
| Лицензия | Разрешён повторный use output для тренировки | Легальный data‑distillation |  
