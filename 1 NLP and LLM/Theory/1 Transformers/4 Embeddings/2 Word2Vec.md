## –ö–æ–Ω—Å–ø–µ–∫—Ç: Word2Vec ‚Äî —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ, —Å—É—Ç—å –∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ Python

URL:  
üîó [Word2Vec](https://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)

## 1. –ó–∞—á–µ–º –Ω—É–∂–µ–Ω Word2Vec
Word2Vec –æ–±—É—á–∞–µ—Ç –ø–ª–æ—Ç–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã —Å–ª–æ–≤, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏ –±–ª–∏–∑–∫–∏–µ —Å–ª–æ–≤–∞ —Ä–∞—Å–ø–æ–ª–∞–≥–∞—é—Ç—Å—è —Ä—è–¥–æ–º, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª—è–º —É—á–∏—Ç—ã–≤–∞—Ç—å —Å–º—ã—Å–ª–æ–≤—ã–µ —Å–≤—è–∑–∏ –∏ —É–ª—É—á—à–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∑–∞–¥–∞—á–∞—Ö –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏, –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, –ø–µ—Ä–µ–≤–æ–¥–∞ –∏ –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–æ–≥–∏–π.

## 2. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏

### 2.1 CBOW –∏ Skip‚ÄëGram
- **CBOW (Continuous Bag‚Äëof‚ÄëWords)** –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ —Å–ª–æ–≤–æ –ø–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–æ–∫—Ä—É–∂–∞—é—â–∏—Ö —Å–ª–æ–≤) –∏ –º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç –∫—Ä–æ—Å—Å‚Äë—ç–Ω—Ç—Ä–æ–ø–∏—é –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏.
- **Skip‚ÄëGram** –æ–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–º—É —Å–ª–æ–≤—É, —á—Ç–æ –¥–∞—ë—Ç –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Ä–µ–¥–∫–∏—Ö —Å–ª–æ–≤.

### 2.2 Negative Sampling –∏ Hierarchical Softmax
- **Hierarchical Softmax** —Å—Ç—Ä–æ–∏—Ç –¥–µ—Ä–µ–≤–æ –•–∞—Ñ—Ñ–º–∞–Ω–∞ –Ω–∞–¥ —Å–ª–æ–≤–∞—Ä—ë–º –∏ –≤—ã—á–∏—Å–ª—è–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ª–æ–≤–∞ –ø–æ –ø—É—Ç–∏ –≤ –¥–µ—Ä–µ–≤–µ, —É—Å–∫–æ—Ä—è—è –æ–±—É—á–µ–Ω–∏–µ –¥–æ O(log V).
- **Negative Sampling** –∑–∞–º–µ–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π softmax –Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ ¬´—Å–ª–æ–≤–æ‚Äì–∫–æ–Ω—Ç–µ–∫—Å—Ç¬ª –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª—É—á–∞–π–Ω—ã—Ö –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ä.

## 3. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å –Ω—É–ª—è
```python
import numpy as np

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
V, D = vocab_size, emb_dim
W = np.random.randn(V, D)      # —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–ª–æ–≤
Wc = np.random.randn(V, D)     # —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

# Softmax-—Ñ—É–Ω–∫—Ü–∏—è
def softmax(x):
    e = np.exp(x - np.max(x))
    return e / e.sum()

# –£–ø—Ä–æ—â—ë–Ω–Ω—ã–π Skip‚ÄëGram –±–µ–∑ Negative Sampling
def train_skipgram(center, context, lr):
    v_c = W[center]
    scores = Wc @ v_c
    probs = softmax(scores)
    for i in range(V):
        label = 1 if i in context else 0
        e = probs[i] - label
        Wc[i] -= lr * e * v_c
        W[center] -= lr * e * Wc[i]
```

## 4. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Gensim
```python
from gensim.models import Word2Vec

model = Word2Vec(
    sentences=corpus,
    vector_size=100,
    window=5,
    min_count=5,
    sg=1,        # 1 = Skip‚ÄëGram, 0 = CBOW
    negative=10,
    epochs=5
)
vectors = model.wv
```  

## 6. –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
- GoogleNews-vectors (3‚ÄØ–º–ª–Ω —Å–ª–æ–≤, 300‚ÄØdim) –º–æ–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —á–µ—Ä–µ–∑ Gensim:
  ```python
  from gensim.models import KeyedVectors
  model = KeyedVectors.load_word2vec_format(
      'GoogleNews-vectors-negative300.bin', binary=True
  )
  ```
- TensorFlow Hub –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –º–æ–¥—É–ª–∏ —Å –≥–æ—Ç–æ–≤—ã–º–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏.