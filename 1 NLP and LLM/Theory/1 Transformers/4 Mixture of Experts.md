# –ö–æ–Ω—Å–ø–µ–∫—Ç ¬´Mixture of Experts (MoE)¬ª  
URL:  
üîó [Mixture of Experts Explained](https://huggingface.co/blog/moe)  
üîó [A Visual Guide to MoE](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts)  
üîó [Understanding Mixture of Experts: Building a MoE Model with PyTorch](https://medium.com/@prateeksikdar/understanding-mixture-of-experts-building-a-moe-model-with-pytorch-dd373d9db81c)
> **–ö–æ—Ä–æ—Ç–∫–æ:** MoE¬†‚Äî —ç—Ç–æ —Å–ø–æ—Å–æ–± ¬´—Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ–≥–æ¬ª –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤: –∫–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω –ø—Ä–æ—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ –Ω–µ–±–æ–ª—å—à–æ–π –ø–æ–¥‚Äë–Ω–∞–±–æ—Ä *—ç–∫—Å–ø–µ—Ä—Ç–æ–≤* (—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö FFN‚Äë–≤–µ—Ç–æ–∫), –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö *—Ä–æ—É—Ç–µ—Ä–æ–º*. –ë–ª–∞–≥–æ–¥–∞—Ä—è —ç—Ç–æ–º—É –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤¬†‚Äî –≤—Å–µ–≥–æ 10‚Äì20‚ÄØ% –æ—Ç –æ–±—â–µ–≥–æ —á–∏—Å–ª–∞, —á—Ç–æ –¥–∞—ë—Ç –ø–æ—á—Ç–∏ –ª–∏–Ω–µ–π–Ω—É—é —ç–∫–æ–Ω–æ–º–∏—é FLOP –±–µ–∑ —É—Ö—É–¥—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞.  

---

## 1. –°—É—Ç—å –∏–¥–µ–∏  
* –ü–ª–æ—Ç–Ω–∞—è LLM —Ç—Ä–∞—Ç–∏—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –∫–∞–∂–¥–æ–º —Å–ª–æ–µ.  
* –í¬†MoE‚Äë—Å–ª–æ–µ –µ—Å—Ç—å $E$ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö **—ç–∫—Å–ø–µ—Ä—Ç–æ–≤**; —Ä–æ—É—Ç–µ—Ä –æ—Ü–µ–Ω–∫–æ–π $p_i$ –≤—ã–±–∏—Ä–∞–µ—Ç —Ç–æ–ø‚Äë$k$ (–æ–±—ã—á–Ω–æ¬†1‚Äì2) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞.   
* –í –∏—Ç–æ–≥–µ –Ω–∞ —Ç–æ–∫–µ–Ω –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç—Å—è –ª–∏—à—å $\frac{k}{E}$ —á–∞—Å—Ç–∏ –≤–µ—Å–∞, –Ω–æ —Å—É–º–º–∞—Ä–Ω–∞—è ¬´–ø–∞–º—è—Ç—å¬ª –º–æ–¥–µ–ª–∏ —Ä–∞—Å—Ç—ë—Ç –ª–∏–Ω–µ–π–Ω–æ —Å —á–∏—Å–ª–æ–º —ç–∫—Å–ø–µ—Ä—Ç–æ–≤.  

---

## 2. –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã  

### 2.1 –≠–∫—Å–ø–µ—Ä—Ç—ã  
–ö–∞–∂–¥—ã–π —ç–∫—Å–ø–µ—Ä—Ç¬†‚Äî —ç—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π FFN —Å–æ SwiGLU (–∏–ª–∏ ReLU), –Ω–æ –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ *–ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ* —Ç–æ–∫–µ–Ω–æ–≤, —Ñ–æ—Ä–º–∏—Ä—É—è ¬´—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é¬ª (–∫–æ–¥, –º–∞—Ç–µ–º–∞—Ç–∏–∫–∞, –¥–∏–∞–ª–æ–≥–∏).  

### 2.2 –†–æ—É—Ç–µ—Ä  
* –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è (softmax –ø–æ $E$) –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤—ã–±–æ—Ä–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤.  
* –ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è *Top‚Äëk* –æ–±—Ä–µ–∑–∫–∞ (–æ–±—ã—á–Ω–æ $k=2$) + *capacity factor* —á—Ç–æ–±—ã –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –æ—á–µ—Ä–µ–¥—å —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ —ç–∫—Å–ø–µ—Ä—Ç–∞ –∏ –∏–∑–±–µ–∂–∞—Ç—å ¬´–ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è¬ª.   

### 2.3 –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –ª–æ—Å—Å—ã  
* **Load‚Äëbalancing loss**: –∑–∞—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–æ—É—Ç–µ—Ä —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—Ç—å —Ç–æ–∫–µ–Ω—ã, –º–∏–Ω–∏–º–∏–∑–∏—Ä—É—è –¥–∏—Å–ø–µ—Ä—Å–∏—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.  
* **Z‚Äëloss / Entropy loss**: —Å–≥–ª–∞–∂–∏–≤–∞–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, —Å–Ω–∏–∂–∞—è ¬´–º—ë—Ä—Ç–≤—ã—Ö¬ª —ç–∫—Å–ø–µ—Ä—Ç–æ–≤.   

---

## 3. –û–±—É—á–µ–Ω–∏–µ  

| –≠—Ç–∞–ø | –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç | –°–ª–æ–∂–Ω–æ—Å—Ç—å |  
|------|----------------|-----------|  
| Pre‚Äëtrain | –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π next‚Äëtoken loss + aux‚Äëbalance | –¢—Ä–µ–±—É–µ—Ç –∫–ª–∞—Å—Ç–µ—Ä NCCL‚Äëfriendly (–º–Ω–æ–≥–æ all‚Äëto‚Äëall)  |  
| Fine‚Äëtune | –ú–æ–∂–Ω–æ ¬´–∑–∞–º–æ—Ä–∞–∂–∏–≤–∞—Ç—å¬ª —ç–∫—Å–ø–µ—Ä—Ç—ã –∏ –æ–±—É—á–∞—Ç—å —Ä–æ—É—Ç–µ—Ä, –ø–æ–ª—É—á–∞—è –ª—ë–≥–∫—É—é –∞–¥–∞–ø—Ç–∞—Ü–∏—é |  |  
| Distillation | Dense‚Äë—Å—Ç—É–¥–µ–Ω—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, 7B) –ø–æ–≥–ª–æ—â–∞–µ—Ç –∑–Ω–∞–Ω–∏—è MoE‚Äë—É—á–∏—Ç–µ–ª—è | –°–Ω–∏–∂–∞–µ—Ç latency –Ω–∞ inference  |  

---

## 4. –ü–ª—é—Å—ã –∏ –º–∏–Ω—É—Å—ã  

| –ü–ª—é—Å—ã | –ú–∏–Ω—É—Å—ã |  
|-------|--------|  
| $\sim10\times$ –±–æ–ª—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ¬´–≤ –ø–∞–º—è—Ç–∏¬ª –ø—Ä–∏ —Ç–æ–º –∂–µ FLOP | –°–ª–æ–∂–Ω—ã–π all‚Äëto‚Äëall ‚Üí —Å–µ—Ç–µ–≤–æ–π bottleneck |  
| –õ–µ–≥–∫–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å, –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ | ¬´–ò–≥—Ä–∞¬ª —Å capacity‚Äëfactor –∏–Ω–∞—á–µ —Ç–æ–∫–µ–Ω—ã –¥—Ä–æ–ø–∞—é—Ç—Å—è  |  
| –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ —É–ª—É—á—à–∞–µ—Ç zero‚Äëshot reasoning | –°–ª–æ–∂–Ω–µ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—å —á–µ–∫–ø–æ–π–Ω—Ç—ã (ROUTER seed) |  
| –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –≥–∏–±—Ä–∏–¥–Ω—ã—Ö –∑–∞–¥–∞—á (–≤–∏–∑—É–∞–ª/—Ç–µ–∫—Å—Ç) —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω—ã–µ –ø—É–ª—ã —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ | |  

---

## 5. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã (–∏–∑ —Å—Ç–∞—Ç–µ–π)  
1. **k=1 vs k=2**: –æ–¥–∏–Ω —ç–∫—Å–ø–µ—Ä—Ç –±—ã—Å—Ç—Ä–µ–µ –∏ –ø—Ä–æ—â–µ, –¥–≤–∞¬†‚Äî –≤—ã—à–µ –∫–∞—á–µ—Å—Ç–≤–æ, –Ω–æ —É–¥–≤–∞–∏–≤–∞–µ—Ç –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—é.   
2. **Capacity factor¬†1.25**¬†‚Äî —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–π –±–∞–ª–∞–Ω—Å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–π.   
3. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ **FP8 / INT4** –∫ –∞–∫—Ç–∏–≤–Ω—ã–º –≤–µ—Å–∞–º –¥–∞—ë—Ç –≤—ã–∏–≥—Ä—ã—à –≤ –ø–∞–º—è—Ç–∏ –±–µ–∑ –∑–∞–º–µ—Ç–Ω–æ–π –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏.   
4. –ù–∞ inference –º–æ–∂–Ω–æ ¬´–∑–∞–∫—ç—à–∏—Ä–æ–≤–∞—Ç—å¬ª —Ä–æ—É—Ç–µ—Ä‚Äë–≤—ã–±–æ—Ä –¥–ª—è —Å—Ç–∞—Ç–∏—á–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤, —Å–Ω–∏–∂–∞—è latency.   

---

## 6. –ö–ª—é—á–µ–≤—ã–µ —Ñ–æ—Ä–º—É–ª—ã  

**–†–æ—É—Ç‚Äë–ª–æ–≥–∏—Ç—ã:** $z = W_r h$  

**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏:** $p = \text{softmax}(z)$  

**Top‚Äëk mask:**  
$$m_i = \begin{cases}1, & p_i \in \text{top‚Äëk}\\0,&\text{–∏–Ω–∞—á–µ}\end{cases}$$  

**Load‚Äëbalancing loss:**  
$$L_{lb} = E \sum_j q_j \log q_j,\quad q_j = \frac{n_j}{\sum_k n_k}$$  

–≥–¥–µ $n_j$ ‚Äî —á–∏—Å–ª–æ —Ç–æ–∫–µ–Ω–æ–≤, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö –∫ —ç–∫—Å–ø–µ—Ä—Ç—É¬†$j$.   

---

## 7. –†–µ—Ü–µ–ø—Ç ¬´–ú–∏–Ω–∏‚ÄëMoE¬ª (–ø–æ Medium)  

### 2.1 4 —à–∞–≥–∞ –∫ —Ä–∞–±–æ—á–µ–º—É –±–ª–æ–∫—É  
1. **–≠–∫—Å–ø–µ—Ä—Ç—ã**: N¬†–ª–∏–Ω–µ–π–Ω—ã—Ö FFN‚Äë–≤–µ—Ç–æ–∫ —Å SwiGLU.   
2. **–ì–µ–π—Ç**: $p=\text{softmax}(W_r h)$, –≤—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø‚Äë$k=2$, –ø—Ä–∏–º–µ–Ω—è–µ–º capacity‚Äëfactor¬†1.25.  
3. **–°–±–æ—Ä–∫–∞**: —Ä–∞—Å—Å—ã–ª–∞–µ–º —Ç–æ–∫–µ–Ω—ã –ø–æ —ç–∫—Å–ø–µ—Ä—Ç–∞–º (scatter) ‚Üí –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º ‚Üí —Å–æ–±–∏—Ä–∞–µ–º (gather).  
4. **Aux‚Äëloss**: load‚Äëbalancing + —ç–Ω—Ç—Ä–æ–ø–∏—è, —á—Ç–æ–±—ã —ç–∫—Å–ø–µ—Ä—Ç—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ.   

### 2.2 –ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞   
```python
import torch, torch.nn as nn
import torch.nn.functional as F

class FFN(nn.Module):
    """
    –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π FFN-–±–ª–æ–∫ Transformer-–¥–µ–∫–æ–¥–µ—Ä–∞ (SwiGLU –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é).
    """
    def __init__(self, d_model: int, d_ff: int):
        super().__init__()
        self.w1   = nn.Linear(d_model, d_ff * 2) # ‚Üí2√ó –¥–ª—è SwiGLU
        self.w2   = nn.Linear(d_ff, d_model)

    def forward(self, x):
        a, b = self.w1(x).chunk(2, dim=-1) # SwiGLU
        return self.w2(F.silu(a) * b)


class MoEBlock(nn.Module):
    """
    Mixture-of-Experts-—Å–ª–æ–π (Top-k Gating) –±–µ–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–≥–æ all-to-all,
    –ø—Ä–∏–≥–æ–¥–Ω—ã–π –¥–ª—è CPU / –æ–¥–Ω–æ–π GPU. –í DeepSpeed —ç—Ç–∞ –ª–æ–≥–∏–∫–∞ ¬´–∑–∞—à–∏—Ç–∞¬ª –≤ CUDA-—è–¥—Ä–∞.
    """
    def __init__(
        self,
        d_model:   int  = 4096,
        d_ff:      int  = 14336,
        experts:   int  = 16,
        top_k:     int  = 2,
        capacity:  float = 1.25, # –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç ¬´—ë–º–∫–æ—Å—Ç–∏¬ª —ç–∫—Å–ø–µ—Ä—Ç–∞
    ):
        super().__init__()
        self.top_k      = top_k
        self.experts    = nn.ModuleList([FFN(d_model, d_ff) for _ in range(experts)])
        self.router     = nn.Linear(d_model, experts, bias=False)
        self.capacity   = capacity

        # –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è auxiliary load-balance loss
        self.register_buffer("decay", torch.tensor(0.9))

    def forward(self, x):
        """
        x: [batch, seq, d_model]
        """
        B, S, D = x.shape
        E       = len(self.experts)
        tokens  = x.view(-1, D) # ‚Üí [B¬∑S, d_model]

        # 1) Gating: –æ—Ü–µ–Ω–∫–∏ –≤–∞–∂–Ω–æ—Å—Ç–∏ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        logits   = self.router(tokens) # [B¬∑S, E]
        scores   = F.softmax(logits, dim=-1)

        # 2) Top-k –≤—ã–±–æ—Ä –∏ –∏–Ω–¥–µ–∫—Å—ã —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        topk_val, topk_idx = torch.topk(scores, self.top_k, dim=-1) # [B¬∑S, k]

        # 3) Capacity ‚Äì —Å–∫–æ–ª—å–∫–æ —Ç–æ–∫–µ–Ω–æ–≤ –º–æ–∂–µ—Ç –ø—Ä–∏–Ω—è—Ç—å —ç–∫—Å–ø–µ—Ä—Ç
        cap = int(self.capacity * (B * S) / E)

        # 4) –§–æ—Ä–º–∏—Ä—É–µ–º *dispatch*-–º–∞—Å–∫—É (one-hot –ø–æ —Ç–æ–ø-k) –∏ —Å—á–∏—Ç–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É
        dispatch = torch.zeros(B * S, E, device=x.device)
        for i in range(self.top_k):
            idx = topk_idx[:, i]
            mask = (
                torch.arange(cap, device=x.device)[None, :] # [1, cap]
                < torch.bincount(idx, minlength=E)[idx][:, None]
            )
            dispatch.scatter_(1, idx.unsqueeze(-1), mask.float())

        # 5) –†–∞—Å—Å—ã–ª–∞–µ–º —Ç–æ–∫–µ–Ω—ã –∫ —ç–∫—Å–ø–µ—Ä—Ç–∞–º
        expert_inputs = [
            tokens[dispatch[:, e].bool()] for e in range(E) # variable length
        ]
        expert_outputs = [
            self.experts[e](inp) if len(inp) else torch.empty_like(inp)
            for e, inp in enumerate(expert_inputs)
        ]

        # 6) –û–±—Ä–∞—Ç–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è (gather) —Å –≤–µ—Å–∞–º–∏ —Ç–æ–ø-k-–æ—Ü–µ–Ω–æ–∫
        output = torch.zeros_like(tokens)
        for e in range(E):
            out   = expert_outputs[e] # [n_e, D]
            sel   = dispatch[:, e].bool()
            output[sel] += out * scores[sel, e:e+1] # –≤–∑–≤–µ—à–∏–≤–∞–µ–º –ø–æ softmax-–æ—Ü–µ–Ω–∫–µ

        # 7) –î–æ–ø-–ª–æ—Å—Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –Ω–∞–≥—Ä—É–∑–∫–∏ (Routers Auxiliary Loss)
        load = dispatch.mean(0) # –¥–æ–ª—è —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∞ —ç–∫—Å–ø–µ—Ä—Ç–∞
        prob = scores.mean(0) # —Å—Ä–µ–¥–Ω–µ–µ softmax-p
        aux_loss = (E * (load * prob).sum()) # Fedus et al., 2021

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º EMA —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É, –ø—Ä–∏–≥–æ–¥–∏—Ç—Å—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        if self.training:
            if not hasattr(self, "aux_ema"):
                self.aux_ema = aux_loss.detach()
            self.aux_ema = self.decay * self.aux_ema + (1 - self.decay) * aux_loss.detach()

        return output.view(B, S, D), aux_loss
```

### 2.3 –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∫–æ–¥–∞
| –®–∞–≥                   | –ö–æ–¥                                    | –û–±—ä—è—Å–Ω–µ–Ω–∏–µ                                                                                                                                          |
| --------------------- | -------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- |
| **1. Router softmax** | `scores = F.softmax(logits, -1)`       | –õ–∏–Ω–µ–π–Ω—ã–π ¬´–≥–µ–π—Ç¬ª –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å $p_{i}$, —á—Ç–æ —Ç–æ–∫–µ–Ω –ø–æ–π–¥—ë—Ç –∫ —ç–∫—Å–ø–µ—Ä—Ç—É $i$.                                                               |
| **2. Top-k –≤—ã–±–æ—Ä**    | `topk_val, topk_idx = torch.topk(...)` | –û—Ç–±–∏—Ä–∞–µ–º $k$ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º $p$ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞. –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è $k=1$ –∏–ª–∏ $k=2$ ‚Äî –∫–æ–º–ø—Ä–æ–º–∏—Å—Å ¬´–∫–∞—á–µ—Å—Ç–≤–æ vs –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏¬ª. |
| **3. Capacity**       | `cap = int(self.capacity * N / E)`     | –ö–∞–∂–¥—ã–π —ç–∫—Å–ø–µ—Ä—Ç –æ–±—Å–ª—É–∂–∏–≤–∞–µ—Ç –Ω–µ –±–æ–ª–µ–µ *capacity factor* √ó —Å—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ —Ç–æ–∫–µ–Ω–æ–≤. DeepSpeed-MoE –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1.25.                                    |
| **4. Dispatch mask**  | `dispatch.scatter_`                    | One-hot-—Ç–µ–Ω–∑–æ—Ä `[N, E]` —É–∫–∞–∑—ã–≤–∞–µ—Ç, –∫–∞–∫–æ–π —Ç–æ–∫–µ–Ω –∫ –∫–∞–∫–æ–º—É —ç–∫—Å–ø–µ—Ä—Ç—É –ø–æ–π–¥—ë—Ç ‚Äî –∞–Ω–∞–ª–æ–≥ CUDA-kernel `dhs_dispatch` –≤ DeepSpeed.                           |
| **5. Scatter**        | `expert_inputs = [‚Ä¶]`                  | –†–∞–∑–¥–µ–ª—è–µ–º –≤—Ö–æ–¥—ã –ø–æ —ç–∫—Å–ø–µ—Ä—Ç–∞–º; –≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏ —ç—Ç–æ *all-to-all* MPI-–æ–ø–µ—Ä–∞—Ü–∏—è.                                                               |
| **6. Gather**         | `output[sel] += out * weight`          | –û–±—Ä–∞—Ç–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤, –≤–∑–≤–µ—à–µ–Ω–Ω–∞—è –ø–æ –∏—Å—Ö–æ–¥–Ω—ã–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º (Switch Transformer trick).                                          |
| **7. Aux loss**       | `aux_loss = (E*(load*prob).sum())`     | **Load-balancing loss** —Å—Ç–∏–º—É–ª–∏—Ä—É–µ—Ç —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤, –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞—è ¬´–≥–æ–ª–æ–¥–∞–Ω–∏–µ¬ª .                                                 |


